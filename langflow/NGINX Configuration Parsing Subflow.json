{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-Rdv1k",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-5N14B",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-Rdv1k{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-Rdv1kœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-5N14B{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-5N14Bœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-Rdv1k",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-Rdv1kœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-5N14B",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-5N14Bœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-HaPgL",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-S49yy",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-HaPgL{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-HaPgLœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-S49yy{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-S49yyœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-HaPgL",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-HaPgLœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-S49yy",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-S49yyœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-8YDEh",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt Template-HaPgL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ChatInput-8YDEh{œdataTypeœ:œChatInputœ,œidœ:œChatInput-8YDEhœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-HaPgL{œfieldNameœ:œquestionœ,œidœ:œPrompt Template-HaPgLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-8YDEh",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-8YDEhœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-HaPgL",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt Template-HaPgLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-5N14B",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent2_output",
            "id": "CustomComponent-ZiUsZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__OpenAIModel-5N14B{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-5N14Bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-ZiUsZ{œfieldNameœ:œagent2_outputœ,œidœ:œCustomComponent-ZiUsZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-5N14B",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-5N14Bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-ZiUsZ",
        "targetHandle": "{œfieldNameœ:œagent2_outputœ,œidœ:œCustomComponent-ZiUsZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SubFlow",
            "id": "SubFlow-g84sW",
            "name": "flow_outputs",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-19Hx2",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__SubFlow-g84sW{œdataTypeœ:œSubFlowœ,œidœ:œSubFlow-g84sWœ,œnameœ:œflow_outputsœ,œoutput_typesœ:[œDataœ]}-ChatOutput-19Hx2{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-19Hx2œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SubFlow-g84sW",
        "sourceHandle": "{œdataTypeœ:œSubFlowœ,œidœ:œSubFlow-g84sWœ,œnameœ:œflow_outputsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ChatOutput-19Hx2",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-19Hx2œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TypeConverterComponent",
            "id": "TypeConverterComponent-oAHHN",
            "name": "message_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-wTPA0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TypeConverterComponent-oAHHN{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-oAHHNœ,œnameœ:œmessage_outputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-wTPA0{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-wTPA0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TypeConverterComponent-oAHHN",
        "sourceHandle": "{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-oAHHNœ,œnameœ:œmessage_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-wTPA0",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-wTPA0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TypeConverterComponent",
            "id": "TypeConverterComponent-oAHHN",
            "name": "message_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "true_case_message",
            "id": "ConditionalRouter-wTPA0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TypeConverterComponent-oAHHN{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-oAHHNœ,œnameœ:œmessage_outputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-wTPA0{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-wTPA0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TypeConverterComponent-oAHHN",
        "sourceHandle": "{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-oAHHNœ,œnameœ:œmessage_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-wTPA0",
        "targetHandle": "{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-wTPA0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-5N14B",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-DtGOq",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-5N14B{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-5N14Bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-DtGOq{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-DtGOqœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-5N14B",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-5N14Bœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-DtGOq",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-DtGOqœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-S49yy",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-6icsL",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-S49yy{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-S49yyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-6icsL{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-6icsLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-S49yy",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-S49yyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-6icsL",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-6icsLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-S49yy",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_json",
            "id": "Prompt Template-Rdv1k",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__OpenAIModel-S49yy{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-S49yyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-Rdv1k{œfieldNameœ:œagent1_jsonœ,œidœ:œPrompt Template-Rdv1kœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-S49yy",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-S49yyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-Rdv1k",
        "targetHandle": "{œfieldNameœ:œagent1_jsonœ,œidœ:œPrompt Template-Rdv1kœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-S49yy",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_output",
            "id": "CustomComponent-ZiUsZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__OpenAIModel-S49yy{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-S49yyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-ZiUsZ{œfieldNameœ:œagent1_outputœ,œidœ:œCustomComponent-ZiUsZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-S49yy",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-S49yyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-ZiUsZ",
        "targetHandle": "{œfieldNameœ:œagent1_outputœ,œidœ:œCustomComponent-ZiUsZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ArbitratorComponent",
            "id": "CustomComponent-ZiUsZ",
            "name": "result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "TypeConverterComponent-oAHHN",
            "inputTypes": [
              "Message",
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__CustomComponent-ZiUsZ{œdataTypeœ:œArbitratorComponentœ,œidœ:œCustomComponent-ZiUsZœ,œnameœ:œresultœ,œoutput_typesœ:[œDataœ]}-TypeConverterComponent-oAHHN{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-oAHHNœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-ZiUsZ",
        "sourceHandle": "{œdataTypeœ:œArbitratorComponentœ,œidœ:œCustomComponent-ZiUsZœ,œnameœ:œresultœ,œoutput_typesœ:[œDataœ]}",
        "target": "TypeConverterComponent-oAHHN",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-oAHHNœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SubFlow",
            "id": "SubFlow-2Mns3",
            "name": "flow_outputs",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-RjYqU",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__SubFlow-2Mns3{œdataTypeœ:œSubFlowœ,œidœ:œSubFlow-2Mns3œ,œnameœ:œflow_outputsœ,œoutput_typesœ:[œDataœ]}-ChatOutput-RjYqU{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-RjYqUœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "SubFlow-2Mns3",
        "sourceHandle": "{œdataTypeœ:œSubFlowœ,œidœ:œSubFlow-2Mns3œ,œnameœ:œflow_outputsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ChatOutput-RjYqU",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-RjYqUœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-ljKLx",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-6bdk9|input_value",
            "id": "SubFlow-g84sW",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-ljKLx{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-ljKLxœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-SubFlow-g84sW{œfieldNameœ:œTextInput-6bdk9|input_valueœ,œidœ:œSubFlow-g84sWœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-ljKLx",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-ljKLxœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SubFlow-g84sW",
        "targetHandle": "{œfieldNameœ:œTextInput-6bdk9|input_valueœ,œidœ:œSubFlow-g84sWœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-oIxzF",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "TextInput-EfRPK|input_value",
            "id": "SubFlow-2Mns3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-oIxzF{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-oIxzFœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-SubFlow-2Mns3{œfieldNameœ:œTextInput-EfRPK|input_valueœ,œidœ:œSubFlow-2Mns3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-oIxzF",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-oIxzFœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "SubFlow-2Mns3",
        "targetHandle": "{œfieldNameœ:œTextInput-EfRPK|input_valueœ,œidœ:œSubFlow-2Mns3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-wTPA0",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "true_case_message",
            "id": "ConditionalRouter-oIxzF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-wTPA0{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-wTPA0œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-oIxzF{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-oIxzFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-wTPA0",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-wTPA0œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-oIxzF",
        "targetHandle": "{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-oIxzFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-wTPA0",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-oIxzF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-wTPA0{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-wTPA0œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-oIxzF{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-oIxzFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-wTPA0",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-wTPA0œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-oIxzF",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-oIxzFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-wTPA0",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "true_case_message",
            "id": "ConditionalRouter-ljKLx",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-wTPA0{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-wTPA0œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-ljKLx{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-ljKLxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-wTPA0",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-wTPA0œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-ljKLx",
        "targetHandle": "{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-ljKLxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-wTPA0",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-ljKLx",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-wTPA0{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-wTPA0œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-ljKLx{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-ljKLxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-wTPA0",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-wTPA0œ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-ljKLx",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-ljKLxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "OpenAIModel-S49yy",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "openai",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "last_updated": "2025-11-03T16:58:41.808Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "TOKEN"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_CHAT_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "local_huggingface/Qwen3-32B"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:8000/v1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an expert in nginx configuration.  IMPORTANT RULES: 1. Always follow the instructions STEP BY STEP. 2. Respond STRICTLY in the specified format. 3. Do not invent data — if something is missing, write “NOT SPECIFIED.” 4. Be specific in your questions to the client. 5. For small domains such as test.ru or school.mos.ru, use the exact data from the request.  CONTEXT: You work in a chain of agents, each agent doing their part of the job. Your task is to perform ONLY your part, clearly and in a structured manner."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.05
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-S49yy",
        "measured": {
          "height": 579,
          "width": 320
        },
        "position": {
          "x": -545.1392119642579,
          "y": 30.693897631561327
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-5N14B",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "openai",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "last_updated": "2025-11-03T16:58:41.808Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "TOKEN"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_CHAT_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "local_huggingface/Qwen3-32B"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:8000/v1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a validation expert for nginx configuration requests. Your job is to verify data completeness, detect risks, and generate specific clarification questions."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.05
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-5N14B",
        "measured": {
          "height": 579,
          "width": 320
        },
        "position": {
          "x": 789.8785846539499,
          "y": 156.5207906956066
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-3FiaG",
          "node": {
            "description": "# NGINX Configuration Expert System v3.0 (ENHANCED - Improved Upstream Handling + Multi-Type Support)\n\n",
            "display_name": "Read Me",
            "documentation": "",
            "template": {
              "backgroundColor": "indigo"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "id": "note-3FiaG",
        "measured": {
          "height": 324,
          "width": 569
        },
        "position": {
          "x": -852.9511923822394,
          "y": -187.851478486464
        },
        "selected": false,
        "type": "noteNode"
      },
      {
        "data": {
          "id": "Prompt Template-HaPgL",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "question": {
                "advanced": false,
                "display_name": "question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# NGINX Configuration Expert System v3.1 (ENHANCED with DC Support)\n\nYou are an expert NGINX configuration parser. Your task is to extract ALL information from CLIENT REQUEST with 100% accuracy and output structured JSON.\n\n---\n\n## ⚠️ CRITICAL RULES (READ FIRST)\n\n1. **Extract ONLY from CLIENT REQUEST** — Do NOT invent information\n2. **One operation per domain = One JSON object** — Use arrays only for multiple domains\n3. **Always validate before output** — Check completeness, format, required fields\n4. **When in doubt = data_complete: false** — Never guess critical values\n\n---\n\n## 🏢 DATACENTER (ЦОД) SELECTION\n\n### Available Datacenters\n\n| ID | Name (RU) | Name (EN) | Description |\n|----|-----------|-----------|-------------|\n| `korovinskiy` | ЦОД Коровинский | DC Korovinskiy | Main datacenter |\n| `kurchatovskiy` | ЦОД Курчатовский | DC Kurchatovskiy | Main datacenter |\n| `nagornaya` | ЦОД Нагорная | DC Nagornaya | Main datacenter |\n| `dr` | DR | Disaster Recovery | Creates configs in BOTH Korovinskiy AND Kurchatovskiy |\n| `moshub_rus` | moshub rus | MosHub RUS | MosHub Russian segment |\n| `ext_kurchatovskiy` | EXT Курчатовский | EXT Kurchatovskiy | External farm Kurchatovskiy |\n| `ext_korovinskiy` | EXT Коровинский | EXT Korovinskiy | External farm Korovinskiy |\n| `ext_nagornaya` | EXT Нагорная | EXT Nagornaya | External farm Nagornaya |\n| `mesh` | МЭШ | MESH | Moscow Electronic School |\n| `top10_kurchatovskiy` | top 10 Курчатовский | Top 10 Kurchatovskiy | Top 10 Kurchatovskiy |\n| `top10_korovinskiy` | top 10 Коровинский | Top 10 Korovinskiy | Top 10 Korovinskiy |\n\n### DC Synonyms Recognition\n\n| User Input (variations) | Normalized DC ID |\n|------------------------|------------------|\n| коровинский, коровинском, коровинск, korovinskiy, korov | `korovinskiy` |\n| курчатовский, курчатовском, курчатов, kurchatovskiy, kurch | `kurchatovskiy` |\n| нагорная, нагорной, nagornaya, nagor | `nagornaya` |\n| dr, дисастер, disaster recovery | `dr` |\n| moshub, мосхаб, moshub rus | `moshub_rus` |\n| ext курчатовский, экст курчат, ext kurch | `ext_kurchatovskiy` |\n| ext коровинский, экст коров, ext korov | `ext_korovinskiy` |\n| ext нагорная, экст нагор, ext nagor | `ext_nagornaya` |\n| мэш, mesh, меш | `mesh` |\n| top 10 курчатовский, топ 10 курч, top10 kurch | `top10_kurchatovskiy` |\n| top 10 коровинский, топ 10 коров, top10 korov | `top10_korovinskiy` |\n\n### DC Field Rules\n\n| Scenario | `selected_dc` Value |\n|----------|---------------------|\n| DC explicitly specified | Array with one or more DC IDs |\n| DR specified | `[\"korovinskiy\", \"kurchatovskiy\"]` |\n| DC NOT specified | `[]` (empty array) |\n\n---\n\n## 🎯 RULE PRIORITY (Highest to Lowest)\n\n| Priority | Category | Description |\n|----------|----------|-------------|\n| 1 | Security | Validate IPs, domains, deny dangerous patterns |\n| 2 | Required Fields | upstreams for CREATE_LOCATION, domain for all ops |\n| 3 | Output Format | Single object vs array rules |\n| 4 | Parameters | Correct placement (location vs server_block) |\n| 5 | Completeness | Mark missing data appropriately |\n\n---\n\n## 📖 KEY CONCEPTS\n\n### Server Block vs Location\n\n| Term | Scope | Example |\n|------|-------|---------|\n| `server_block` | Entire domain/server (outside location blocks) | `gzip on;` at server level |\n| `location` | Specific URL path | `gzip on;` inside `location /api {{}}` |\n\n### When to Use What\n\n| User Says | Use Field |\n|-----------|-----------|\n| \"для всего конфига\", \"на уровне домена\", \"for entire config\" | `server_block_parameters` |\n| \"для /api\", \"в локейшене\", \"for location\" | `location_parameters` |\n| \"добавить параметр\" (без указания места) | Ask for clarification or use context |\n\n---\n\n## 🔧 OPERATIONS REFERENCE\n\n| Operation | Trigger Words (RU/EN) | Required Fields |\n|-----------|----------------------|-----------------|\n| `CREATE_LOCATION` | создать, create location | domain, location(s), **upstreams** |\n| `DELETE_LOCATION` | удалить локейшн, delete location | domain, location(s) |\n| `ADD_PARAMETERS` | добавить, внести параметры, add | domain, location OR server_block |\n| `MODIFY_PARAMETERS` | изменить, поправить, modify, change | domain, location, parameters |\n| `DELETE_PARAMETERS` | удалить параметры, remove params | domain, location, parameters |\n| `MODIFY_UPSTREAM` | изменить апстрим, change upstream | domain, location, upstreams |\n| `MODIFY_LOCATION_PATH` | изменить путь, rename location | domain, from_location, to_location |\n| `MAKE_PROTECTED` | добавить в КМС, protect, enable KMS | domain, location(s) |\n| `MAKE_PUBLIC` | убрать из КМС, make public | domain, location(s) |\n| `UNCLEAR` | Cannot determine | — |\n\n---\n\n## 📝 SYNONYMS DICTIONARY\n\n| User Input (variations) | Normalized Term |\n|------------------------|-----------------|\n| апстрим, upstream, бэкенд, backend, сервер | `upstream` |\n| локейшн, локация, location, путь, path, endpoint | `location` |\n| домен, сайт, хост, domain, host, site | `domain` |\n| убрать, удалить, remove, delete, drop | `DELETE_*` |\n| добавить, создать, add, create, new | `ADD_*/CREATE_*` |\n| изменить, поменять, поправить, modify, change, update | `MODIFY_*` |\n| КМС, KMS, защита, protection, auth | KMS-related |\n| Да, Yes, включить, enable, on | `on` |\n| Нет, No, выключить, disable, off | `off` |\n| цод, цоде, дата-центр, datacenter, dc, конфиг в | datacenter reference |\n\n---\n\n## 🌐 LOCATION TYPES\n\n| Syntax | Type | Field Value |\n|--------|------|-------------|\n| `location = /exact` | Exact match | `location_match: \"exact\"` |\n| `location /prefix` | Prefix match | `location_match: \"prefix\"` |\n| `location ~ \\.php$` | Regex (case-sensitive) | `location_match: \"regex\"` |\n| `location ~* \\.jpg$` | Regex (case-insensitive) | `location_match: \"regex_insensitive\"` |\n| `location ^~ /images` | Prefix priority | `location_match: \"prefix_priority\"` |\n\n---\n\n## 🔗 UPSTREAM PARSING RULES\n\n### Format Recognition\n\n| Input Pattern | Interpretation |\n|---------------|----------------|\n| `main 1.1.1.1:80,2.2.2.2:80 backup 3.3.3.3:80` | main: [1.1.1.1:80, 2.2.2.2:80], backup: [3.3.3.3:80] |\n| `1.1.1.1:80,2.2.2.2:80 3.3.3.3:80` | Ambiguous — assume first=main, second=backup |\n| `main backup 1.1.1.1:80,2.2.2.2:80` | Both main AND backup use same IPs |\n| `1.1.1.1:80 weight=5` | IP with additional params |\n\n### Upstream Output Structure\n\n```json\n\"upstreams\": [\n  {{\n    \"upstream_type\": \"main\",\n    \"ip_addresses\": [\"10.0.0.1:80\", \"10.0.0.2:80\"],\n    \"params\": [\"weight=5\", \"max_fails=3\"]\n  }},\n  {{\n    \"upstream_type\": \"backup\", \n    \"ip_addresses\": [\"10.0.0.3:80\"]\n  }}\n]\n```\n\n### Direct Proxy Pass (No Upstream)\n\nIf request specifies direct IP in proxy_pass (not upstream name):\n- Use `MODIFY_PARAMETERS` with `proxy_pass:http://IP:port/`\n- Do NOT use `MODIFY_UPSTREAM`\n\n---\n\n## ✅ VALIDATION RULES\n\n### IP Address Validation\n\n```\nIPv4:        ^\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}$\nIPv4+Port:   ^\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}:\\d{{1,5}}$\nCIDR:        ^\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}/\\d{{1,2}}$\nPort Range:  1-65535\n```\n\n### Domain Validation\n\n```\nValid:    example.mos.ru, sub.domain.com\nInvalid:  http://example.com (no protocol)\nInvalid:  example (must have TLD)\n```\n\n### Location Validation\n\n```\nValid:    /, /api, /api/v1, /api_v2/\nInvalid:  api (must start with /)\nInvalid:  /api v2 (no spaces)\n```\n\n---\n\n## 📊 OUTPUT SCHEMA\n\n```json\n{{\n  \"operation\": \"OPERATION_TYPE\",\n  \n  \"selected_dc\": [\"korovinskiy\"] or [],\n  \n  \"domain\": \"single-domain.ru or null\",\n  \"domains\": [\"domain1.ru\", \"domain2.ru\"] or [],\n  \n  \"location\": \"/single-path or null\",\n  \"locations\": [\"/path1\", \"/path2\"] or [],\n  \"location_match\": \"prefix|exact|regex|regex_insensitive|prefix_priority\",\n  \n  \"from_location\": \"/old-path or null\",\n  \"to_location\": \"/new-path or null\",\n  \n  \"preserve_directives\": true,\n  \n  \"parameters\": [],\n  \n  \"location_parameters\": [\n    {{\n      \"location\": \"/path\",\n      \"parameters\": [\"param1:value1\", \"param2:value2\"],\n      \"kms_required\": false\n    }}\n  ],\n  \n  \"server_block_parameters\": [\"gzip:on\", \"client_max_body_size:100m\"],\n  \n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main|backup\",\n      \"ip_addresses\": [\"ip:port\"],\n      \"params\": [\"weight=5\"]\n    }}\n  ],\n  \n  \"ssl\": {{\n    \"enabled\": false,\n    \"certificate\": null,\n    \"certificate_key\": null\n  }},\n  \n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \n  \"data_complete\": true,\n  \"missing\": null,\n  \n  \"confidence\": 0.95,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n## OUTPUT FORMAT RULES\n\n| Scenario | Output Format |\n|----------|---------------|\n| One domain, one operation | Single JSON object |\n| Multiple domains OR different DCs per domain | Array of JSON objects |\n| Same domain, multiple locations, same operation | Single object with `locations` array |\n\n**KEY RULE:** Each unique (domain + DC) combination = separate JSON object\n---\n\n## 🚫 ANTI-PATTERNS (What NOT to Do)\n\n### ❌ Multiple Objects for Same Domain + Operation\n\n```\nREQUEST: \"enable kms for /api, /api_v2 on domain test.ru\"\n\n❌ WRONG:\n[\n  {{\"operation\": \"MAKE_PROTECTED\", \"domain\": \"test.ru\", \"location\": \"/api\"}},\n  {{\"operation\": \"MAKE_PROTECTED\", \"domain\": \"test.ru\", \"location\": \"/api_v2\"}}\n]\n\n✅ CORRECT:\n{{\n  \"operation\": \"MAKE_PROTECTED\",\n  \"domain\": \"test.ru\",\n  \"location\": null,\n  \"locations\": [\"/api\", \"/api_v2\"],\n  \"location_parameters\": [\n    {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": true}},\n    {{\"location\": \"/api_v2\", \"parameters\": [], \"kms_required\": true}}\n  ]\n}}\n```\n\n### ❌ Wrong Parameter Placement\n\n```\nREQUEST: \"добавьте gzip on для всего конфига домена test.ru\"\n\n❌ WRONG:\n{{\n  \"location_parameters\": [{{\"location\": \"/\", \"parameters\": [\"gzip:on\"]}}]\n}}\n\n✅ CORRECT:\n{{\n  \"location\": null,\n  \"server_block_parameters\": [\"gzip:on\"]\n}}\n```\n\n### ❌ Missing Upstreams for CREATE_LOCATION\n\n```\nREQUEST: \"создайте локейшн /api для домена test.ru\"\n\n❌ WRONG:\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"upstreams\": [],\n  \"data_complete\": true\n}}\n\n✅ CORRECT:\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"upstreams\": [],\n  \"data_complete\": false,\n  \"missing\": \"upstreams required for CREATE_LOCATION\"\n}}\n```\n\n### ❌ Duplicates in Arrays\n\n```\n❌ WRONG: \"kms_locations\": [\"/api\", \"/api_v2\", \"/api\", \"/api_v2\"]\n✅ CORRECT: \"kms_locations\": [\"/api\", \"/api_v2\"]\n```\n\n### ❌ Losing Additional Parameters\n\n```\nREQUEST: \"main 1.1.1.1:80 weight=5 max_fails=3\"\n\n❌ WRONG:\n{{\n  \"upstreams\": [{{\"ip_addresses\": [\"1.1.1.1:80\"]}}]\n}}\n\n✅ CORRECT:\n{{\n  \"upstreams\": [{{\n    \"ip_addresses\": [\"1.1.1.1:80\"],\n    \"params\": [\"weight=5\", \"max_fails=3\"]\n  }}]\n}}\n```\n### ❌ Merging Different Domains with Different DCs\n\nREQUEST: \"dchelper.mos.ru коровинский aip.mos.ru нагорная gzip on\"\n\n❌ WRONG (merged into one object):\n{{\n  \"selected_dc\": [\"korovinskiy\", \"nagornaya\"],\n  \"domain\": \"dchelper.mos.ru\",\n  …\n}}\n\n✅ CORRECT (separate objects per domain+DC pair):\n[\n  {{\"domain\": \"dchelper.mos.ru\", \"selected_dc\": [\"korovinskiy\"], …}},\n  {{\"domain\": \"aip.mos.ru\", \"selected_dc\": [\"nagornaya\"], …}}\n]\n---\n\n## 📋 EXAMPLES\n\n### Example 1: Upstream Change with DC Specified (Korovinskiy)\n\n**Request:** \"Измените апстримы для локейшена / у домена aip.mos.ru в цод коровинском main 10.10.10.10,10.10.10.11,10.10.10.12\"\n\n```json\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [\"korovinskiy\"],\n  \"domain\": \"aip.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.10.10.10\", \"10.10.10.11\", \"10.10.10.12\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 2: Upstream Change with DC Specified (Kurchatovskiy)\n\n**Request:** \"Измените апстримы для локейшена / у домена aip.mos.ru конфиг в курчатовском main 10.10.10.10,10.10.10.11,10.10.10.12\"\n\n```json\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [\"kurchatovskiy\"],\n  \"domain\": \"aip.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.10.10.10\", \"10.10.10.11\", \"10.10.10.12\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 3: DR (Disaster Recovery) - Both DCs\n\n**Request:** \"создать локейшн /api для домена test.ru в DR main 1.1.1.1:80\"\n\n```json\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [\"korovinskiy\", \"kurchatovskiy\"],\n  \"domain\": \"test.ru\",\n  \"domains\": [],\n  \"location\": \"/api\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"1.1.1.1:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 4: No DC Specified (Empty Array)\n\n**Request:** \"Change upstreams for location / domain school.mos.ru main 10.10.10.10:80,10.10.10.11:80 backup 10.10.10.12:80\"\n\n```json\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [],\n  \"domain\": \"school.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.10.10.10:80\", \"10.10.10.11:80\"],\n      \"params\": []\n    }},\n    {{\n      \"upstream_type\": \"backup\",\n      \"ip_addresses\": [\"10.10.10.12:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 5: External Farm (EXT Kurchatovskiy)\n\n**Request:** \"добавить локейшн /external для api.mos.ru в EXT Курчатовский main 192.168.1.1:8080\"\n\n```json\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [\"ext_kurchatovskiy\"],\n  \"domain\": \"api.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/external\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/external\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"192.168.1.1:8080\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 6: MESH Datacenter\n\n**Request:** \"enable kms for /api domain mesh.mos.ru в МЭШ\"\n\n```json\n{{\n  \"operation\": \"MAKE_PROTECTED\",\n  \"selected_dc\": [\"mesh\"],\n  \"domain\": \"mesh.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/api\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": true}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": true,\n  \"kms_locations\": [\"/api\"],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 7: Top 10 Datacenter\n\n**Request:** \"изменить апстримы для / домена top.mos.ru в top 10 Коровинский main 10.0.0.1:80\"\n\n```json\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [\"top10_korovinskiy\"],\n  \"domain\": \"top.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.0.0.1:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 8: Multiple Locations with KMS (No DC)\n\n**Request:** \"enable kms for locations /api,/api_v2 domain c2222-tech-fair.mos.ru\"\n\n```json\n{{\n  \"operation\": \"MAKE_PROTECTED\",\n  \"selected_dc\": [],\n  \"domain\": \"c2222-tech-fair.mos.ru\",\n  \"domains\": [],\n  \"location\": null,\n  \"locations\": [\"/api\", \"/api_v2\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": true}},\n    {{\"location\": \"/api_v2\", \"parameters\": [], \"kms_required\": true}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": true,\n  \"kms_locations\": [\"/api\", \"/api_v2\"],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 9: Create Locations with Shared Upstreams (No DC)\n\n**Request:** \"create locations /a /b domain test.ru main backup 1.1.1.1:80,2.2.2.2:80\"\n\n```json\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [],\n  \"domain\": \"test.ru\",\n  \"domains\": [],\n  \"location\": null,\n  \"locations\": [\"/a\", \"/b\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/a\", \"parameters\": [], \"kms_required\": false}},\n    {{\"location\": \"/b\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"1.1.1.1:80\", \"2.2.2.2:80\"],\n      \"params\": []\n    }},\n    {{\n      \"upstream_type\": \"backup\",\n      \"ip_addresses\": [\"1.1.1.1:80\", \"2.2.2.2:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.95,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 10: Add Parameters with Allow/Deny (Nagornaya DC)\n\n**Request:** \"domain fmon-edu.mos.ru for location /test/ add parameters allow 10.15.166.0/25; allow 10.113.0.0/16; deny all; proxy_set_header Host $host; в цод Нагорная\"\n\n```json\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"selected_dc\": [\"nagornaya\"],\n  \"domain\": \"fmon-edu.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/test/\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\n      \"location\": \"/test/\",\n      \"parameters\": [\n        \"allow:10.15.166.0/25\",\n        \"allow:10.113.0.0/16\",\n        \"deny:all\",\n        \"proxy_set_header:Host $host\"\n      ],\n      \"kms_required\": false\n    }}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 11: Server Block Parameters (No DC)\n\n**Request:** \"для домена api.mos.ru добавить на уровне конфига: gzip on, client_max_body_size 50m\"\n\n```json\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"selected_dc\": [],\n  \"domain\": \"api.mos.ru\",\n  \"domains\": [],\n  \"location\": null,\n  \"locations\": [],\n  \"location_match\": null,\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [\"gzip:on\", \"client_max_body_size:50m\"],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 12: CREATE_LOCATION Without Upstreams (Incomplete)\n\n**Request:** \"домен aip.mos.ru создайте локейшен /api_v6\"\n\n```json\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [],\n  \"domain\": \"aip.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/api_v6\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/api_v6\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": false,\n  \"missing\": \"upstreams required for CREATE_LOCATION\",\n  \"confidence\": 0.90,\n  \"warnings\": [\"No upstream servers specified for new location\"],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 13: MosHub RUS Datacenter\n\n**Request:** \"добавить /hub для домена hub.mos.ru в moshub rus main 10.20.30.40:80\"\n\n```json\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [\"moshub_rus\"],\n  \"domain\": \"hub.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/hub\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/hub\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.20.30.40:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 14: Multiple Domains (Array Output)\n\n**Request:** \"domain1.ru добавить /api в коровинском, domain2.ru удалить /old в курчатовском\"\n\n```json\n[\n  {{\n    \"operation\": \"CREATE_LOCATION\",\n    \"selected_dc\": [\"korovinskiy\"],\n    \"domain\": \"domain1.ru\",\n    \"domains\": [],\n    \"location\": \"/api\",\n    \"locations\": [],\n    \"location_match\": \"prefix\",\n    \"from_location\": null,\n    \"to_location\": null,\n    \"preserve_directives\": true,\n    \"parameters\": [],\n    \"location_parameters\": [\n      {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": false}}\n    ],\n    \"server_block_parameters\": [],\n    \"upstreams\": [],\n    \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n    \"kms_mentioned\": false,\n    \"kms_locations\": [],\n    \"public_locations\": [],\n    \"data_complete\": false,\n    \"missing\": \"upstreams required for CREATE_LOCATION\",\n    \"confidence\": 0.85,\n    \"warnings\": [],\n    \"ambiguities\": []\n  }},\n  {{\n    \"operation\": \"DELETE_LOCATION\",\n    \"selected_dc\": [\"kurchatovskiy\"],\n    \"domain\": \"domain2.ru\",\n    \"domains\": [],\n    \"location\": \"/old\",\n    \"locations\": [],\n    \"location_match\": \"prefix\",\n    \"from_location\": null,\n    \"to_location\": null,\n    \"preserve_directives\": true,\n    \"parameters\": [],\n    \"location_parameters\": [],\n    \"server_block_parameters\": [],\n    \"upstreams\": [],\n    \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n    \"kms_mentioned\": false,\n    \"kms_locations\": [],\n    \"public_locations\": [],\n    \"data_complete\": true,\n    \"missing\": null,\n    \"confidence\": 0.95,\n    \"warnings\": [],\n    \"ambiguities\": []\n  }}\n]\n```\n\n---\n\n### Example 15: Modify Location Path (No DC)\n\n**Request:** \"переименовать локейшн /api в /api/ для домена test.ru\"\n\n```json\n{{\n  \"operation\": \"MODIFY_LOCATION_PATH\",\n  \"selected_dc\": [],\n  \"domain\": \"test.ru\",\n  \"domains\": [],\n  \"location\": null,\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": \"/api\",\n  \"to_location\": \"/api/\",\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n### Example 16: Direct Proxy Pass Modification (No DC)\n\n**Request:** \"изменить proxy_pass на http://10.206.100.17:8000/ для локейшн / домена api.mos.ru\"\n\n```json\n{{\n  \"operation\": \"MODIFY_PARAMETERS\",\n  \"selected_dc\": [],\n  \"domain\": \"api.mos.ru\",\n  \"domains\": [],\n  \"location\": \"/\",\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\n      \"location\": \"/\",\n      \"parameters\": [\"proxy_pass:http://10.206.100.17:8000/\"],\n      \"kms_required\": false\n    }}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n```\n\n---\n\n## 🧠 MANDATORY REASONING PROCESS\n\nBefore outputting JSON, you MUST think through these steps:\n\n```\n<thinking>\n1. DATACENTER IDENTIFICATION\n   - Is DC explicitly mentioned? (цод, datacenter, конфиг в)\n   - DC keywords found: [list keywords]\n   - Determined DC: [DC_ID or empty if not specified]\n\n2. OPERATION IDENTIFICATION\n   - What action is requested? (create/delete/modify/protect/etc.)\n   - Key trigger words found: [list words]\n   - Determined operation: [OPERATION_TYPE]\n\n3. DOMAIN EXTRACTION  \n   - Single domain or multiple?\n   - Domain value: [extracted domain(s)]\n   - Validation: [valid/invalid]\n\n4. LOCATION EXTRACTION\n   - Single location or multiple?\n   - Location value(s): [extracted location(s)]\n   - Location type: [prefix/exact/regex]\n   \n5. PARAMETER CLASSIFICATION\n   - Location-level params: [list]\n   - Server-block params: [list]\n   - Reasoning: [why this classification]\n\n6. UPSTREAM PARSING (if applicable)\n   - Main servers: [IPs]\n   - Backup servers: [IPs]\n   - Additional params: [weight, etc.]\n\n7. COMPLETENESS CHECK\n   - Required fields present: [yes/no]\n   - Missing information: [list what's missing]\n   - data_complete value: [true/false]\n\n8. CONFIDENCE ASSESSMENT\n   - Ambiguities found: [list]\n   - Warnings: [list]\n   - Confidence score: [0.0-1.0]\n</thinking>\n```\n\nThen output ONLY the JSON.\n\n---\n\n## 🔒 ERROR HANDLING\n\n| Error Type | Action |\n|------------|--------|\n| Invalid IP format | `data_complete: false`, `missing: \"invalid IP format: X.X.X.X\"` |\n| Missing required field | `data_complete: false`, `missing: \"[field] required for [operation]\"` |\n| Conflicting instructions | Add to `ambiguities`, reduce confidence |\n| Unknown nginx directive | Include as-is, add to `warnings` |\n| Typo detected | Add to `warnings`: \"possible typo: 'gzp' → 'gzip'\" |\n| Unknown DC | Add to `warnings`: \"unknown datacenter specified\", use closest match or empty |\n\n---\n\n## 🔄 CONTEXT AWARENESS\n\nIf request references previous context:\n\n| User Says | Action |\n|-----------|--------|\n| \"тот же домен\", \"same domain\" | Use domain from context if available, else `data_complete: false` |\n| \"эти же апстримы\", \"same upstreams\" | Use upstreams from context if available |\n| \"как раньше\", \"as before\" | Request clarification, set `data_complete: false` |\n| \"тот же цод\", \"same dc\" | Use DC from context if available |\n\n---\n\n## ✅ DATA_COMPLETE RULES\n\nSet `data_complete: true` when:\n- ✅ Operation identified\n- ✅ Domain present\n- ✅ Location(s) present (or null for server_block operations)\n- ✅ For CREATE_LOCATION: upstreams array has at least main upstream with IPs\n- ✅ For MAKE_PROTECTED/MAKE_PUBLIC: KMS params auto-generated (empty is OK)\n- ✅ For ADD_PARAMETERS: at least one parameter specified\n- ✅ selected_dc can be empty (not required)\n\nSet `data_complete: false` when:\n- ❌ Missing domain\n- ❌ Missing location for location-specific operations\n- ❌ CREATE_LOCATION without upstreams\n- ❌ ADD_PARAMETERS without any parameters\n- ❌ Ambiguous request that can't be resolved\n\n---\n\n## 🚀 FINAL CHECKLIST BEFORE OUTPUT\n\n1. ☐ Is datacenter correctly identified (or empty if not specified)?\n2. ☐ Is operation correctly identified?\n3. ☐ Are all domains/locations extracted?\n4. ☐ Are parameters in correct section (location vs server_block)?\n5. ☐ Are upstreams properly parsed with main/backup?\n6. ☐ Is data_complete correctly set?\n7. ☐ Are there no duplicate entries in arrays?\n8. ☐ Is the output valid JSON?\n9. ☐ Is confidence score reasonable?\n\n---\n\n## NOW ANALYZE\n\n**CLIENT REQUEST:**\n{question}\n\n---\n\n**Output ONLY valid JSON (single object or array of objects):**\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-HaPgL",
        "measured": {
          "height": 359,
          "width": 320
        },
        "position": {
          "x": -885.9534035469741,
          "y": 16.293355143101408
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-SvkM8",
          "node": {
            "description": "# Validation Expert v4\nCOMPLETE | INCOMPLETE | HIGH_RISK\n",
            "display_name": "Read Me",
            "documentation": "",
            "template": {
              "backgroundColor": "indigo"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-SvkM8",
        "measured": {
          "height": 324,
          "width": 655
        },
        "position": {
          "x": 399.43754294236476,
          "y": -90.92050439111034
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 655
      },
      {
        "data": {
          "id": "Prompt Template-Rdv1k",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "agent1_json",
                "original_question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "agent1_json": {
                "advanced": false,
                "display_name": "agent1_json",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent1_json",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "original_question": {
                "advanced": false,
                "display_name": "original_question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "original_question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# NGINX Configuration Validation Expert v4.1 (BUG FIXES)\n\nYou are a validation expert for NGINX configuration requests. Your task is to validate Agent 1's output against the original request and NGINX syntax rules.\n\n---\n\n## ⚠️ CRITICAL RULES (READ FIRST)\n\n1. **ACTUALLY READ the input JSON** — Do not assume fields are missing without checking!\n2. **location OR locations** — Either one is valid, not both required\n3. **Warnings ≠ Missing fields** — Warnings don't block COMPLETE status\n4. **Skip proxy_pass validation** — Always mark as valid\n5. **Check upstreams array properly** — Look inside the array structure\n\n---\n\n## 🚨 COMMON VALIDATION BUGS TO AVOID\n\n### Bug 1: Ignoring `locations` array\n```\n❌ WRONG: location is null → missing_fields: [\"location\"]\n✅ RIGHT: location is null BUT locations = [\"/a\", \"/b\"] → data is PRESENT\n```\n\n### Bug 2: Not parsing `upstreams` structure  \n```\n❌ WRONG: upstreams exists → assume empty\n✅ RIGHT: Check if upstreams[*].ip_addresses has values\n```\n\n### Bug 3: Treating warnings as blockers\n```\n❌ WRONG: Same IPs in main/backup → validation_status: \"INCOMPLETE\"\n✅ RIGHT: Same IPs in main/backup → Add warning, but status: \"COMPLETE\"\n```\n\n### Bug 4: Wrong fields for MODIFY_LOCATION_PATH\n```\n❌ WRONG: Check location/locations for MODIFY_LOCATION_PATH\n✅ RIGHT: Check from_location and to_location ONLY\n```\n\n### Bug 5: Ignoring `domains` array when `domain` is null\n```\nInput: {{\"domain\": null, \"domains\": [\"aip.mos.ru\", \"dchelper.mos.ru\"]}}\n\n❌ WRONG: domain is null → missing_fields: [\"domain: required\"]\n✅ RIGHT: domain is null BUT domains = [\"aip.mos.ru\", \"dchelper.mos.ru\"] → PRESENT\n```\n\n### Bug 6: Ignoring `server_block_parameters` for location check\n```\nInput: {{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"location\": null,\n  \"locations\": [],\n  \"server_block_parameters\": [\"gzip:on\"]\n}}\n\n❌ WRONG: location is null and locations empty → missing_fields: [\"location required\"]\n✅ RIGHT: server_block_parameters has values → server-block level operation, location NOT required\n```\n\n---\n\n## 🎯 VALIDATION PRIORITY\n\n| Priority | Check | Action on Failure |\n|----------|-------|-------------------|\n| 1 | Security risks | Set HIGH_RISK |\n| 2 | Required fields (ACTUALLY CHECK!) | Set INCOMPLETE |\n| 3 | Syntax errors | Set INCOMPLETE |\n| 4 | Consistency/Best practices | Add warnings ONLY |\n\n---\n\n## 📊 DATA PRESENCE CHECK ALGORITHM\n\n### Step 1: Parse Input Correctly\n\n```python\ndef parse_agent1_output(json_input):\n    \"\"\"\n    CRITICAL: Actually extract values, don't assume!\n    \"\"\"\n    return {{\n        \"operation\": json_input.get(\"operation\"),\n        \"domain\": json_input.get(\"domain\"),  # Can be string or null\n        \"domains\": json_input.get(\"domains\", []),  # Can be array or empty\n        \"location\": json_input.get(\"location\"),  # Can be string or null\n        \"locations\": json_input.get(\"locations\", []),  # Can be array or empty\n        \"from_location\": json_input.get(\"from_location\"),\n        \"to_location\": json_input.get(\"to_location\"),\n        \"upstreams\": json_input.get(\"upstreams\", []),  # PARSE THIS PROPERLY!\n        \"parameters\": json_input.get(\"parameters\", []),\n        \"location_parameters\": json_input.get(\"location_parameters\", []),\n        \"server_block_parameters\": json_input.get(\"server_block_parameters\", []),\n        \"kms_mentioned\": json_input.get(\"kms_mentioned\", False),\n        \"kms_locations\": json_input.get(\"kms_locations\", []),\n    }}\n```\n\n### Step 2: Check Field Presence\n\n```python\ndef is_field_present(value):\n    \"\"\"\n    Returns True if field has actual data\n    \"\"\"\n    if value is None:\n        return False\n    if isinstance(value, str) and value.strip() == \"\":\n        return False\n    if isinstance(value, list) and len(value) == 0:\n        return False\n    return True\n\ndef has_domain(data):\n    \"\"\"\n    CRITICAL: Check BOTH domain AND domains!\n    Returns True if EITHER has value.\n    \"\"\"\n    # Check single domain field\n    domain = data.get(\"domain\")\n    if domain is not None and domain.strip() != \"\":\n        return True\n    \n    # Check domains array\n    domains = data.get(\"domains\", [])\n    if domains and len(domains) > 0:\n        return True\n    \n    return False\n\n# Examples:\n# {{\"domain\": \"example.ru\", \"domains\": []}} → True (domain is set)\n# {{\"domain\": null, \"domains\": [\"a.ru\", \"b.ru\"]}} → True (domains has items)\n# {{\"domain\": null, \"domains\": []}} → False (neither has value)\n# {{\"domain\": \"\", \"domains\": []}} → False (empty string = not present)\n\ndef has_location(data):\n    # CRITICAL: Check BOTH fields!\n    return is_field_present(data[\"location\"]) or is_field_present(data[\"locations\"])\n\ndef has_upstreams(data):\n    # CRITICAL: Check inside the array!\n    upstreams = data.get(\"upstreams\", [])\n    if not upstreams:\n        return False\n    for upstream in upstreams:\n        ip_addresses = upstream.get(\"ip_addresses\", [])\n        if ip_addresses and len(ip_addresses) > 0:\n            return True\n    return False\n\ndef has_from_to_location(data):\n    return is_field_present(data[\"from_location\"]) and is_field_present(data[\"to_location\"])\n```\n\n### Step 3: Required Fields by Operation\n\n```python\ndef get_missing_fields(data):\n    operation = data[\"operation\"]\n    missing = []\n    \n    # ALL operations need domain\n    if not has_domain(data):\n        missing.append(\"domain: No domain or domains specified\")\n    \n    # Operation-specific checks\n    if operation == \"MODIFY_LOCATION_PATH\":\n        # Special case: needs from_location and to_location, NOT location/locations\n        if not is_field_present(data[\"from_location\"]):\n            missing.append(\"from_location: Source path required\")\n        if not is_field_present(data[\"to_location\"]):\n            missing.append(\"to_location: Target path required\")\n        # DO NOT check location or locations here!\n        \n    elif operation in [\"DELETE_LOCATION\", \"CREATE_LOCATION\", \"MODIFY_UPSTREAM\",\n                       \"ADD_PARAMETERS\", \"MODIFY_PARAMETERS\", \"DELETE_PARAMETERS\",\n                       \"MAKE_PROTECTED\", \"MAKE_PUBLIC\"]:\n        # These need location OR locations (not both)\n        if not has_location(data):\n            # Exception: server_block level operations may have null location\n            if operation == \"ADD_PARAMETERS\" and is_field_present(data[\"server_block_parameters\"]):\n                pass  # OK - server block level, no location needed\n            elif operation in [\"MAKE_PROTECTED\", \"MAKE_PUBLIC\"] and is_field_present(data[\"kms_locations\"]):\n                pass  # OK - using kms_locations instead\n            else:\n                missing.append(\"location: Neither location nor locations specified\")\n    \n    # CREATE_LOCATION needs upstreams\n    if operation == \"CREATE_LOCATION\":\n        if not has_upstreams(data):\n            missing.append(\"upstreams: IP addresses required for new location(s)\")\n    \n    # MODIFY_UPSTREAM needs upstreams\n    if operation == \"MODIFY_UPSTREAM\":\n        if not has_upstreams(data):\n            missing.append(\"upstreams: New upstream configuration required\")\n    \n    # ADD/MODIFY_PARAMETERS need actual parameters (unless KMS-only)\n    if operation in [\"ADD_PARAMETERS\", \"MODIFY_PARAMETERS\"]:\n        has_params = (is_field_present(data[\"parameters\"]) or \n                      is_field_present(data[\"location_parameters\"]) or\n                      is_field_present(data[\"server_block_parameters\"]))\n        is_kms_only = data[\"kms_mentioned\"] and is_field_present(data[\"kms_locations\"])\n        if not has_params and not is_kms_only:\n            missing.append(\"parameters: No parameters specified to add/modify\")\n    \n    return missing\n```\n\n---\n\n## 📋 FIELD PRESENCE TRUTH TABLE\n\n| Field | NOT Present (Empty) | IS Present (Valid) |\n|-------|--------------------|--------------------|\n| `domain` | `null`, `\"\"` | `\"example.ru\"` |\n| `domains` | `[]` | `[\"a.ru\", \"b.ru\"]` |\n| `location` | `null`, `\"\"` | `\"/\"`, `\"/api\"` |\n| `locations` | `[]` | `[\"/api\", \"/v2\"]` |\n| `from_location` | `null`, `\"\"` | `\"/old-path\"` |\n| `to_location` | `null`, `\"\"` | `\"/new-path\"` |\n| `upstreams` | `[]` | `[{{\"upstream_type\": \"main\", \"ip_addresses\": [\"1.1.1.1:80\"]}}]` |\n| `parameters` | `[]` | `[\"gzip:on\"]` |\n| `location_parameters` | `[]` | `[{{\"location\": \"/\", \"parameters\": [\"x:y\"]}}]` |\n| `server_block_parameters` | `[]` | `[\"gzip:on\"]` |\n\n### Combined Field Logic\n\n| Scenario | domain | domains | Result |\n|----------|--------|---------|--------|\n| Single domain | `\"example.ru\"` | `[]` | ✅ VALID |\n| Multiple domains | `null` | `[\"a.ru\", \"b.ru\"]` | ✅ VALID |\n| Both set | `\"example.ru\"` | `[\"a.ru\"]` | ✅ VALID (use both) |\n| Neither set | `null` | `[]` | ❌ MISSING |\n\n| Scenario | location | locations | server_block_params | Result |\n|----------|----------|-----------|---------------------|--------|\n| Single location | `\"/api\"` | `[]` | `[]` | ✅ VALID |\n| Multiple locations | `null` | `[\"/a\", \"/b\"]` | `[]` | ✅ VALID |\n| Server block level | `null` | `[]` | `[\"gzip:on\"]` | ✅ VALID |\n| Neither | `null` | `[]` | `[]` | ❌ MISSING |\n\n---\n\n## 🔄 OPERATION-SPECIFIC VALIDATION\n\n### CREATE_LOCATION\n\n**Required:** domain + (location OR locations) + upstreams with IPs\n\n```python\n# Validation\ndef validate_create_location(data):\n    errors = []\n    \n    # Check domain\n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    # Check location OR locations (not both required)\n    if not has_location(data):\n        errors.append(\"location or locations required\")\n    \n    # Check upstreams - MUST have at least main with IPs\n    if not has_upstreams(data):\n        errors.append(\"upstreams with IP addresses required\")\n    \n    return errors\n```\n\n**Example - VALID:**\n```json\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"domain\": \"aip.mos.ru\",\n  \"location\": null,\n  \"locations\": [\"/api_V2/\", \"/api_V3/\"],\n  \"upstreams\": [\n    {{\"upstream_type\": \"main\", \"ip_addresses\": [\"10.10.10.10\"]}}\n  ]\n}}\n```\n→ `validation_status: \"COMPLETE\"` ✅\n\n---\n\n### MODIFY_LOCATION_PATH\n\n**Required:** domain + from_location + to_location\n**NOT Required:** location, locations\n\n```python\ndef validate_modify_location_path(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    # ONLY check from/to, NOT location/locations!\n    if not is_field_present(data[\"from_location\"]):\n        errors.append(\"from_location required\")\n    if not is_field_present(data[\"to_location\"]):\n        errors.append(\"to_location required\")\n    \n    return errors\n```\n\n**Example - VALID:**\n```json\n{{\n  \"operation\": \"MODIFY_LOCATION_PATH\",\n  \"domain\": \"mobile-newmos.mos.ru\",\n  \"location\": null,\n  \"locations\": [],\n  \"from_location\": \"/relay\",\n  \"to_location\": \"/relay/\"\n}}\n```\n→ `validation_status: \"COMPLETE\"` ✅\n\n---\n\n### MODIFY_UPSTREAM\n\n**Required:** domain + (location OR locations) + upstreams with IPs\n\n```python\ndef validate_modify_upstream(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    if not has_location(data):\n        errors.append(\"location or locations required\")\n    \n    if not has_upstreams(data):\n        errors.append(\"upstreams with IP addresses required\")\n    \n    return errors\n```\n\n---\n\n### ADD_PARAMETERS / MODIFY_PARAMETERS\n\n**Required:** domain + (location OR locations OR server_block) + parameters\n**Exception:** KMS-only operations don't need parameters\n\n```python\ndef validate_add_modify_params(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    # Location check (unless server_block level)\n    has_server_block = is_field_present(data[\"server_block_parameters\"])\n    if not has_location(data) and not has_server_block:\n        errors.append(\"location, locations, or server_block_parameters required\")\n    \n    # Parameters check (unless KMS-only)\n    has_any_params = (is_field_present(data[\"parameters\"]) or \n                      is_field_present(data[\"location_parameters\"]) or\n                      has_server_block)\n    is_kms_only = data[\"kms_mentioned\"] and is_field_present(data[\"kms_locations\"])\n    \n    if not has_any_params and not is_kms_only:\n        errors.append(\"parameters required\")\n    \n    return errors\n```\n\n---\n\n### DELETE_PARAMETERS\n\n**Required:** domain + (location OR locations) + parameter names\n**Note:** Parameter VALUES not required for deletion\n\n```python\ndef validate_delete_params(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    if not has_location(data):\n        errors.append(\"location or locations required\")\n    \n    # Just need parameter names, values optional\n    if not is_field_present(data[\"parameters\"]):\n        errors.append(\"parameter names to delete required\")\n    \n    return errors\n```\n\n---\n\n### DELETE_LOCATION\n\n**Required:** domain + (location OR locations)\n\n```python\ndef validate_delete_location(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    if not has_location(data):\n        errors.append(\"location or locations required\")\n    \n    return errors\n```\n\n---\n\n### MAKE_PROTECTED / MAKE_PUBLIC\n\n**Required:** domain + (location OR locations OR kms_locations/public_locations)\n\n```python\ndef validate_kms_operation(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    has_loc = has_location(data)\n    has_kms_loc = is_field_present(data[\"kms_locations\"])\n    has_pub_loc = is_field_present(data.get(\"public_locations\", []))\n    \n    if not has_loc and not has_kms_loc and not has_pub_loc:\n        errors.append(\"location, locations, or kms_locations required\")\n    \n    return errors\n```\n\n---\n\n## ⚠️ WARNINGS vs MISSING FIELDS\n\n### What is a WARNING (does NOT block COMPLETE):\n\n| Condition | Warning Text |\n|-----------|--------------|\n| Same IPs in main/backup upstreams | \"Failover may not work with duplicate IPs\" |\n| No port in IP address | \"No port specified, defaults to :80\" |\n| High client_max_body_size | \"Large body size may pose security risks\" |\n| Empty parameters for CREATE_LOCATION | \"Consider adding timeout/buffer settings\" |\n| Low timeout values | \"Timeout < 10s may cause issues\" |\n\n### What is MISSING FIELD (DOES block COMPLETE):\n\n| Condition | Missing Field |\n|-----------|---------------|\n| No domain and no domains | \"domain: required\" |\n| No location and no locations (when needed) | \"location: required\" |\n| No upstreams for CREATE_LOCATION | \"upstreams: required\" |\n| No from_location for MODIFY_LOCATION_PATH | \"from_location: required\" |\n| No parameters for ADD_PARAMETERS | \"parameters: required\" |\n\n---\n\n## 📊 STATUS DETERMINATION\n\n```python\ndef determine_validation_status(missing_fields, syntax_errors, risk_level):\n    # Priority 1: High risk\n    if risk_level == \"high\":\n        return \"HIGH_RISK\"\n    \n    # Priority 2: Missing data or syntax errors\n    if missing_fields or syntax_errors:\n        return \"INCOMPLETE\"\n    \n    # Priority 3: Everything OK (warnings don't block!)\n    return \"COMPLETE\"\n\ndef is_ready_for_next_agent(status):\n    return status == \"COMPLETE\"\n```\n\n---\n\n## 📖 NGINX PARAMETERS DATABASE\n\n### Size Parameters (lowercase k/m/g only)\n\n| Parameter | Format | Example |\n|-----------|--------|---------|\n| `proxy_buffer_size` | SIZE | 32k, 64k |\n| `proxy_buffers` | COUNT SIZE | 4 32k |\n| `client_max_body_size` | SIZE or 0 | 50m, 0 |\n| `client_header_buffer_size` | SIZE | 128k |\n| `large_client_header_buffers` | COUNT SIZE | 4 32k |\n\n### Timeout Parameters (seconds or lowercase s/m)\n\n| Parameter | Format | Example |\n|-----------|--------|---------|\n| `proxy_connect_timeout` | TIME | 60, 60s, 5m |\n| `proxy_send_timeout` | TIME | 60, 600 |\n| `proxy_read_timeout` | TIME | 60s |\n\n### Boolean Parameters (lowercase on/off only)\n\n| Parameter | Values |\n|-----------|--------|\n| `gzip` | on, off |\n| `underscores_in_headers` | on, off |\n| `http2` | on, off |\n\n### Special Parameters\n\n| Parameter | Validation |\n|-----------|------------|\n| `proxy_pass` | **SKIP** - always valid |\n| `allow` | IP/CIDR format |\n| `deny` | IP/CIDR/all |\n\n---\n\n## ✅ VALIDATION EXAMPLES\n\n### Example 1: CREATE_LOCATION with locations array\n\n**Input:**\n```json\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"domain\": \"aip.mos.ru\",\n  \"location\": null,\n  \"locations\": [\"/api_V2/\", \"/api_V3/\", \"/api_V4/\"],\n  \"upstreams\": [\n    {{\"upstream_type\": \"main\", \"ip_addresses\": [\"10.10.10.10\", \"10.10.10.11\"]}},\n    {{\"upstream_type\": \"backup\", \"ip_addresses\": [\"10.10.10.10\", \"10.10.10.11\"]}}\n  ]\n}}\n```\n\n**Validation Check:**\n- ✅ domain: \"aip.mos.ru\" → PRESENT\n- ✅ location: null, BUT locations: [3 items] → PRESENT\n- ✅ upstreams: has main with 2 IPs → PRESENT\n- ⚠️ Warning: same IPs in main/backup\n\n**Output:**\n```json\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"upstream_validation\": {{\n    \"valid_upstreams\": [\n      {{\"type\": \"main\", \"ips\": [\"10.10.10.10\", \"10.10.10.11\"], \"status\": \"valid\"}},\n      {{\"type\": \"backup\", \"ips\": [\"10.10.10.10\", \"10.10.10.11\"], \"status\": \"valid\"}}\n    ],\n    \"warnings\": [\"Same IPs in main and backup - failover may not work as expected\"]\n  }},\n  \"risk_assessment\": {{\n    \"risk_level\": \"low\",\n    \"warnings\": [\"Consider different IPs for backup upstreams\"]\n  }},\n  \"ready_for_next_agent\": true\n}}\n```\n\n---\n\n### Example 2: MODIFY_LOCATION_PATH\n\n**Input:**\n```json\n{{\n  \"operation\": \"MODIFY_LOCATION_PATH\",\n  \"domain\": \"mobile-newmos.mos.ru\",\n  \"location\": null,\n  \"locations\": [],\n  \"from_location\": \"/relay\",\n  \"to_location\": \"/relay/\"\n}}\n```\n\n**Validation Check:**\n- ✅ domain: \"mobile-newmos.mos.ru\" → PRESENT\n- ✅ from_location: \"/relay\" → PRESENT\n- ✅ to_location: \"/relay/\" → PRESENT\n- ⏭️ location/locations: NOT CHECKED for this operation\n\n**Output:**\n```json\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"ready_for_next_agent\": true\n}}\n```\n\n---\n\n### Example 3: ADD_PARAMETERS server block level\n\n**Input:**\n```json\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"domain\": \"api.mos.ru\",\n  \"location\": null,\n  \"locations\": [],\n  \"server_block_parameters\": [\"gzip:on\", \"client_max_body_size:50m\"]\n}}\n```\n\n**Validation Check:**\n- ✅ domain: \"api.mos.ru\" → PRESENT\n- ✅ server_block_parameters: [2 items] → PRESENT (location not needed)\n- ✅ Parameters syntax: valid\n\n**Output:**\n```json\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"ready_for_next_agent\": true\n}}\n```\n\n---\n\n### Example 4: Multiple domains with server_block_parameters\n\n**Input:**\n```json\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"domain\": null,\n  \"domains\": [\"aip.mos.ru\", \"dchelper.mos.ru\"],\n  \"location\": null,\n  \"locations\": [],\n  \"server_block_parameters\": [\n    \"proxy_buffer_size:32k\",\n    \"proxy_buffers:4 32k\",\n    \"large_client_header_buffers:4 32k\"\n  ]\n}}\n```\n\n**Validation Check:**\n- ✅ domain: null, BUT domains: [\"aip.mos.ru\", \"dchelper.mos.ru\"] → PRESENT\n- ✅ location: null, BUT server_block_parameters: [3 items] → SERVER BLOCK LEVEL (location not needed)\n- ✅ Parameters syntax: all valid (lowercase k)\n\n**Output:**\n```json\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"parameter_validation\": {{\n    \"validated_parameters\": [\n      \"proxy_buffer_size: 32k (valid)\",\n      \"proxy_buffers: 4 32k (valid)\",\n      \"large_client_header_buffers: 4 32k (valid)\"\n    ],\n    \"invalid_parameters\": [],\n    \"warnings\": [],\n    \"recommendations\": [\"Consider setting proxy_busy_buffers_size for buffer consistency\"]\n  }},\n  \"ready_for_next_agent\": true\n}}\n```\n\n---\n\n## 🚫 ANTI-PATTERNS (DO NOT DO THIS!)\n\n### ❌ Bug 1: Ignoring locations array\n\n```\nInput: {{\"location\": null, \"locations\": [\"/api\", \"/v2\"]}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"location: required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n}}\n```\n\n### ❌ Bug 2: Not parsing upstreams\n\n```\nInput: {{\n  \"upstreams\": [\n    {{\"upstream_type\": \"main\", \"ip_addresses\": [\"10.0.0.1:80\"]}}\n  ]\n}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"upstreams: required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n}}\n```\n\n### ❌ Bug 3: Warnings blocking completion\n\n```\nInput: upstreams with same IPs in main/backup\n\nWRONG output:\n{{\n  \"missing_fields\": [\"upstreams: should have different IPs\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"warnings\": [\"Same IPs in main/backup\"],\n  \"validation_status\": \"COMPLETE\"\n}}\n```\n\n### ❌ Bug 4: Wrong fields for MODIFY_LOCATION_PATH\n\n```\nInput: {{\n  \"operation\": \"MODIFY_LOCATION_PATH\",\n  \"location\": null,\n  \"from_location\": \"/old\",\n  \"to_location\": \"/new\"\n}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"location: required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n}}\n```\n\n### ❌ Bug 5: Ignoring domains array\n\n```\nInput: {{\"domain\": null, \"domains\": [\"aip.mos.ru\", \"dchelper.mos.ru\"]}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"domain: No domain or domains specified\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n}}\n```\n\n### ❌ Bug 6: Requiring location for server_block operations\n\n```\nInput: {{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"location\": null,\n  \"locations\": [],\n  \"server_block_parameters\": [\"gzip:on\"]\n}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"location: required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n  // server_block_parameters means server-level, no location needed\n}}\n```\n\n---\n\n## 📊 OUTPUT SCHEMA\n\n```json\n{{\n  \"validation_status\": \"COMPLETE | INCOMPLETE | HIGH_RISK\",\n  \"data_complete\": true | false,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"parameter_validation\": {{\n    \"validated_parameters\": [],\n    \"invalid_parameters\": [],\n    \"warnings\": [],\n    \"recommendations\": []\n  }},\n  \"kms_rules\": {{\n    \"locations_need_kms\": [],\n    \"locations_public\": [],\n    \"note\": null\n  }},\n  \"upstream_validation\": {{\n    \"valid_upstreams\": [],\n    \"invalid_upstreams\": [],\n    \"warnings\": []\n  }},\n  \"risk_assessment\": {{\n    \"risk_level\": \"low | medium | high\",\n    \"risk_factors\": [],\n    \"warnings\": [],\n    \"requires_confirmation\": false\n  }},\n  \"cross_referenced\": {{\n    \"applied\": false,\n    \"note\": null,\n    \"inherited_fields\": []\n  }},\n  \"ready_for_next_agent\": true | false,\n  \"validation_summary\": {{\n    \"total_parameters\": 0,\n    \"valid_parameters\": 0,\n    \"invalid_parameters\": 0,\n    \"skipped_parameters\": 0\n  }}\n}}\n```\n\n---\n\n## 🧠 MANDATORY REASONING PROCESS\n\nBefore outputting JSON, think step by step:\n\n```\n<thinking>\n1. PARSE INPUT\n   - Operation: [operation]\n   - Domain present? [check domain AND domains]\n   - Location present? [check location AND locations]\n   - From/to location? [for MODIFY_LOCATION_PATH]\n   - Upstreams present? [check array contents]\n   - Parameters present? [check all param fields]\n\n2. DETERMINE REQUIRED FIELDS\n   - For [operation], required fields are: [list]\n   - Checking each:\n     - Field X: [present/missing]\n     - Field Y: [present/missing]\n\n3. VALIDATE SYNTAX (if parameters present)\n   - Parameter A: [valid/invalid]\n   - Parameter B: [valid/invalid]\n\n4. IDENTIFY WARNINGS (do not block completion!)\n   - [list any warnings]\n\n5. DETERMINE STATUS\n   - Missing fields: [count]\n   - Syntax errors: [count]\n   - High risk: [yes/no]\n   - Final status: [COMPLETE/INCOMPLETE/HIGH_RISK]\n\n6. SET READY FLAG\n   - Status is COMPLETE? [yes/no]\n   - ready_for_next_agent: [true/false]\n</thinking>\n```\n\n---\n\n## ❗ CRITICAL RULES\n\n1. **ALWAYS check both `domain` AND `domains`** — either one being present is valid\n2. **ALWAYS check both `location` AND `locations`** — either one being present is valid\n3. **ALWAYS parse `upstreams` array contents** — check ip_addresses inside\n4. **NEVER treat warnings as missing fields** — warnings don't block COMPLETE\n5. **For MODIFY_LOCATION_PATH** — check from_location/to_location, NOT location/locations\n6. **For server_block_parameters** — location NOT required when operating at server level\n7. **Skip proxy_pass validation** — always mark as valid\n8. **Consistency check** — if missing_fields is empty, status should be COMPLETE\n\n---\n\n## NOW VALIDATE\n\n**AGENT 1 OUTPUT:**\n{agent1_json}\n\n**ORIGINAL REQUEST:**\n{original_question}\n\n---\n\n**Output ONLY valid JSON:**\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-Rdv1k",
        "measured": {
          "height": 441,
          "width": 320
        },
        "position": {
          "x": 385.6229360719941,
          "y": 54.93943366384599
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-8YDEh",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/components-io#chat-input",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatInput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        # Ensure files is a list and filter out empty/None values\n        files = self.files if self.files else []\n        if files and not isinstance(files, list):\n            files = [files]\n        files = [f for f in files if f is not None and f != \"\"]\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=files,\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-8YDEh",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": -1155.820142756474,
          "y": 620.8304655750491
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-wTPA0",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": false,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "last_updated": "2025-11-23T11:38:59.625Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "group_outputs": true,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "group_outputs": true,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"starts with\",\n                \"ends with\",\n                \"regex\",\n                \"less than\",\n                \"less than or equal\",\n                \"greater than\",\n                \"greater than or equal\",\n            ],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"true_case_message\",\n            display_name=\"Case True\",\n            info=\"The message to pass if the condition is True.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"false_case_message\",\n            display_name=\"Case False\",\n            info=\"The message to pass if the condition is False.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n            try:\n                input_num = float(input_text)\n                match_num = float(match_text)\n                if operator == \"less than\":\n                    return input_num < match_num\n                if operator == \"less than or equal\":\n                    return input_num <= match_num\n                if operator == \"greater than\":\n                    return input_num > match_num\n                if operator == \"greater than or equal\":\n                    return input_num >= match_num\n            except ValueError:\n                return False  # Invalid number format for comparison\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        \"\"\"Handles cycle iteration counting and branch exclusion.\n\n        Uses two complementary mechanisms:\n        1. stop() - ACTIVE/INACTIVE state for cycle management (gets reset each iteration)\n        2. exclude_branch_conditionally() - Persistent exclusion for conditional routing\n\n        When max_iterations is reached, breaks the cycle by allowing the default_route to execute.\n        \"\"\"\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n\n            # Check if max iterations reached and we're trying to stop the default route\n            if current_iteration >= self.max_iterations and route_to_stop == self.default_route:\n                # Clear ALL conditional exclusions to allow default route to execute\n                if self._id in self.graph.conditional_exclusion_sources:\n                    previous_exclusions = self.graph.conditional_exclusion_sources[self._id]\n                    self.graph.conditionally_excluded_vertices -= previous_exclusions\n                    del self.graph.conditional_exclusion_sources[self._id]\n\n                # Switch which route to stop - stop the NON-default route to break the cycle\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n\n                # Call stop to break the cycle\n                self.stop(route_to_stop)\n                # Don't apply conditional exclusion when breaking cycle\n                return\n\n            # Normal case: Use BOTH mechanisms\n            # 1. stop() for cycle management (marks INACTIVE, updates run manager, gets reset)\n            self.stop(route_to_stop)\n\n            # 2. Conditional exclusion for persistent routing (doesn't get reset except by this router)\n            self.graph.exclude_branch_conditionally(self._id, output_name=route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        # Check if we should force output due to max_iterations on default route\n        current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n        force_output = current_iteration >= self.max_iterations and self.default_route == \"true_result\"\n\n        if result or force_output:\n            self.status = self.true_case_message\n            if not force_output:  # Only stop the other branch if not forcing due to max iterations\n                self.iterate_and_stop_once(\"false_result\")\n            return self.true_case_message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        if not result:\n            self.status = self.false_case_message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.false_case_message\n\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "external_options": {},
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "'status': 'SUCCESS'"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "external_options": {},
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "contains"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-wTPA0",
        "measured": {
          "height": 509,
          "width": 320
        },
        "position": {
          "x": 2393.791064298566,
          "y": -45.705763305825286
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-DtGOq",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007216440637271487,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-DtGOq",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 1169.626242073545,
          "y": 581.0801810886725
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-6icsL",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007216440637271487,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-6icsL",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": -44.5100834142543,
          "y": 588.6976909240258
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SubFlow-g84sW",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates a Component from a Flow, with all of its inputs, and ",
            "display_name": "Sub Flow",
            "documentation": "",
            "edited": false,
            "field_order": [
              "flow_name"
            ],
            "frozen": false,
            "icon": "Workflow",
            "key": "SubFlow",
            "last_updated": "2025-11-30T06:32:26.153Z",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Outputs",
                "group_outputs": false,
                "method": "generate_results",
                "name": "flow_outputs",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "logic.RunFlow"
            ],
            "score": 0.10272033187433852,
            "template": {
              "TextInput-6bdk9|input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text Input - Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "TextInput-6bdk9|input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.base.flow_processing.utils import build_data_from_result_data\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.graph.graph.base import Graph\nfrom langflow.graph.vertex.base import Vertex\nfrom langflow.helpers.flow import get_flow_inputs\nfrom langflow.io import DropdownInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.data import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass SubFlowComponent(Component):\n    display_name = \"Sub Flow\"\n    description = \"Generates a Component from a Flow, with all of its inputs, and \"\n    name = \"SubFlow\"\n    legacy: bool = True\n    replacement = [\"logic.RunFlow\"]\n    icon = \"Workflow\"\n\n    async def get_flow_names(self) -> list[str]:\n        flow_data = await self.alist_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_data]\n\n    async def get_flow(self, flow_name: str) -> Data | None:\n        flow_datas = await self.alist_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = await self.get_flow_names()\n\n        for key in list(build_config.keys()):\n            if key not in [x.name for x in self.inputs] + [\"code\", \"_type\", \"get_final_results_only\"]:\n                del build_config[key]\n        if field_value is not None and field_name == \"flow_name\":\n            try:\n                flow_data = await self.get_flow(field_value)\n            except Exception:  # noqa: BLE001\n                await logger.aexception(f\"Error getting flow {field_value}\")\n            else:\n                if not flow_data:\n                    msg = f\"Flow {field_value} not found.\"\n                    await logger.aerror(msg)\n                else:\n                    try:\n                        graph = Graph.from_payload(flow_data.data[\"data\"])\n                        # Get all inputs from the graph\n                        inputs = get_flow_inputs(graph)\n                        # Add inputs to the build config\n                        build_config = self.add_inputs_to_build_config(inputs, build_config)\n                    except Exception:  # noqa: BLE001\n                        await logger.aexception(f\"Error building graph for flow {field_value}\")\n\n        return build_config\n\n    def add_inputs_to_build_config(self, inputs_vertex: list[Vertex], build_config: dotdict):\n        new_fields: list[dotdict] = []\n\n        for vertex in inputs_vertex:\n            new_vertex_inputs = []\n            field_template = vertex.data[\"node\"][\"template\"]\n            for inp in field_template:\n                if inp not in {\"code\", \"_type\"}:\n                    field_template[inp][\"display_name\"] = (\n                        vertex.display_name + \" - \" + field_template[inp][\"display_name\"]\n                    )\n                    field_template[inp][\"name\"] = vertex.id + \"|\" + inp\n                    new_vertex_inputs.append(field_template[inp])\n            new_fields += new_vertex_inputs\n        for field in new_fields:\n            build_config[field[\"name\"]] = field\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\",\n            display_name=\"Flow Name\",\n            info=\"The name of the flow to run.\",\n            options=[],\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"flow_outputs\", display_name=\"Flow Outputs\", method=\"generate_results\")]\n\n    async def generate_results(self) -> list[Data]:\n        tweaks: dict = {}\n        for field in self._attributes:\n            if field != \"flow_name\" and \"|\" in field:\n                [node, name] = field.split(\"|\")\n                if node not in tweaks:\n                    tweaks[node] = {}\n                tweaks[node][name] = self._attributes[field]\n        flow_name = self._attributes.get(\"flow_name\")\n        run_outputs = await self.run_flow(\n            tweaks=tweaks,\n            flow_name=flow_name,\n            output_type=\"all\",\n        )\n        data: list[Data] = []\n        if not run_outputs:\n            return data\n        run_output = run_outputs[0]\n\n        if run_output is not None:\n            for output in run_output.outputs:\n                if output:\n                    data.extend(build_data_from_result_data(output))\n        return data\n"
              },
              "flow_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Flow Name",
                "dynamic": false,
                "external_options": {},
                "info": "The name of the flow to run.",
                "name": "flow_name",
                "options": [
                  "New Flow",
                  "New Flow (1)",
                  "nginx configuration_v2",
                  "New Flow (2)",
                  "NGINX Configuration Parsing Subflow",
                  "YAML Processing Subflow Locations",
                  "YAML Processing Subflow Upstreams"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "YAML Processing Subflow Locations"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SubFlow"
        },
        "dragging": false,
        "id": "SubFlow-g84sW",
        "measured": {
          "height": 380,
          "width": 320
        },
        "position": {
          "x": 3396.730012514587,
          "y": -68.19982165139018
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-19Hx2",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003169567463043492,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-19Hx2",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 4018.913363011257,
          "y": 352.56393878501797
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-ZiUsZ",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Проверяет validation_status от Agent2 и возвращает JSON от Agent1 если COMPLETE",
            "display_name": "JSON Arbitrator",
            "documentation": "",
            "edited": true,
            "field_order": [
              "agent1_output",
              "agent2_output"
            ],
            "frozen": false,
            "icon": "check-circle",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result",
                "group_outputs": false,
                "hidden": null,
                "method": "process",
                "name": "result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Needs Clarification",
                "group_outputs": false,
                "hidden": null,
                "method": "get_clarification",
                "name": "needs_clarification",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent1_output": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Agent 1 Output",
                "dynamic": false,
                "info": "JSON от первого агента (парсер)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "agent1_output",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "agent2_output": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Agent 2 Output",
                "dynamic": false,
                "info": "JSON от второго агента (валидатор)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "agent2_output",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.data import Data\nimport json\n\n\nclass ArbitratorComponent(Component):\n    display_name = \"JSON Arbitrator\"\n    description = \"Проверяет validation_status от Agent2 и возвращает JSON от Agent1 если COMPLETE\"\n    icon = \"check-circle\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"agent1_output\",\n            display_name=\"Agent 1 Output\",\n            info=\"JSON от первого агента (парсер)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"agent2_output\",\n            display_name=\"Agent 2 Output\",\n            info=\"JSON от второго агента (валидатор)\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Result\",\n            name=\"result\",\n            method=\"process\",\n        ),\n        Output(\n            display_name=\"Needs Clarification\",\n            name=\"needs_clarification\",\n            method=\"get_clarification\",\n        ),\n    ]\n\n    def _parse_json(self, text: str) -> dict:\n        \"\"\"Парсит JSON, убирая markdown обёртки если есть\"\"\"\n        text = text.strip()\n        # Убираем ```json ... ``` если есть\n        if text.startswith(\"```\"):\n            lines = text.split(\"\\n\")\n            # Убираем первую и последнюю строку с ```\n            lines = [l for l in lines if not l.strip().startswith(\"```\")]\n            text = \"\\n\".join(lines)\n        return json.loads(text)\n\n    def _is_valid(self, agent2_data: dict) -> bool:\n        \"\"\"Проверяет статус валидации\"\"\"\n        status = agent2_data.get(\"validation_status\", \"\").upper()\n        return status == \"COMPLETE\"\n\n    def process(self) -> Data:\n        \"\"\"Основной выход — возвращает agent1 если валидация прошла\"\"\"\n        try:\n            agent1_data = self._parse_json(self.agent1_output)\n            agent2_data = self._parse_json(self.agent2_output)\n\n            if self._is_valid(agent2_data):\n                return Data(data={\n                    \"status\": \"SUCCESS\",\n                    \"payload\": agent1_data,\n                    \"ready_for_execution\": True\n                })\n            else:\n                return Data(data={\n                    \"status\": \"VALIDATION_FAILED\",\n                    \"payload\": None,\n                    \"ready_for_execution\": False,\n                    \"missing_fields\": agent2_data.get(\"missing_fields\", []),\n                    \"clarification_questions\": agent2_data.get(\"clarification_questions\", [])\n                })\n\n        except json.JSONDecodeError as e:\n            return Data(data={\n                \"status\": \"PARSE_ERROR\",\n                \"error\": str(e),\n                \"ready_for_execution\": False\n            })\n\n    def get_clarification(self) -> Data:\n        \"\"\"Второй выход — вопросы для уточнения если нужны\"\"\"\n        try:\n            agent2_data = self._parse_json(self.agent2_output)\n\n            if not self._is_valid(agent2_data):\n                questions = agent2_data.get(\"clarification_questions\", [])\n                missing = agent2_data.get(\"missing_fields\", [])\n                \n                return Data(data={\n                    \"needs_clarification\": True,\n                    \"questions\": questions,\n                    \"missing_fields\": missing,\n                    \"message\": self._format_clarification_message(questions, missing)\n                })\n            else:\n                return Data(data={\n                    \"needs_clarification\": False,\n                    \"questions\": [],\n                    \"missing_fields\": [],\n                    \"message\": None\n                })\n\n        except json.JSONDecodeError:\n            return Data(data={\n                \"needs_clarification\": True,\n                \"questions\": [],\n                \"missing_fields\": [],\n                \"message\": \"Ошибка парсинга JSON от агентов\"\n            })\n\n    def _format_clarification_message(self, questions: list, missing: list) -> str:\n        \"\"\"Форматирует сообщение для пользователя\"\"\"\n        parts = []\n        \n        if missing:\n            parts.append(\"Не хватает данных:\")\n            for field in missing:\n                parts.append(f\"  • {field}\")\n        \n        if questions:\n            parts.append(\"\\nУточняющие вопросы:\")\n            for q in questions:\n                parts.append(f\"  • {q}\")\n        \n        return \"\\n\".join(parts) if parts else \"Требуется уточнение запроса\""
              }
            },
            "tool_mode": false
          },
          "selected_output": "result",
          "showNode": true,
          "type": "ArbitratorComponent"
        },
        "dragging": false,
        "id": "CustomComponent-ZiUsZ",
        "measured": {
          "height": 301,
          "width": 320
        },
        "position": {
          "x": 1515.4637447364557,
          "y": -66.4796612170395
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-oAHHN",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "key": "TypeConverterComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message Output",
                "group_outputs": false,
                "method": "convert_to_message",
                "name": "message_output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.008834292878014125,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Message"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-oAHHN",
        "measured": {
          "height": 261,
          "width": 320
        },
        "position": {
          "x": 1943.1174882359091,
          "y": -51.25604215070524
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-ljKLx",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": false,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "last_updated": "2025-11-30T12:21:17.327Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "group_outputs": true,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "group_outputs": true,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"starts with\",\n                \"ends with\",\n                \"regex\",\n                \"less than\",\n                \"less than or equal\",\n                \"greater than\",\n                \"greater than or equal\",\n            ],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"true_case_message\",\n            display_name=\"Case True\",\n            info=\"The message to pass if the condition is True.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"false_case_message\",\n            display_name=\"Case False\",\n            info=\"The message to pass if the condition is False.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n            try:\n                input_num = float(input_text)\n                match_num = float(match_text)\n                if operator == \"less than\":\n                    return input_num < match_num\n                if operator == \"less than or equal\":\n                    return input_num <= match_num\n                if operator == \"greater than\":\n                    return input_num > match_num\n                if operator == \"greater than or equal\":\n                    return input_num >= match_num\n            except ValueError:\n                return False  # Invalid number format for comparison\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        \"\"\"Handles cycle iteration counting and branch exclusion.\n\n        Uses two complementary mechanisms:\n        1. stop() - ACTIVE/INACTIVE state for cycle management (gets reset each iteration)\n        2. exclude_branch_conditionally() - Persistent exclusion for conditional routing\n\n        When max_iterations is reached, breaks the cycle by allowing the default_route to execute.\n        \"\"\"\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n\n            # Check if max iterations reached and we're trying to stop the default route\n            if current_iteration >= self.max_iterations and route_to_stop == self.default_route:\n                # Clear ALL conditional exclusions to allow default route to execute\n                if self._id in self.graph.conditional_exclusion_sources:\n                    previous_exclusions = self.graph.conditional_exclusion_sources[self._id]\n                    self.graph.conditionally_excluded_vertices -= previous_exclusions\n                    del self.graph.conditional_exclusion_sources[self._id]\n\n                # Switch which route to stop - stop the NON-default route to break the cycle\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n\n                # Call stop to break the cycle\n                self.stop(route_to_stop)\n                # Don't apply conditional exclusion when breaking cycle\n                return\n\n            # Normal case: Use BOTH mechanisms\n            # 1. stop() for cycle management (marks INACTIVE, updates run manager, gets reset)\n            self.stop(route_to_stop)\n\n            # 2. Conditional exclusion for persistent routing (doesn't get reset except by this router)\n            self.graph.exclude_branch_conditionally(self._id, output_name=route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        # Check if we should force output due to max_iterations on default route\n        current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n        force_output = current_iteration >= self.max_iterations and self.default_route == \"true_result\"\n\n        if result or force_output:\n            self.status = self.true_case_message\n            if not force_output:  # Only stop the other branch if not forcing due to max iterations\n                self.iterate_and_stop_once(\"false_result\")\n            return self.true_case_message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        if not result:\n            self.status = self.false_case_message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.false_case_message\n\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "external_options": {},
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".*(ADD_PARAMETERS|MODIFY_PARAMETERS|DELETE_PARAMETERS|DELETE_LOCATION|CREATE_LOCATION|MODIFY_LOCATION_PATH|MAKE_PROTECTED|MAKE_PUBLIC).*"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "external_options": {},
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "regex"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-ljKLx",
        "measured": {
          "height": 509,
          "width": 320
        },
        "position": {
          "x": 2990.468580536074,
          "y": -99.1977493166253
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-oIxzF",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": false,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "last_updated": "2025-11-30T12:02:50.362Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "group_outputs": true,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "group_outputs": true,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"starts with\",\n                \"ends with\",\n                \"regex\",\n                \"less than\",\n                \"less than or equal\",\n                \"greater than\",\n                \"greater than or equal\",\n            ],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"true_case_message\",\n            display_name=\"Case True\",\n            info=\"The message to pass if the condition is True.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"false_case_message\",\n            display_name=\"Case False\",\n            info=\"The message to pass if the condition is False.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n            try:\n                input_num = float(input_text)\n                match_num = float(match_text)\n                if operator == \"less than\":\n                    return input_num < match_num\n                if operator == \"less than or equal\":\n                    return input_num <= match_num\n                if operator == \"greater than\":\n                    return input_num > match_num\n                if operator == \"greater than or equal\":\n                    return input_num >= match_num\n            except ValueError:\n                return False  # Invalid number format for comparison\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        \"\"\"Handles cycle iteration counting and branch exclusion.\n\n        Uses two complementary mechanisms:\n        1. stop() - ACTIVE/INACTIVE state for cycle management (gets reset each iteration)\n        2. exclude_branch_conditionally() - Persistent exclusion for conditional routing\n\n        When max_iterations is reached, breaks the cycle by allowing the default_route to execute.\n        \"\"\"\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n\n            # Check if max iterations reached and we're trying to stop the default route\n            if current_iteration >= self.max_iterations and route_to_stop == self.default_route:\n                # Clear ALL conditional exclusions to allow default route to execute\n                if self._id in self.graph.conditional_exclusion_sources:\n                    previous_exclusions = self.graph.conditional_exclusion_sources[self._id]\n                    self.graph.conditionally_excluded_vertices -= previous_exclusions\n                    del self.graph.conditional_exclusion_sources[self._id]\n\n                # Switch which route to stop - stop the NON-default route to break the cycle\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n\n                # Call stop to break the cycle\n                self.stop(route_to_stop)\n                # Don't apply conditional exclusion when breaking cycle\n                return\n\n            # Normal case: Use BOTH mechanisms\n            # 1. stop() for cycle management (marks INACTIVE, updates run manager, gets reset)\n            self.stop(route_to_stop)\n\n            # 2. Conditional exclusion for persistent routing (doesn't get reset except by this router)\n            self.graph.exclude_branch_conditionally(self._id, output_name=route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        # Check if we should force output due to max_iterations on default route\n        current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n        force_output = current_iteration >= self.max_iterations and self.default_route == \"true_result\"\n\n        if result or force_output:\n            self.status = self.true_case_message\n            if not force_output:  # Only stop the other branch if not forcing due to max iterations\n                self.iterate_and_stop_once(\"false_result\")\n            return self.true_case_message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        if not result:\n            self.status = self.false_case_message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.false_case_message\n\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "external_options": {},
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".*(CREATE_LOCATION|MODIFY_UPSTREAM|DELETE_LOCATION).*"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "external_options": {},
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "regex"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-oIxzF",
        "measured": {
          "height": 509,
          "width": 320
        },
        "position": {
          "x": 2985.6890366161933,
          "y": 651.4728894768728
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SubFlow-2Mns3",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates a Component from a Flow, with all of its inputs, and ",
            "display_name": "Sub Flow",
            "documentation": "",
            "edited": false,
            "field_order": [
              "flow_name"
            ],
            "frozen": false,
            "icon": "Workflow",
            "key": "SubFlow",
            "last_updated": "2025-11-30T11:51:57.570Z",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Flow Outputs",
                "group_outputs": false,
                "method": "generate_results",
                "name": "flow_outputs",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "logic.RunFlow"
            ],
            "score": 0.10272033187433852,
            "template": {
              "TextInput-EfRPK|input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text Input - Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "TextInput-EfRPK|input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.base.flow_processing.utils import build_data_from_result_data\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.graph.graph.base import Graph\nfrom langflow.graph.vertex.base import Vertex\nfrom langflow.helpers.flow import get_flow_inputs\nfrom langflow.io import DropdownInput, Output\nfrom langflow.logging.logger import logger\nfrom langflow.schema.data import Data\nfrom langflow.schema.dotdict import dotdict\n\n\nclass SubFlowComponent(Component):\n    display_name = \"Sub Flow\"\n    description = \"Generates a Component from a Flow, with all of its inputs, and \"\n    name = \"SubFlow\"\n    legacy: bool = True\n    replacement = [\"logic.RunFlow\"]\n    icon = \"Workflow\"\n\n    async def get_flow_names(self) -> list[str]:\n        flow_data = await self.alist_flows()\n        return [flow_data.data[\"name\"] for flow_data in flow_data]\n\n    async def get_flow(self, flow_name: str) -> Data | None:\n        flow_datas = await self.alist_flows()\n        for flow_data in flow_datas:\n            if flow_data.data[\"name\"] == flow_name:\n                return flow_data\n        return None\n\n    async def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name == \"flow_name\":\n            build_config[\"flow_name\"][\"options\"] = await self.get_flow_names()\n\n        for key in list(build_config.keys()):\n            if key not in [x.name for x in self.inputs] + [\"code\", \"_type\", \"get_final_results_only\"]:\n                del build_config[key]\n        if field_value is not None and field_name == \"flow_name\":\n            try:\n                flow_data = await self.get_flow(field_value)\n            except Exception:  # noqa: BLE001\n                await logger.aexception(f\"Error getting flow {field_value}\")\n            else:\n                if not flow_data:\n                    msg = f\"Flow {field_value} not found.\"\n                    await logger.aerror(msg)\n                else:\n                    try:\n                        graph = Graph.from_payload(flow_data.data[\"data\"])\n                        # Get all inputs from the graph\n                        inputs = get_flow_inputs(graph)\n                        # Add inputs to the build config\n                        build_config = self.add_inputs_to_build_config(inputs, build_config)\n                    except Exception:  # noqa: BLE001\n                        await logger.aexception(f\"Error building graph for flow {field_value}\")\n\n        return build_config\n\n    def add_inputs_to_build_config(self, inputs_vertex: list[Vertex], build_config: dotdict):\n        new_fields: list[dotdict] = []\n\n        for vertex in inputs_vertex:\n            new_vertex_inputs = []\n            field_template = vertex.data[\"node\"][\"template\"]\n            for inp in field_template:\n                if inp not in {\"code\", \"_type\"}:\n                    field_template[inp][\"display_name\"] = (\n                        vertex.display_name + \" - \" + field_template[inp][\"display_name\"]\n                    )\n                    field_template[inp][\"name\"] = vertex.id + \"|\" + inp\n                    new_vertex_inputs.append(field_template[inp])\n            new_fields += new_vertex_inputs\n        for field in new_fields:\n            build_config[field[\"name\"]] = field\n        return build_config\n\n    inputs = [\n        DropdownInput(\n            name=\"flow_name\",\n            display_name=\"Flow Name\",\n            info=\"The name of the flow to run.\",\n            options=[],\n            refresh_button=True,\n            real_time_refresh=True,\n        ),\n    ]\n\n    outputs = [Output(name=\"flow_outputs\", display_name=\"Flow Outputs\", method=\"generate_results\")]\n\n    async def generate_results(self) -> list[Data]:\n        tweaks: dict = {}\n        for field in self._attributes:\n            if field != \"flow_name\" and \"|\" in field:\n                [node, name] = field.split(\"|\")\n                if node not in tweaks:\n                    tweaks[node] = {}\n                tweaks[node][name] = self._attributes[field]\n        flow_name = self._attributes.get(\"flow_name\")\n        run_outputs = await self.run_flow(\n            tweaks=tweaks,\n            flow_name=flow_name,\n            output_type=\"all\",\n        )\n        data: list[Data] = []\n        if not run_outputs:\n            return data\n        run_output = run_outputs[0]\n\n        if run_output is not None:\n            for output in run_output.outputs:\n                if output:\n                    data.extend(build_data_from_result_data(output))\n        return data\n"
              },
              "flow_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Flow Name",
                "dynamic": false,
                "external_options": {},
                "info": "The name of the flow to run.",
                "name": "flow_name",
                "options": [
                  "New Flow",
                  "New Flow (1)",
                  "nginx configuration_v2",
                  "New Flow (2)",
                  "NGINX Configuration Parsing Subflow",
                  "YAML Processing Subflow Locations",
                  "YAML Processing Subflow Upstreams"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "YAML Processing Subflow Upstreams"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SubFlow"
        },
        "dragging": false,
        "id": "SubFlow-2Mns3",
        "measured": {
          "height": 380,
          "width": 320
        },
        "position": {
          "x": 3377.8364167014697,
          "y": 698.2128550275747
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-RjYqU",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003169567463043492,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-RjYqU",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 4031.3665698131026,
          "y": 1073.5413966931917
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 316.5566966179214,
      "y": 323.92232362619893,
      "zoom": 0.25
    }
  },
  "description": "Expert, Validator, Arbitr",
  "endpoint_name": null,
  "id": "9b3ab1a8-dd1f-4b36-a8e8-3635c79c023c",
  "is_component": false,
  "last_tested_version": "1.6.0",
  "name": "NGINX Configuration Parsing Subflow",
  "tags": []
}