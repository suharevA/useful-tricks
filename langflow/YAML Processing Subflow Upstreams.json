{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-4CHsH",
            "name": "item",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-eGILW",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__LoopComponent-4CHsH{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-4CHsHœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}-ParserComponent-eGILW{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-eGILWœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopComponent-4CHsH",
        "sourceHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-4CHsHœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-eGILW",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-eGILWœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-eGILW",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "upstreams",
            "id": "Prompt Template-Tj3jj",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-eGILW{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-eGILWœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-Tj3jj{œfieldNameœ:œupstreamsœ,œidœ:œPrompt Template-Tj3jjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-eGILW",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-eGILWœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-Tj3jj",
        "targetHandle": "{œfieldNameœ:œupstreamsœ,œidœ:œPrompt Template-Tj3jjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-Tj3jj",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-mYcwF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-Tj3jj{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-Tj3jjœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-mYcwF{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-mYcwFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-Tj3jj",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-Tj3jjœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-mYcwF",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-mYcwFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-mYcwF",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "TypeConverterComponent-D3L0W",
            "inputTypes": [
              "Message",
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-mYcwF{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-mYcwFœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TypeConverterComponent-D3L0W{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-D3L0Wœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-mYcwF",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-mYcwFœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TypeConverterComponent-D3L0W",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-D3L0Wœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TypeConverterComponent",
            "id": "TypeConverterComponent-D3L0W",
            "name": "data_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-4CHsH",
            "name": "item",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__TypeConverterComponent-D3L0W{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-D3L0Wœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}-LoopComponent-4CHsH{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-4CHsHœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "selected": false,
        "source": "TypeConverterComponent-D3L0W",
        "sourceHandle": "{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-D3L0Wœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "LoopComponent-4CHsH",
        "targetHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-4CHsHœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-4CHsH",
            "name": "done",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-70UEC",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__LoopComponent-4CHsH{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-4CHsHœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-70UEC{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-70UECœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopComponent-4CHsH",
        "sourceHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-4CHsHœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-70UEC",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-70UECœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-70UEC",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-X3c1r",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParserComponent-70UEC{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-70UECœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-X3c1r{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-X3c1rœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParserComponent-70UEC",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-70UECœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-X3c1r",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-X3c1rœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UniversalSearchConfigComponent",
            "id": "UniversalSearchConfigComponent-3wswc",
            "name": "config_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "config_data",
            "id": "UpstreamExtractorComponent-rkDhh",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UniversalSearchConfigComponent-3wswc{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-3wswcœ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}-UpstreamExtractorComponent-rkDhh{œfieldNameœ:œconfig_dataœ,œidœ:œUpstreamExtractorComponent-rkDhhœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UniversalSearchConfigComponent-3wswc",
        "sourceHandle": "{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-3wswcœ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "UpstreamExtractorComponent-rkDhh",
        "targetHandle": "{œfieldNameœ:œconfig_dataœ,œidœ:œUpstreamExtractorComponent-rkDhhœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-EfRPK",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_json",
            "id": "UniversalSearchConfigComponent-3wswc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-EfRPK{œdataTypeœ:œTextInputœ,œidœ:œTextInput-EfRPKœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-UniversalSearchConfigComponent-3wswc{œfieldNameœ:œagent1_jsonœ,œidœ:œUniversalSearchConfigComponent-3wswcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-EfRPK",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-EfRPKœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "UniversalSearchConfigComponent-3wswc",
        "targetHandle": "{œfieldNameœ:œagent1_jsonœ,œidœ:œUniversalSearchConfigComponent-3wswcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UpstreamExtractorComponent",
            "id": "UpstreamExtractorComponent-rkDhh",
            "name": "upstream_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "selected_block",
            "id": "UpstreamConfigBlockSplitter-RP41F",
            "inputTypes": [
              "Message",
              "Data",
              "dict"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UpstreamExtractorComponent-rkDhh{œdataTypeœ:œUpstreamExtractorComponentœ,œidœ:œUpstreamExtractorComponent-rkDhhœ,œnameœ:œupstream_dataœ,œoutput_typesœ:[œDataœ]}-UpstreamConfigBlockSplitter-RP41F{œfieldNameœ:œselected_blockœ,œidœ:œUpstreamConfigBlockSplitter-RP41Fœ,œinputTypesœ:[œMessageœ,œDataœ,œdictœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UpstreamExtractorComponent-rkDhh",
        "sourceHandle": "{œdataTypeœ:œUpstreamExtractorComponentœ,œidœ:œUpstreamExtractorComponent-rkDhhœ,œnameœ:œupstream_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "UpstreamConfigBlockSplitter-RP41F",
        "targetHandle": "{œfieldNameœ:œselected_blockœ,œidœ:œUpstreamConfigBlockSplitter-RP41Fœ,œinputTypesœ:[œMessageœ,œDataœ,œdictœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UpstreamConfigBlockSplitter",
            "id": "UpstreamConfigBlockSplitter-RP41F",
            "name": "config_items_df",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "LoopComponent-4CHsH",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UpstreamConfigBlockSplitter-RP41F{œdataTypeœ:œUpstreamConfigBlockSplitterœ,œidœ:œUpstreamConfigBlockSplitter-RP41Fœ,œnameœ:œconfig_items_dfœ,œoutput_typesœ:[œDataFrameœ]}-LoopComponent-4CHsH{œfieldNameœ:œdataœ,œidœ:œLoopComponent-4CHsHœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UpstreamConfigBlockSplitter-RP41F",
        "sourceHandle": "{œdataTypeœ:œUpstreamConfigBlockSplitterœ,œidœ:œUpstreamConfigBlockSplitter-RP41Fœ,œnameœ:œconfig_items_dfœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "LoopComponent-4CHsH",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œLoopComponent-4CHsHœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-vfp3E",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Ciqh9",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParserComponent-vfp3E{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-vfp3Eœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Ciqh9{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Ciqh9œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParserComponent-vfp3E",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-vfp3Eœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-Ciqh9",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Ciqh9œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-eGILW",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_data",
            "id": "Prompt Template-Tj3jj",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-eGILW{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-eGILWœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-Tj3jj{œfieldNameœ:œagent1_dataœ,œidœ:œPrompt Template-Tj3jjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-eGILW",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-eGILWœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-Tj3jj",
        "targetHandle": "{œfieldNameœ:œagent1_dataœ,œidœ:œPrompt Template-Tj3jjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UniversalSearchConfigComponent",
            "id": "UniversalSearchConfigComponent-3wswc",
            "name": "config_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-vfp3E",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UniversalSearchConfigComponent-3wswc{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-3wswcœ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}-ParserComponent-vfp3E{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-vfp3Eœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UniversalSearchConfigComponent-3wswc",
        "sourceHandle": "{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-3wswcœ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-vfp3E",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-vfp3Eœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-eGILW",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "operation",
            "id": "Prompt Template-Tj3jj",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-eGILW{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-eGILWœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-Tj3jj{œfieldNameœ:œoperationœ,œidœ:œPrompt Template-Tj3jjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-eGILW",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-eGILWœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-Tj3jj",
        "targetHandle": "{œfieldNameœ:œoperationœ,œidœ:œPrompt Template-Tj3jjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "Prompt Template-Tj3jj",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "operation",
                "agent1_data",
                "upstreams"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "agent1_data": {
                "advanced": false,
                "display_name": "agent1_data",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent1_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "operation": {
                "advanced": false,
                "display_name": "operation",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "operation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# NGINX Upstream Configuration Agent v5.0 (Optimized for Qwen)\n\nYou are an nginx upstream configuration expert. Process upstream configs in JSON format.\n\n## ERROR CHECK (DO FIRST)\n\nIf ANY condition is true, return error JSON and STOP:\n- `agent1_data` is \"None\" or missing\n- `upstreams` is \"None\" or missing (except CREATE_LOCATION)\n\n```json\n{{\n  \"status\": \"error\",\n  \"operation_type\": \"NONE\",\n  \"error_type\": \"PREREQUISITE_ERROR\",\n  \"error_message\": \"Missing required data\",\n  \"ready_to_save\": false\n}}\n```\n\n## INPUTS\n\n- `{operation}`: CREATE_LOCATION | MODIFY_UPSTREAM | DELETE_LOCATION\n- `{agent1_data}`: Request details (domain, location, ip_addresses, upstream_type)\n- `{upstreams}`: Current upstream configs (JSON)\n\n## CONFIG FORMAT (JSON)\n\n```json\n{{\n  \"nginx_http_upstreams\": {{\n    \"aip_mos_ru\": {{\n      \"main\": {{\n        \"lb\": \"ip_hash\",\n        \"servers\": [\"10.206.218.65:80\", \"10.206.218.66:80\"]\n      }},\n      \"backup\": {{\n        \"servers\": [\"10.207.139.201:80\"]\n      }},\n      \"domains\": [\"aip.mos.ru\"],\n      \"environment\": \"production\",\n      \"system_id\": \"IS0166\"\n    }}\n  }}\n}}\n```\n\n**Server params:** `max_fails=N`, `fail_timeout=Xs`, `weight=N`, `backup`, `down`\n**LB methods:** `round_robin`, `ip_hash`, `least_conn`, `hash`\n\n⚠️ **LB RULE:** Field `lb` include ONLY if:\n- Already exists in current config → preserve it\n- User explicitly requested → add it\n- Otherwise → DO NOT add `lb` field\n\n## OPERATIONS\n\n### CREATE_LOCATION\n\n1. Generate name: `domain.replace(\".\",  \"_\")` + `_` + `location.replace(\"/\", \"_\")`\n   - Example: `aip.mos.ru` + `/api/` → `aip_mos_ru_api`\n2. Create config from `agent1_data.upstreams[]`\n3. Add `:80` if no port specified\n\n**Output:**\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"CREATE_LOCATION\",\n  \"upstream_name\": \"aip_mos_ru_api\",\n  \"updated_json\": {{\n    \"aip_mos_ru_api\": {{\n      \"main\": {{\"servers\": [\"10.10.10.10:80\"]}},\n      \"domains\": [\"aip.mos.ru\"],\n      \"environment\": \"production\",\n      \"system_id\": null\n    }}\n  }},\n  \"explanation\": \"Создан upstream aip_mos_ru_api с 1 main сервером\",\n  \"ready_to_save\": true\n}}\n```\n\nNote: `lb` field omitted - add only if user explicitly requests load balancing method.\n\n### MODIFY_UPSTREAM\n\n1. Get `upstream_type` (main/backup) from `agent1_data.upstreams[0]`\n2. Get `ip_addresses` from `agent1_data.upstreams[0]`\n3. Add `:80` if no port\n4. Replace servers in target section\n5. **Preserve `lb` ONLY if it exists in current config** (do not add if absent)\n6. Keep `domains`, `environment`, `system_id` unchanged\n\n**Single upstream output:**\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"MODIFY_UPSTREAM\",\n  \"upstream_name\": \"aip_mos_ru\",\n  \"target_section\": \"main\",\n  \"analysis\": {{\n    \"current_servers\": [\"10.206.218.65:80\"],\n    \"new_servers\": [\"10.10.10.10:80\", \"10.10.10.11:80\"],\n    \"servers_added\": 2,\n    \"servers_removed\": 1\n  }},\n  \"updated_json\": {{\n    \"aip_mos_ru\": {{\n      \"main\": {{\"servers\": [\"10.10.10.10:80\", \"10.10.10.11:80\"]}},\n      \"backup\": {{\"servers\": [\"10.207.139.201:80\"]}},\n      \"domains\": [\"aip.mos.ru\"],\n      \"environment\": \"production\",\n      \"system_id\": \"IS0166\"\n    }}\n  }},\n  \"diff\": {{\n    \"removed\": [\"10.206.218.65:80\"],\n    \"added\": [\"10.10.10.10:80\", \"10.10.10.11:80\"]\n  }},\n  \"explanation\": \"Обновлены main серверы для aip_mos_ru\",\n  \"ready_to_save\": true\n}}\n```\n\nNote: No `lb` in output because it wasn't in original config. If original had `\"lb\": \"ip_hash\"`, preserve it in `main` or `backup` section.\n\n**Multiple upstreams output:**\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"MODIFY_UPSTREAM\",\n  \"modified_upstreams\": [\"upstream1\", \"upstream2\"],\n  \"target_section\": \"main\",\n  \"updated_json\": {{\n    \"upstream1\": {{...}},\n    \"upstream2\": {{...}}\n  }},\n  \"explanation\": \"Обновлены main серверы для 2 upstreams\",\n  \"ready_to_save\": true\n}}\n```\n\n### DELETE_LOCATION\n\nCheck `domains` array length:\n- **Multiple domains** → keep upstream, return warning\n- **Single domain** → safe to delete\n\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"DELETE_LOCATION\",\n  \"upstream_name\": \"aip_mos_ru\",\n  \"action\": \"delete_upstream\",\n  \"explanation\": \"Upstream используется только одним доменом, можно удалить\",\n  \"ready_to_save\": true\n}}\n```\n\n## RULES\n\n✅ ALLOWED:\n- Modify `main.servers` or `backup.servers`\n- Create new upstreams (CREATE_LOCATION)\n- Recommend deletion (DELETE_LOCATION)\n\n❌ FORBIDDEN:\n- Modify `domains`, `environment`, `system_id` (except defaults for new)\n- Delete upstream with multiple domains\n\n## VALIDATION\n\n- IP format: `XXX.XXX.XXX.XXX`\n- Port: `1-65535`, default `:80`\n- Min 1 server in main (recommended)\n\n## OUTPUT\n\nReturn ONLY valid JSON"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "upstreams": {
                "advanced": false,
                "display_name": "upstreams",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "upstreams",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-Tj3jj",
        "measured": {
          "height": 523,
          "width": 320
        },
        "position": {
          "x": 2317.8356171842656,
          "y": 67.24894509659137
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-mYcwF",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "openai",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "last_updated": "2025-11-03T16:58:41.808Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "TOKEN"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_CHAT_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "local_huggingface/Qwen3-32B"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:8000/v1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an nginx upstream configuration expert. You modify upstream configurations in `skdpu_http_upstreams.yml` based on validated user requests.\n⚠️ **CRITICAL**: You work with EXISTING upstream configurations. You manage backend server lists for upstreams."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.05
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-mYcwF",
        "measured": {
          "height": 537,
          "width": 320
        },
        "position": {
          "x": 2747.3939226513285,
          "y": 394.02035520437346
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-D3L0W",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "key": "TypeConverterComponent",
            "last_updated": "2025-11-21T11:34:07.249Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data Output",
                "group_outputs": false,
                "hidden": null,
                "method": "convert_to_data",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.008834292878014125,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Data"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-D3L0W",
        "measured": {
          "height": 261,
          "width": 320
        },
        "position": {
          "x": 3180.601424865175,
          "y": 1084.5035097859904
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-70UEC",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template with safe handling of missing keys.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": true,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep",
              "missing_key_placeholder"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template with safe handling of missing keys.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data. Missing keys will be replaced with 'None'.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n        MessageTextInput(\n            name=\"missing_key_placeholder\",\n            display_name=\"Missing Key Placeholder\",\n            advanced=True,\n            value=\"None\",\n            info=\"Text to use when a template key is not found in the data.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def safe_format(self, template: str, data_dict: dict) -> str:\n        \"\"\"\n        Safely format template by replacing missing keys with placeholder.\n        \n        Args:\n            template: Template string with {key} placeholders\n            data_dict: Dictionary with data to substitute\n            \n        Returns:\n            Formatted string with missing keys replaced by placeholder\n        \"\"\"\n        import re\n        \n        # Find all {key} patterns in template\n        pattern = r'\\{([^}]+)\\}'\n        keys = re.findall(pattern, template)\n        \n        # Create safe dict with placeholders for missing keys\n        safe_dict = {}\n        for key in keys:\n            if key in data_dict:\n                safe_dict[key] = data_dict[key]\n            else:\n                safe_dict[key] = self.missing_key_placeholder or \"None\"\n                self.log(f\"Warning: Key '{key}' not found in data, using placeholder\")\n        \n        try:\n            return template.format(**safe_dict)\n        except KeyError as e:\n            self.log(f\"Error formatting template: {e}\")\n            # Fallback: return template as-is\n            return template\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.safe_format(self.pattern, row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.safe_format(self.pattern, data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data, clean_data=self.clean_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "missing_key_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Missing Key Placeholder",
                "dynamic": false,
                "info": "Text to use when a template key is not found in the data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "missing_key_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "None"
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data. Missing keys will be replaced with 'None'.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}\\n"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-70UEC",
        "measured": {
          "height": 343,
          "width": 320
        },
        "position": {
          "x": 2061.3922707917736,
          "y": 1314.0214331203147
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LoopComponent-4CHsH",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.",
            "display_name": "Loop",
            "documentation": "https://docs.langflow.org/components-logic#loop",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "infinity",
            "key": "LoopComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": true,
                "cache": true,
                "display_name": "Item",
                "group_outputs": true,
                "method": "item_output",
                "name": "item",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Done",
                "group_outputs": true,
                "method": "done_output",
                "name": "done",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\n\n\nclass LoopComponent(Component):\n    display_name = \"Loop\"\n    description = (\n        \"Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.\"\n    )\n    documentation: str = \"https://docs.langflow.org/components-logic#loop\"\n    icon = \"infinity\"\n\n    inputs = [\n        HandleInput(\n            name=\"data\",\n            display_name=\"Inputs\",\n            info=\"The initial list of Data objects or DataFrame to iterate over.\",\n            input_types=[\"DataFrame\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Item\", name=\"item\", method=\"item_output\", allows_loop=True, group_outputs=True),\n        Output(display_name=\"Done\", name=\"done\", method=\"done_output\", group_outputs=True),\n    ]\n\n    def initialize_data(self) -> None:\n        \"\"\"Initialize the data list, context index, and aggregated list.\"\"\"\n        if self.ctx.get(f\"{self._id}_initialized\", False):\n            return\n\n        # Ensure data is a list of Data objects\n        data_list = self._validate_data(self.data)\n\n        # Store the initial data and context variables\n        self.update_ctx(\n            {\n                f\"{self._id}_data\": data_list,\n                f\"{self._id}_index\": 0,\n                f\"{self._id}_aggregated\": [],\n                f\"{self._id}_initialized\": True,\n            }\n        )\n\n    def _validate_data(self, data):\n        \"\"\"Validate and return a list of Data objects.\"\"\"\n        if isinstance(data, DataFrame):\n            return data.to_data_list()\n        if isinstance(data, Data):\n            return [data]\n        if isinstance(data, list) and all(isinstance(item, Data) for item in data):\n            return data\n        msg = \"The 'data' input must be a DataFrame, a list of Data objects, or a single Data object.\"\n        raise TypeError(msg)\n\n    def evaluate_stop_loop(self) -> bool:\n        \"\"\"Evaluate whether to stop item or done output.\"\"\"\n        current_index = self.ctx.get(f\"{self._id}_index\", 0)\n        data_length = len(self.ctx.get(f\"{self._id}_data\", []))\n        return current_index > data_length\n\n    def item_output(self) -> Data:\n        \"\"\"Output the next item in the list or stop if done.\"\"\"\n        self.initialize_data()\n        current_item = Data(text=\"\")\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n        else:\n            # Get data list and current index\n            data_list, current_index = self.loop_variables()\n            if current_index < len(data_list):\n                # Output current item and increment index\n                try:\n                    current_item = data_list[current_index]\n                except IndexError:\n                    current_item = Data(text=\"\")\n            self.aggregated_output()\n            self.update_ctx({f\"{self._id}_index\": current_index + 1})\n\n        # Now we need to update the dependencies for the next run\n        self.update_dependency()\n        return current_item\n\n    def update_dependency(self):\n        item_dependency_id = self.get_incoming_edge_by_target_param(\"item\")\n        if item_dependency_id not in self.graph.run_manager.run_predecessors[self._id]:\n            self.graph.run_manager.run_predecessors[self._id].append(item_dependency_id)\n\n    def done_output(self) -> DataFrame:\n        \"\"\"Trigger the done output when iteration is complete.\"\"\"\n        self.initialize_data()\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n            self.start(\"done\")\n\n            aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n\n            return DataFrame(aggregated)\n        self.stop(\"done\")\n        return DataFrame([])\n\n    def loop_variables(self):\n        \"\"\"Retrieve loop variables from context.\"\"\"\n        return (\n            self.ctx.get(f\"{self._id}_data\", []),\n            self.ctx.get(f\"{self._id}_index\", 0),\n        )\n\n    def aggregated_output(self) -> list[Data]:\n        \"\"\"Return the aggregated list once all items are processed.\"\"\"\n        self.initialize_data()\n\n        # Get data list and aggregated list\n        data_list = self.ctx.get(f\"{self._id}_data\", [])\n        aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n        loop_input = self.item\n        if loop_input is not None and not isinstance(loop_input, str) and len(aggregated) <= len(data_list):\n            aggregated.append(loop_input)\n            self.update_ctx({f\"{self._id}_aggregated\": aggregated})\n        return aggregated\n"
              },
              "data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "The initial list of Data objects or DataFrame to iterate over.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LoopComponent"
        },
        "dragging": false,
        "id": "LoopComponent-4CHsH",
        "measured": {
          "height": 241,
          "width": 320
        },
        "position": {
          "x": 1300.8539167319896,
          "y": 505.48892665310973
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-eGILW",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{location_path}\n{operation}\n{upstreams}\n{agent1_data}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-eGILW",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 1757.8953252499305,
          "y": 468.530568581428
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-X3c1r",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003169567463043492,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-X3c1r",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 2537.5807426158813,
          "y": 1602.1887293694783
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-EfRPK",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00004500241402777085,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-EfRPK",
        "measured": {
          "height": 203,
          "width": 320
        },
        "position": {
          "x": -727.3953596781856,
          "y": 572.0599688432061
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UpstreamExtractorComponent-rkDhh",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Извлекает upstream данные из NGINX конфигов для Агента 4",
            "display_name": "Upstream Extractor",
            "documentation": "",
            "edited": true,
            "field_order": [
              "config_data",
              "mosru_path"
            ],
            "frozen": false,
            "icon": "database",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Upstream Data",
                "group_outputs": false,
                "hidden": null,
                "method": "process_upstream",
                "name": "upstream_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"\nUpstream Extractor Component for Langflow\nИзвлекает данные upstream из конфигов для операций MODIFY_UPSTREAM и DELETE_LOCATION\nРаботает с Data/DataFrame от Universal Search Config\n\"\"\"\n\nimport re\nimport os\nimport yaml\nimport json\nfrom typing import Optional, Dict, Any, List\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass UpstreamExtractorComponent(Component):\n    display_name = \"Upstream Extractor\"\n    description = \"Извлекает upstream данные из NGINX конфигов для Агента 4\"\n    icon = \"database\"\n\n    inputs = [\n        DataInput(\n            name=\"config_data\",\n            display_name=\"Config Data\",\n            info=\"Data/DataFrame от Universal Search Config\",\n            input_types=[\"Data\"]\n        ),\n        MessageTextInput(\n            name=\"mosru_path\",\n            display_name=\"MosRU Path\",\n            value=\"mosru_nginx/mos_ru_nginx\",\n            info=\"Базовый путь к конфигам MosRU\"\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Upstream Data\", name=\"upstream_data\", method=\"process_upstream\"),\n    ]\n\n    def extract_data_from_input(self) -> Dict[str, Any]:\n        \"\"\"\n        Извлекает данные из Data/DataFrame объекта\n        Обрабатывает все возможные форматы данных от Universal Search\n        \"\"\"\n        try:\n            self.log(f\"🔍 Input type: {type(self.config_data)}\")\n            self.log(f\"🔍 Input value preview: {str(self.config_data)[:200]}\")\n\n            # Если это Data объект от Langflow\n            if hasattr(self.config_data, 'data'):\n                self.log(\"📦 Found .data attribute\")\n                data = self.config_data.data\n\n                if isinstance(data, dict):\n                    self.log(f\"✅ Data is dict with keys: {list(data.keys())}\")\n                    return data\n                elif isinstance(data, str):\n                    self.log(\"🔄 Data is string, parsing JSON\")\n                    return json.loads(data)\n                elif isinstance(data, list) and len(data) > 0:\n                    self.log(\"📋 Data is list, taking first item\")\n                    return data[0] if isinstance(data[0], dict) else {}\n\n            # Если это dict напрямую\n            if isinstance(self.config_data, dict):\n                self.log(f\"✅ Direct dict with keys: {list(self.config_data.keys())}\")\n                return self.config_data\n\n            # Если это строка JSON\n            if isinstance(self.config_data, str):\n                self.log(\"🔄 String input, parsing JSON\")\n                return json.loads(self.config_data)\n\n            # Если это список\n            if isinstance(self.config_data, list) and len(self.config_data) > 0:\n                self.log(\"📋 List input, taking first item\")\n                first = self.config_data[0]\n                if hasattr(first, 'data'):\n                    return first.data\n                return first if isinstance(first, dict) else {}\n\n            self.log(f\"⚠️ Unexpected data type: {type(self.config_data)}\")\n            self.log(f\"⚠️ Data content: {self.config_data}\")\n            return {}\n\n        except Exception as e:\n            self.log(f\"❌ Error extracting data: {e}\")\n            import traceback\n            self.log(f\"Traceback: {traceback.format_exc()}\")\n            return {}\n\n    def find_proxy_pass(self, config_lines: List[str], location_path: str) -> Optional[str]:\n        \"\"\"\n        Находит proxy_pass для определенного location\n        Returns: upstream_name или None\n        \"\"\"\n        config_str = '\\n'.join(config_lines)\n\n        self.log(f\"🔍 Looking for proxy_pass in location: {location_path}\")\n        self.log(f\"📝 Config has {len(config_lines)} lines\")\n\n        # Нормализуем location path\n        location_normalized = location_path.strip().rstrip('/')\n\n        # Определяем тип match\n        exact_match = location_normalized.startswith('=')\n        if exact_match:\n            path = location_normalized[1:].strip().rstrip('/')\n        else:\n            path = location_normalized.rstrip('/')\n\n        # Для root location\n        if path == '' or path == '/':\n            path = '/'\n\n        path_escaped = re.escape(path) if path != '/' else '/'\n\n        # Паттерны для поиска\n        patterns = []\n\n        if exact_match:\n            patterns.append(rf'location\\s*=\\s*{path_escaped}/?[\\s{{].*?proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)')\n        else:\n            if path == '/':\n                # Специальный паттерн для root location\n                patterns.extend([\n                    r'location\\s+/\\s*\\{\\s*proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n                    r'location\\s+/\\s+\\{\\s*proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n                ])\n            else:\n                patterns.extend([\n                    rf'location\\s+{path_escaped}/?[\\s{{].*?proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n                ])\n\n        for i, pattern in enumerate(patterns):\n            self.log(f\"🔍 Trying pattern {i+1}: {pattern[:50]}...\")\n            match = re.search(pattern, config_str, re.DOTALL | re.MULTILINE)\n            if match:\n                upstream = match.group(1).strip()\n                self.log(f\"✅ Found upstream: {upstream} for location: {location_path}\")\n                return upstream\n\n        self.log(f\"❌ No proxy_pass found for location: {location_path}\")\n        # Показываем несколько строк для отладки\n        for i, line in enumerate(config_lines[:5]):\n            self.log(f\"  Line {i}: {line}\")\n\n        return None\n\n    def load_upstream_config(self, upstream_name: str, mosru_path: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Загружает конфигурацию upstream из skdpu_http_upstreams.yml\n        \"\"\"\n        skdpu_http_upstreams = f\"/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/skdpu_config/skdpu_http_upstreams.yml\"\n\n        self.log(f\"📂 Looking for upstream file: {skdpu_http_upstreams}\")\n\n        if not os.path.exists(skdpu_http_upstreams):\n            self.log(f\"❌ File not found: {skdpu_http_upstreams}\")\n            return None\n\n        try:\n            with open(skdpu_http_upstreams, 'r', encoding='utf-8') as f:\n                upstreams_data = yaml.safe_load(f)\n\n            self.log(f\"📄 YAML loaded, top-level keys: {list(upstreams_data.keys())[:10]}\")\n\n            # Проверка на top-level upstream\n            if upstream_name in upstreams_data:\n                self.log(f\"✅ Found upstream at top level: {upstream_name}\")\n                return upstreams_data[upstream_name]\n\n            # Ищем upstream в секции nginx_http_upstreams\n            if 'nginx_http_upstreams' in upstreams_data:\n                upstreams = upstreams_data['nginx_http_upstreams']\n                self.log(f\"🔍 Found nginx_http_upstreams with {len(upstreams)} entries\")\n\n                if upstream_name in upstreams:\n                    self.log(f\"✅ Found upstream config: {upstream_name}\")\n                    return upstreams[upstream_name]\n\n            # Альтернативный поиск\n            for section, data in upstreams_data.items():\n                if isinstance(data, dict) and upstream_name in data:\n                    self.log(f\"✅ Found upstream config in {section}: {upstream_name}\")\n                    return data[upstream_name]\n\n            self.log(f\"❌ Upstream not found in YAML: {upstream_name}\")\n            return None\n\n        except Exception as e:\n            self.log(f\"❌ Error loading upstream config: {e}\")\n            return None\n\n    def process_upstream(self) -> Data:\n        \"\"\"\n        Основной метод обработки - обрабатывает ВСЕ домены из agent1_data.payload\n        \"\"\"\n        try:\n            self.log(\"=\" * 50)\n            self.log(\"🚀 Starting Upstream Extractor processing\")\n\n            config_data = self.extract_data_from_input()\n\n            if not config_data:\n                return Data(data={\n                    \"status\": \"error\",\n                    \"operation\": \"UNKNOWN\",\n                    \"error_message\": \"Не удалось извлечь данные из config_data\",\n                    \"upstream_processing_needed\": False\n                })\n\n            status = config_data.get('status')\n            if status != 'success':\n                return Data(data={\n                    \"status\": \"error\",\n                    \"operation\": \"UNKNOWN\",\n                    \"error_message\": config_data.get('error_message', 'Config search failed'),\n                    \"upstream_processing_needed\": False\n                })\n\n            agent1_data = config_data.get('agent1_data', {})\n            operation = agent1_data.get('operation', config_data.get('operation', ''))\n\n            if operation not in ['MODIFY_UPSTREAM', 'DELETE_LOCATION']:\n                return Data(data={\n                    \"status\": \"skipped\",\n                    \"operation\": operation,\n                    \"message\": f\"Операция {operation} не требует обработки upstream\",\n                    \"upstream_processing_needed\": False\n                })\n\n            # Получаем информацию о мульти-ЦОД\n            found_in_multiple_dc = config_data.get('found_in_multiple_dc', False)\n            domains_in_multiple_dc = config_data.get('domains_in_multiple_dc', [])\n            domain_dc_mapping = config_data.get('domain_dc_mapping', {})\n            unique_dcs = config_data.get('unique_dcs', [])\n\n            # Получаем payload с операциями для каждого домена\n            payload = agent1_data.get('payload', [])\n            all_configs = config_data.get('all_configs', [])\n\n            # Создаём маппинг domain -> config_block (берём первый конфиг для домена)\n            domain_to_config = {}\n            domain_to_config_info = {}  # Дополнительная инфо о конфиге\n\n            for cfg in all_configs:\n                for domain in cfg.get('matching_domains', []):\n                    if domain not in domain_to_config:  # Берём первый найденный\n                        domain_to_config[domain] = cfg.get('config_block', [])\n                        domain_to_config_info[domain] = {\n                            'config_file': cfg.get('config_file', ''),\n                            'config_key': cfg.get('config_key', ''),\n                            'folder': cfg.get('folder', ''),\n                            'inferred_dc': cfg.get('inferred_dc', [])\n                        }\n\n            self.log(f\"📋 Domain to config mapping: {list(domain_to_config.keys())}\")\n\n            upstreams = []\n            warnings = []\n\n            # Генерируем warnings для доменов в нескольких ЦОД\n            if found_in_multiple_dc and domains_in_multiple_dc:\n                for domain in domains_in_multiple_dc:\n                    dcs = domain_dc_mapping.get(domain, [])\n                    warning_msg = f\"Домен {domain} найден в нескольких ЦОД: {', '.join(dcs)}. Убедитесь, что изменения применяются ко всем площадкам.\"\n                    warnings.append({\n                        \"type\": \"MULTI_DC\",\n                        \"domain\": domain,\n                        \"datacenters\": dcs,\n                        \"message\": warning_msg\n                    })\n                    self.log(f\"⚠️ WARNING: {warning_msg}\")\n\n            # Обрабатываем каждую операцию из payload\n            for op_item in payload:\n                domain = op_item.get('domain', '')\n                location = op_item.get('location', '/')\n\n                self.log(f\"🔍 Processing domain: {domain}, location: {location}\")\n\n                # Находим config_block для этого домена\n                config_block = domain_to_config.get(domain, [])\n                config_info = domain_to_config_info.get(domain, {})\n\n                if not config_block:\n                    self.log(f\"⚠️ No config_block found for domain: {domain}\")\n                    warnings.append({\n                        \"type\": \"NO_CONFIG\",\n                        \"domain\": domain,\n                        \"message\": f\"Не найден конфиг для домена {domain}\"\n                    })\n                    continue\n\n                # Ищем proxy_pass\n                upstream_name = self.find_proxy_pass(config_block, location)\n\n                if upstream_name:\n                    upstream_config = self.load_upstream_config(upstream_name, self.mosru_path)\n                    if upstream_config:\n                        upstream_entry = {\n                            \"domain\": domain,\n                            \"location\": location,\n                            \"upstream_name\": upstream_name,\n                            \"upstream_config\": upstream_config,\n                            \"upstream_yaml_block\": yaml.dump(\n                                {upstream_name: upstream_config},\n                                default_flow_style=False,\n                                allow_unicode=True,\n                                sort_keys=False\n                            ),\n                            \"config_info\": config_info\n                        }\n\n                        # Добавляем инфо о ЦОД если домен в нескольких\n                        if domain in domains_in_multiple_dc:\n                            upstream_entry[\"multi_dc\"] = True\n                            upstream_entry[\"datacenters\"] = domain_dc_mapping.get(domain, [])\n\n                        upstreams.append(upstream_entry)\n                        self.log(f\"✅ Found upstream for {domain}{location}: {upstream_name}\")\n                    else:\n                        self.log(f\"⚠️ Upstream config not found in YAML: {upstream_name}\")\n                        warnings.append({\n                            \"type\": \"UPSTREAM_NOT_FOUND\",\n                            \"domain\": domain,\n                            \"location\": location,\n                            \"upstream_name\": upstream_name,\n                            \"message\": f\"Upstream {upstream_name} не найден в skdpu_http_upstreams.yml\"\n                        })\n                else:\n                    self.log(f\"⚠️ No proxy_pass found for {domain}{location}\")\n                    warnings.append({\n                        \"type\": \"NO_PROXY_PASS\",\n                        \"domain\": domain,\n                        \"location\": location,\n                        \"message\": f\"Не найден proxy_pass для {domain}{location}\"\n                    })\n\n            if not upstreams:\n                return Data(data={\n                    \"status\": \"error\",\n                    \"operation\": operation,\n                    \"error_message\": \"Не найдены upstreams для указанных доменов\",\n                    \"upstream_processing_needed\": False,\n                    \"processed_domains\": [op.get('domain') for op in payload],\n                    \"warnings\": warnings\n                })\n\n            result = {\n                \"status\": \"success\",\n                \"operation\": operation,\n                \"upstreams\": upstreams,\n                \"upstream_processing_needed\": True,\n                \"agent1_data\": agent1_data,\n                \"full_config_data\": config_data,\n                # Мульти-ЦОД информация\n                \"found_in_multiple_dc\": found_in_multiple_dc,\n                \"domains_in_multiple_dc\": domains_in_multiple_dc,\n                \"domain_dc_mapping\": domain_dc_mapping,\n                \"unique_dcs\": unique_dcs,\n                \"dc_count\": config_data.get('dc_count', 1),\n                # Warnings\n                \"warnings\": warnings,\n                \"has_warnings\": len(warnings) > 0\n            }\n\n            self.log(f\"✅ SUCCESS! Found {len(upstreams)} upstreams\")\n            if warnings:\n                self.log(f\"⚠️ Generated {len(warnings)} warnings\")\n            return Data(data=result)\n\n        except Exception as e:\n            import traceback\n            self.log(f\"❌ CRITICAL ERROR: {str(e)}\\n{traceback.format_exc()}\")\n            return Data(data={\n                \"status\": \"error\",\n                \"operation\": \"UNKNOWN\",\n                \"error_message\": f\"Ошибка обработки: {str(e)}\",\n                \"upstream_processing_needed\": False\n            })"
              },
              "config_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Config Data",
                "dynamic": false,
                "info": "Data/DataFrame от Universal Search Config",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "config_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mosru_path": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "MosRU Path",
                "dynamic": false,
                "info": "Базовый путь к конфигам MosRU",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "mosru_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "config_file_path",
          "showNode": true,
          "type": "UpstreamExtractorComponent"
        },
        "dragging": false,
        "id": "UpstreamExtractorComponent-rkDhh",
        "measured": {
          "height": 263,
          "width": 320
        },
        "position": {
          "x": 290.14917613530923,
          "y": 544.5304383008565
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UniversalSearchConfigComponent-3wswc",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Универсально сканирует YML файлы по доменам из любой структуры JSON (включая Arbitrator payload)",
            "display_name": "Universal Search Config",
            "documentation": "",
            "edited": true,
            "field_order": [
              "agent1_json",
              "config_base_path"
            ],
            "frozen": false,
            "icon": "search",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Config Data",
                "group_outputs": false,
                "hidden": null,
                "method": "search_config",
                "name": "config_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent1_json": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Agent 1 JSON Output",
                "dynamic": false,
                "info": "JSON с извлечёнными данными от Agent 1 или Arbitrator (любая структура)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "agent1_json",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, StrInput, Output\nfrom langflow.schema import Data\nimport json\nimport yaml\nimport os\nimport glob\nimport re\nfrom typing import List, Dict, Any, Optional\n\n\nclass UniversalSearchConfigComponent(Component):\n    display_name = \"Universal Search Config\"\n    description = \"Универсально сканирует YML файлы по доменам из любой структуры JSON (включая Arbitrator payload)\"\n    icon = \"search\"\n    inputs = [\n        MessageTextInput(\n            name=\"agent1_json\",\n            display_name=\"Agent 1 JSON Output\",\n            info=\"JSON с извлечёнными данными от Agent 1 или Arbitrator (любая структура)\",\n            required=True\n        ),\n        StrInput(\n            name=\"config_base_path\",\n            display_name=\"Config Base Path\",\n            info=\"Путь к родительской папке с конфигами (например, /path/to/mos_ru_nginx/)\",\n            value=\"/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/\",\n            required=True\n        )\n    ]\n    outputs = [\n        Output(\n            display_name=\"Config Data\",\n            name=\"config_data\",\n            method=\"search_config\"\n        )\n    ]\n\n    def search_config(self) -> Data:\n        \"\"\"\n        Универсально обрабатывает любой JSON/Python dict и ищет конфигурации\n        \"\"\"\n        try:\n            # 🔧 ПРЕДОБРАБОТКА: Очищаем от markdown блоков\n            cleaned_input = self._clean_markdown(self.agent1_json)\n\n            # 🔄 ПАРСИМ: Поддержка и JSON, и Python dict\n            raw_data = self._parse_input(cleaned_input)\n\n            # 🔄 НОРМАЛИЗАЦИЯ: Извлекаем payload если это Arbitrator output\n            agent1_data = self._normalize_input(raw_data)\n            # 🔍 УНИВЕРСАЛЬНОЕ ИЗВЛЕЧЕНИЕ ДОМЕНОВ\n            domains = self._universal_extract_domains(agent1_data)\n\n            # 🔍 УНИВЕРСАЛЬНОЕ ИЗВЛЕЧЕНИЕ ДРУГИХ ДАННЫХ\n            locations = self._universal_extract_locations(agent1_data)\n            ip_addresses = self._universal_extract_ips(agent1_data)\n            upstreams = self._universal_extract_upstreams(agent1_data)\n            parameters = self._universal_extract_parameters(agent1_data)\n            location_parameters = self._universal_extract_location_parameters(agent1_data)\n            operation = self._universal_extract_operation(agent1_data)\n            selected_dc = self._universal_extract_selected_dc(agent1_data)\n            # ✅ ПРОВЕРЯЕМ СТАТУС\n            status = self._check_status(raw_data)  # Проверяем оригинальные данные\n            if status and status.get(\"is_error\"):\n                return self._return_error_status(status, agent1_data)\n            # ❌ ОШИБКА: Домены не найдены\n            if not domains:\n                return self._return_no_domains_error(\n                    agent1_data, locations, ip_addresses, parameters, operation\n                )\n            # 🔍 ОПРЕДЕЛЯЕМ ПАПКИ ДЛЯ ПОИСКА\n            search_folders = self._get_search_folders(selected_dc)\n            # 🔍 СКАНИРУЕМ ВСЕ YML ФАЙЛЫ В ВЫБРАННЫХ ПАПКАХ\n            config_results = []\n            scanned_files = 0\n            for folder in search_folders:\n                folder_path = os.path.join(self.config_base_path, folder)\n                if not os.path.isdir(folder_path):\n                    continue\n                yml_files = glob.glob(os.path.join(folder_path, \"*.yml\"))\n                scanned_files += len(yml_files)\n                for yml_file in yml_files:\n                    file_results = self._scan_yml_file(yml_file, domains)\n                    for res in file_results:\n                        res[\"folder\"] = folder\n                        res[\"inferred_dc\"] = self._infer_dc_from_folder(folder)\n                    config_results.extend(file_results)\n            # Удаляем дубликаты (по полному пути и ключу)\n            unique_results = self._deduplicate_results(config_results)\n            # ❌ ОШИБКА: Конфиги не найдены\n            if not unique_results:\n                return self._return_not_found_error(\n                    domains, scanned_files, agent1_data,\n                    locations, ip_addresses, parameters, operation\n                )\n            # ✅ УСПЕХ: Конфиг найден\n            first_config = unique_results[0]\n\n            # 🆕 АНАЛИЗ: Проверяем, найден ли домен в нескольких ЦОД\n            multi_dc_info = self._analyze_multi_dc_presence(unique_results, domains)\n\n            result = {\n                \"status\": \"success\",\n\n                # 📦 Конфиг данные\n                \"config_file\": first_config[\"config_file\"],\n                \"config_key\": first_config[\"config_key\"],\n                \"full_config_text\": first_config[\"full_config_text\"],\n                \"server_names\": first_config[\"server_names\"],\n                \"matching_domains\": first_config[\"matching_domains\"],\n                # 📦 Извлечённые данные (нормализованные)\n                \"agent1_data\": agent1_data,\n                \"operation\": operation,\n                \"domains\": domains,\n                \"locations\": locations,\n                \"ip_addresses\": ip_addresses,\n                \"upstreams\": upstreams,\n                \"parameters\": parameters,\n                \"location_parameters\": location_parameters,\n                \"selected_dc\": selected_dc,\n                # 📊 Метаданные\n                \"scanned_files\": scanned_files,\n                \"found_configs\": len(unique_results),\n                \"all_configs\": unique_results,\n                \"data_complete\": True,\n                \"error_type\": None,\n                \"error_message\": None,\n\n                # 🆕 НОВЫЕ КЛЮЧИ: Информация о нахождении в нескольких ЦОД\n                \"found_in_multiple_dc\": multi_dc_info[\"found_in_multiple_dc\"],\n                \"dc_count\": multi_dc_info[\"dc_count\"],\n                \"unique_dcs\": multi_dc_info[\"unique_dcs\"],\n                \"domain_dc_mapping\": multi_dc_info[\"domain_dc_mapping\"],\n                \"domains_in_multiple_dc\": multi_dc_info[\"domains_in_multiple_dc\"],\n            }\n            # Формируем сообщение\n            msg = self._format_success_message(result)\n            return Data(data=result, text=msg)\n        except json.JSONDecodeError as e:\n            return self._return_json_error(e, self.agent1_json)\n        except Exception as e:\n            return self._return_unexpected_error(e)\n\n    # ==========================================\n    # 🆕 НОВЫЙ МЕТОД: Анализ присутствия в нескольких ЦОД\n    # ==========================================\n    def _analyze_multi_dc_presence(self, config_results: List[Dict], domains: List[str]) -> Dict:\n        \"\"\"\n        Анализирует, найден ли домен в нескольких ЦОД\n\n        Returns:\n            Dict с ключами:\n            - found_in_multiple_dc: bool - True если хотя бы один домен найден в >1 ЦОД\n            - dc_count: int - количество уникальных ЦОД где найдены конфиги\n            - unique_dcs: List[str] - список уникальных ЦОД\n            - domain_dc_mapping: Dict[str, List[str]] - маппинг домен -> список ЦОД\n            - domains_in_multiple_dc: List[str] - домены, найденные в нескольких ЦОД\n        \"\"\"\n        # Собираем все уникальные ЦОД из результатов\n        all_dcs = set()\n        for config in config_results:\n            inferred_dc = config.get(\"inferred_dc\", [])\n            all_dcs.update(inferred_dc)\n\n        unique_dcs = sorted(list(all_dcs))\n        dc_count = len(unique_dcs)\n\n        # Строим маппинг: домен -> в каких ЦОД найден\n        domain_dc_mapping = {}\n        for domain in domains:\n            domain_dcs = set()\n            for config in config_results:\n                matching_domains = config.get(\"matching_domains\", [])\n                if domain in matching_domains:\n                    inferred_dc = config.get(\"inferred_dc\", [])\n                    domain_dcs.update(inferred_dc)\n            domain_dc_mapping[domain] = sorted(list(domain_dcs))\n\n        # Определяем домены, которые найдены в нескольких ЦОД\n        domains_in_multiple_dc = [\n            domain for domain, dcs in domain_dc_mapping.items()\n            if len(dcs) > 1\n        ]\n\n        # Главный флаг: есть ли хотя бы один домен в нескольких ЦОД\n        found_in_multiple_dc = len(domains_in_multiple_dc) > 0\n\n        return {\n            \"found_in_multiple_dc\": found_in_multiple_dc,\n            \"dc_count\": dc_count,\n            \"unique_dcs\": unique_dcs,\n            \"domain_dc_mapping\": domain_dc_mapping,\n            \"domains_in_multiple_dc\": domains_in_multiple_dc\n        }\n\n    # ==========================================\n    # ПРЕДОБРАБОТКА И НОРМАЛИЗАЦИЯ\n    # ==========================================\n    def _clean_markdown(self, raw_input: str) -> str:\n        \"\"\"Убирает только markdown разметку\"\"\"\n        if not raw_input:\n            return raw_input\n\n        cleaned = raw_input.strip()\n\n        patterns = [\n            (r'^```json\\s*\\n', ''),\n            (r'^```\\s*\\n', ''),\n            (r'\\n```\\s*$', ''),\n            (r'^```json\\s*', ''),\n            (r'^```\\s*', ''),\n            (r'```\\s*$', ''),\n        ]\n\n        for pattern, replacement in patterns:\n            cleaned = re.sub(pattern, replacement, cleaned)\n\n        return cleaned.strip()\n\n    def _parse_input(self, text: str) -> Dict:\n        \"\"\"\n        🔄 Парсит входные данные — поддерживает JSON и Python dict\n        \"\"\"\n        # Способ 1: Пробуем как JSON\n        try:\n            return json.loads(text)\n        except json.JSONDecodeError:\n            pass\n\n        # Способ 2: Пробуем как Python dict через ast.literal_eval\n        try:\n            import ast\n            result = ast.literal_eval(text)\n            if isinstance(result, dict):\n                return result\n        except (ValueError, SyntaxError):\n            pass\n\n        # Способ 3: Ручная конвертация Python → JSON\n        try:\n            converted = text\n            converted = re.sub(r'\\bNone\\b', 'null', converted)\n            converted = re.sub(r'\\bTrue\\b', 'true', converted)\n            converted = re.sub(r'\\bFalse\\b', 'false', converted)\n            converted = converted.replace(\"'\", '\"')\n            return json.loads(converted)\n        except json.JSONDecodeError:\n            pass\n\n        # Если ничего не сработало — выбрасываем ошибку\n        raise json.JSONDecodeError(\n            f\"Не удалось распарсить ни как JSON, ни как Python dict\",\n            text,\n            0\n        )\n\n    def _normalize_input(self, raw_data: Any) -> Dict:\n        \"\"\"\n        🔄 НОРМАЛИЗАЦИЯ: Извлекает payload из Arbitrator output\n\n        Поддерживает форматы:\n        1. Arbitrator: {\"status\": \"SUCCESS\", \"payload\": {...}, \"ready_for_execution\": true}\n        2. Прямой Agent1: {\"operation\": \"...\", \"domain\": \"...\", ...}\n        3. Вложенный: {\"data\": {\"payload\": {...}}}\n        \"\"\"\n        if not isinstance(raw_data, dict):\n            return raw_data\n\n        # Случай 1: Arbitrator output с payload\n        if \"payload\" in raw_data and isinstance(raw_data[\"payload\"], dict):\n            # Проверяем что это успешный Arbitrator response\n            status = raw_data.get(\"status\", \"\").upper()\n            if status in [\"SUCCESS\", \"COMPLETE\", \"OK\"]:\n                return raw_data[\"payload\"]\n            # Даже если статус не SUCCESS, но payload есть — используем его\n            if raw_data[\"payload\"]:\n                return raw_data[\"payload\"]\n\n        # Случай 2: Вложенный data.payload\n        if \"data\" in raw_data and isinstance(raw_data[\"data\"], dict):\n            if \"payload\" in raw_data[\"data\"]:\n                return raw_data[\"data\"][\"payload\"]\n            return raw_data[\"data\"]\n\n        # Случай 3: Прямой Agent1 output (уже нормализован)\n        return raw_data\n\n    # ==========================================\n    # УНИВЕРСАЛЬНЫЕ МЕТОДЫ ИЗВЛЕЧЕНИЯ ДАННЫХ\n    # ==========================================\n    def _universal_extract_domains(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет домены во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        domains = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return domains\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"domain\", \"domains\", \"server_name\", \"server_names\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        domains.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                domains.append(item.strip())\n\n            for value in data.values():\n                domains.extend(self._universal_extract_domains(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                domains.extend(self._universal_extract_domains(item, visited))\n\n        return list(set([d for d in domains if d and self._looks_like_domain(d)]))\n\n    def _universal_extract_locations(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет location/locations во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        locations = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return locations\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"location\", \"locations\", \"kms_locations\", \"public_locations\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        locations.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                locations.append(item.strip())\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    locations.extend(self._universal_extract_locations(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                locations.extend(self._universal_extract_locations(item, visited))\n\n        return list(set([loc for loc in locations if loc and loc.startswith(\"/\")]))\n\n    def _universal_extract_ips(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет IP адреса во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        ips = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return ips\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"ip_addresses\", \"ips\", \"servers\", \"upstream\", \"ip\", \"address\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        ips.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                ips.append(item.strip())\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    ips.extend(self._universal_extract_ips(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                ips.extend(self._universal_extract_ips(item, visited))\n\n        return list(set([ip for ip in ips if ip and self._looks_like_ip(ip)]))\n\n    def _universal_extract_upstreams(self, data: Any, visited: Optional[set] = None) -> List[Dict]:\n        \"\"\"\n        🆕 Извлекает структурированные upstreams\n\n        Формат входа:\n        \"upstreams\": [\n            {\"upstream_type\": \"main\", \"ip_addresses\": [\"10.10.10.10\", ...], \"params\": []},\n            {\"upstream_type\": \"backup\", \"ip_addresses\": [...], \"params\": []}\n        ]\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        upstreams = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return upstreams\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            # Прямой ключ upstreams\n            if \"upstreams\" in data and isinstance(data[\"upstreams\"], list):\n                for upstream in data[\"upstreams\"]:\n                    if isinstance(upstream, dict):\n                        normalized = {\n                            \"type\": upstream.get(\"upstream_type\", upstream.get(\"type\", \"main\")),\n                            \"ip_addresses\": upstream.get(\"ip_addresses\", upstream.get(\"ips\", [])),\n                            \"params\": upstream.get(\"params\", upstream.get(\"parameters\", []))\n                        }\n                        if normalized[\"ip_addresses\"]:\n                            upstreams.append(normalized)\n\n            # Рекурсивный поиск\n            for key, value in data.items():\n                if key != \"upstreams\" and isinstance(value, (dict, list)):\n                    upstreams.extend(self._universal_extract_upstreams(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                upstreams.extend(self._universal_extract_upstreams(item, visited))\n\n        return upstreams\n\n    def _universal_extract_location_parameters(self, data: Any, visited: Optional[set] = None) -> List[Dict]:\n        \"\"\"\n        🆕 Извлекает параметры для конкретных locations\n\n        Формат входа:\n        \"location_parameters\": [\n            {\"location\": \"/api_V2/\", \"parameters\": [], \"kms_required\": false},\n            ...\n        ]\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        loc_params = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return loc_params\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            if \"location_parameters\" in data and isinstance(data[\"location_parameters\"], list):\n                for lp in data[\"location_parameters\"]:\n                    if isinstance(lp, dict) and \"location\" in lp:\n                        normalized = {\n                            \"location\": lp.get(\"location\"),\n                            \"parameters\": lp.get(\"parameters\", []),\n                            \"kms_required\": lp.get(\"kms_required\", False)\n                        }\n                        loc_params.append(normalized)\n\n            for key, value in data.items():\n                if key != \"location_parameters\" and isinstance(value, (dict, list)):\n                    loc_params.extend(self._universal_extract_location_parameters(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                loc_params.extend(self._universal_extract_location_parameters(item, visited))\n\n        return loc_params\n\n    def _universal_extract_parameters(self, data: Any, visited: Optional[set] = None) -> Dict:\n        \"\"\"\n        Ищет общие параметры в структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        parameters = {}\n\n        data_id = id(data)\n        if data_id in visited:\n            return parameters\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            # server_block_parameters\n            if \"server_block_parameters\" in data:\n                params = data[\"server_block_parameters\"]\n                if isinstance(params, list):\n                    parameters[\"server_block\"] = params\n                elif isinstance(params, dict):\n                    parameters[\"server_block\"] = params\n\n            # Общие parameters\n            if \"parameters\" in data:\n                params = data[\"parameters\"]\n                if isinstance(params, dict):\n                    parameters.update(params)\n                elif isinstance(params, list):\n                    parameters[\"general\"] = params\n\n            # Рекурсивно (но не в уже обработанные ключи)\n            for key, value in data.items():\n                if key not in [\"parameters\", \"server_block_parameters\", \"location_parameters\"] \\\n                        and isinstance(value, (dict, list)):\n                    sub_params = self._universal_extract_parameters(value, visited)\n                    for k, v in sub_params.items():\n                        if k not in parameters:\n                            parameters[k] = v\n\n        elif isinstance(data, list):\n            for item in data:\n                sub_params = self._universal_extract_parameters(item, visited)\n                parameters.update(sub_params)\n\n        return parameters\n\n    def _universal_extract_operation(self, data: Any) -> Optional[str]:\n        \"\"\"\n        Ищет тип операции в любой структуре\n        \"\"\"\n        if isinstance(data, dict):\n            for key in [\"operation\", \"operation_type\", \"action\", \"type\"]:\n                if key in data and data[key]:\n                    val = str(data[key])\n                    # Фильтруем не-операции\n                    if val.upper() not in [\"MAIN\", \"BACKUP\", \"PREFIX\", \"EXACT\"]:\n                        return val\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    result = self._universal_extract_operation(value)\n                    if result:\n                        return result\n\n        elif isinstance(data, list):\n            for item in data:\n                result = self._universal_extract_operation(item)\n                if result:\n                    return result\n\n        return None\n\n    def _universal_extract_selected_dc(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет selected_dc во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        dcs = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return dcs\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"selected_dc\", \"dc\", \"datacenters\", \"datacenter\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        dcs.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                dcs.append(item.strip())\n\n            for value in data.values():\n                dcs.extend(self._universal_extract_selected_dc(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                dcs.extend(self._universal_extract_selected_dc(item, visited))\n\n        return list(set(dcs))\n\n    def _check_status(self, data: Any) -> Optional[Dict]:\n        \"\"\"\n        Проверяет статус ошибки в данных\n        \"\"\"\n        if isinstance(data, dict):\n            status = data.get(\"status\", \"\")\n\n            # Ошибка Arbitrator\n            if status == \"VALIDATION_FAILED\":\n                return {\n                    \"is_error\": True,\n                    \"status\": status,\n                    \"error_type\": \"VALIDATION_FAILED\",\n                    \"error_message\": \"Валидация не прошла\",\n                    \"missing_fields\": data.get(\"missing_fields\", []),\n                    \"clarification_questions\": data.get(\"clarification_questions\", [])\n                }\n\n            # Ошибка Agent1\n            if status == \"error\":\n                return {\n                    \"is_error\": True,\n                    \"status\": data.get(\"status\"),\n                    \"error_type\": data.get(\"error_type\"),\n                    \"error_message\": data.get(\"error_message\"),\n                    \"explanation\": data.get(\"explanation\"),\n                    \"warnings\": data.get(\"warnings\", [])\n                }\n        return None\n\n    # ==========================================\n    # ВАЛИДАЦИЯ\n    # ==========================================\n    def _looks_like_domain(self, text: str) -> bool:\n        \"\"\"Проверяет, похоже ли на домен\"\"\"\n        if not text or len(text) < 3:\n            return False\n        return '.' in text or re.match(r'^[a-zA-Z0-9\\-\\.]+$', text) is not None\n\n    def _looks_like_ip(self, text: str) -> bool:\n        \"\"\"Проверяет, похоже ли на IP адрес\"\"\"\n        if not text:\n            return False\n        ip_pattern = r'^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}(:\\d+)?$'\n        return re.match(ip_pattern, text) is not None\n\n    # ==========================================\n    # ЛОГИКА ПОИСКА ПО ПАПКАМ И DC\n    # ==========================================\n    def _get_all_folders(self) -> List[str]:\n        \"\"\"Возвращает список всех возможных папок\"\"\"\n        return [\n            \"production_ext_kor_sites\",\n            \"production_ext_nag_http\",\n            \"production_ext_nag_sites\",\n            \"production_ext_sites\",\n            \"production_kor_ngate_sites\",\n            \"production_kor_sites\",\n            \"production_mesh_main_kor_sites\",\n            \"production_mesh_rus_kor_sites\",\n            \"production_metro_kor_sites\",\n            \"production_metro_sites\",\n            \"production_moshub_ext_kor_sites\",\n            \"production_moshub_kor_sites\",\n            \"production_nag_sites\",\n            \"production_sites\",\n            \"production_upload_sites\",\n            \"stage_kor_sites\",\n            \"stage_nag_sites\",\n            \"stage_sites\",\n            \"test_kor_sites\",\n            \"test_nag_sites\",\n            \"test_sites\"\n        ]\n\n    def _get_search_folders(self, selected_dc: List[str]) -> List[str]:\n        \"\"\"Определяет папки для поиска на основе selected_dc\"\"\"\n        all_folders = self._get_all_folders()\n        if not selected_dc:\n            return all_folders\n\n        search_folders = set()\n        for dc in selected_dc:\n            if dc == \"dr\":\n                search_folders.update(self._get_folders_for_dc(\"korovinskiy\"))\n                search_folders.update(self._get_folders_for_dc(\"kurchatovskiy\"))\n            else:\n                search_folders.update(self._get_folders_for_dc(dc))\n        return list(search_folders)\n\n    def _get_folders_for_dc(self, dc: str) -> List[str]:\n        \"\"\"Возвращает папки для конкретного DC\"\"\"\n        all_folders = self._get_all_folders()\n\n        if dc == \"korovinskiy\":\n            # Исключаем metro и mesh - они относятся к отдельным DC\n            return [f for f in all_folders\n                    if \"_kor_\" in f\n                    and \"metro\" not in f\n                    and \"mesh\" not in f]\n\n        elif dc == \"kurchatovskiy\":\n            return [f for f in all_folders if\n                    f in [\"production_sites\", \"stage_sites\", \"test_sites\", \"production_ext_sites\",\n                          \"production_upload_sites\"]]  # убрал production_metro_sites\n\n        elif dc == \"nagornaya\":\n            return [f for f in all_folders if \"_nag_\" in f]\n\n        elif dc == \"moshub_rus\":\n            return [f for f in all_folders if \"moshub\" in f and \"ext\" not in f]\n\n        elif dc == \"ext_kurchatovskiy\":\n            return [f for f in all_folders if \"ext\" in f and \"_kor_\" not in f and \"_nag_\" not in f]\n\n        elif dc == \"ext_korovinskiy\":\n            return [f for f in all_folders if \"ext\" in f and \"_kor_\" in f]\n\n        elif dc == \"ext_nagornaya\":\n            return [f for f in all_folders if \"ext\" in f and \"_nag_\" in f]\n\n        elif dc == \"mesh\":\n            return [f for f in all_folders if \"mesh\" in f]\n\n        elif dc == \"top10_kurchatovskiy\":\n            return [f for f in all_folders if \"metro\" in f and \"_kor_\" not in f]\n\n        elif dc == \"top10_korovinskiy\":\n            return [f for f in all_folders if \"metro\" in f and \"_kor_\" in f]\n\n        return []\n\n    def _infer_dc_from_folder(self, folder: str) -> List[str]:\n        \"\"\"Определяет DC на основе имени папки\"\"\"\n        dcs = []\n        folder_lower = folder.lower()\n        if \"_kor_\" in folder_lower:\n            dcs.append(\"korovinskiy\")\n        if \"_nag_\" in folder_lower:\n            dcs.append(\"nagornaya\")\n        if folder in [\"production_sites\", \"stage_sites\", \"test_sites\", \"production_ext_sites\", \"production_metro_sites\",\n                      \"production_upload_sites\"]:\n            dcs.append(\"kurchatovskiy\")\n        if \"mesh\" in folder_lower:\n            dcs.append(\"mesh\")\n        if \"moshub\" in folder_lower:\n            dcs.append(\"moshub_rus\")\n        if \"metro\" in folder_lower:\n            if \"_kor_\" in folder_lower:\n                dcs.append(\"top10_korovinskiy\")\n            else:\n                dcs.append(\"top10_kurchatovskiy\")\n        if \"ext\" in folder_lower:\n            if \"_kor_\" in folder_lower:\n                dcs.append(\"ext_korovinskiy\")\n            elif \"_nag_\" in folder_lower:\n                dcs.append(\"ext_nagornaya\")\n            else:\n                dcs.append(\"ext_kurchatovskiy\")\n        return list(set(dcs))\n\n    # ==========================================\n    # СКАНИРОВАНИЕ YML\n    # ==========================================\n    def _scan_yml_file(self, yml_file: str, target_domains: List[str]) -> List[Dict]:\n        \"\"\"Сканирует один YML файл и находит совпадения по server_name\"\"\"\n        results = []\n        try:\n            with open(yml_file, 'r', encoding='utf-8') as f:\n                config_text = f.read()\n                config_yaml = yaml.safe_load(config_text)\n            if not config_yaml:\n                return results\n            for config_key, config_block in config_yaml.items():\n                server_names = self._extract_server_names(config_block)\n                if not server_names:\n                    continue\n                matching_domains = []\n                for target_domain in target_domains:\n                    if self._is_domain_match(target_domain, server_names):\n                        matching_domains.append(target_domain)\n                if matching_domains:\n                    result = {\n                        \"config_key\": config_key,\n                        \"config_file\": yml_file,\n                        \"server_names\": server_names,\n                        \"matching_domains\": matching_domains,\n                        \"full_config_text\": config_text,\n                        \"parsed_yaml\": config_yaml,\n                        \"config_block\": config_block\n                    }\n                    results.append(result)\n        except yaml.YAMLError as e:\n            print(f\"⚠️ Ошибка чтения YAML {yml_file}: {e}\")\n        except Exception as e:\n            print(f\"⚠️ Ошибка обработки {yml_file}: {e}\")\n        return results\n\n    def _extract_server_names(self, config_block: Any) -> List[str]:\n        \"\"\"Извлекает все server_name из конфигурационного блока\"\"\"\n        server_names = []\n        if isinstance(config_block, list):\n            for item in config_block:\n                if isinstance(item, str) and item.startswith(\"server_name \"):\n                    server_name_part = item.replace(\"server_name \", \"\").strip()\n                    names = [n.strip() for n in server_name_part.split() if n.strip()]\n                    server_names.extend(names)\n        return list(set(server_names))\n\n    def _is_domain_match(self, target_domain: str, server_names: List[str]) -> bool:\n        \"\"\"Проверяет, совпадает ли target_domain с любым server_name\"\"\"\n        target_domain = target_domain.strip().lower()\n        for server_name in server_names:\n            server_name = server_name.strip().lower()\n            if server_name == target_domain:\n                return True\n            if server_name.startswith(\"~^\") and server_name.endswith(\"$\"):\n                pattern = server_name[2:-1]\n                try:\n                    if re.match(pattern, target_domain):\n                        return True\n                except re.error:\n                    continue\n        return False\n\n    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:\n        \"\"\"Удаляет дубликаты результатов\"\"\"\n        seen = set()\n        unique = []\n        for result in results:\n            key = (result[\"config_file\"], result[\"config_key\"])\n            if key not in seen:\n                seen.add(key)\n                unique.append(result)\n        return unique\n\n    # ==========================================\n    # ОБРАБОТКА ОШИБОК\n    # ==========================================\n    def _return_error_status(self, status: Dict, agent1_data: Any) -> Data:\n        \"\"\"Возвращает ошибку из статуса\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": status.get(\"error_type\", \"UNKNOWN_ERROR\"),\n            \"error_message\": status.get(\"error_message\", \"Unknown error\"),\n            \"explanation\": status.get(\"explanation\", \"\"),\n            \"warnings\": status.get(\"warnings\", []),\n            \"missing_fields\": status.get(\"missing_fields\", []),\n            \"clarification_questions\": status.get(\"clarification_questions\", []),\n            \"agent1_data\": agent1_data,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: {status.get('error_message')}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        questions = status.get(\"clarification_questions\", [])\n        missing = status.get(\"missing_fields\", [])\n\n        error_msg = f\"\"\"❌ **Ошибка**\n🔴 **Тип:** {status.get('error_type')}\n📝 **Сообщение:** {status.get('error_message')}\n\"\"\"\n        if missing:\n            error_msg += f\"\\n📋 **Не хватает:** {', '.join(missing[:3])}\"\n        if questions:\n            error_msg += f\"\\n❓ **Вопросы:** {questions[0]}\"\n        return Data(data=error_result, text=error_msg)\n\n    def _return_no_domains_error(self, agent1_data: Any, locations: List[str],\n                                 ip_addresses: List[str], parameters: Dict,\n                                 operation: Optional[str]) -> Data:\n        \"\"\"Возвращает ошибку об отсутствии доменов\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"NO_DOMAINS\",\n            \"error_message\": \"Домены не найдены в данных\",\n            \"agent1_data\": agent1_data,\n            \"operation\": operation,\n            \"locations\": locations,\n            \"ip_addresses\": ip_addresses,\n            \"parameters\": parameters,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": \"# Error: No domains specified\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        error_msg = f\"\"\"❌ **Ошибка: домен не указан**\n📋 **Что извлечено:**\n- Operation: {operation or 'N/A'}\n- Locations: {', '.join(locations[:3]) if locations else 'N/A'}\n- IPs: {', '.join(ip_addresses[:3]) if ip_addresses else 'N/A'}\n💡 Укажите домен явно в запросе.\n\"\"\"\n        return Data(data=error_result, text=error_msg)\n\n    def _return_not_found_error(self, domains: List[str], scanned_files: int,\n                                agent1_data: Any, locations: List[str],\n                                ip_addresses: List[str], parameters: Dict,\n                                operation: Optional[str]) -> Data:\n        \"\"\"Возвращает ошибку о ненайденной конфигурации\"\"\"\n        not_found_result = {\n            \"status\": \"not_found\",\n            \"error_type\": \"CONFIG_NOT_FOUND\",\n            \"error_message\": f\"Конфигурация не найдена для: {', '.join(domains)}\",\n            \"domains\": domains,\n            \"scanned_files\": scanned_files,\n            \"agent1_data\": agent1_data,\n            \"operation\": operation,\n            \"locations\": locations,\n            \"ip_addresses\": ip_addresses,\n            \"parameters\": parameters,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: Config not found for: {', '.join(domains)}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        error_msg = f\"\"\"❌ **Конфигурация не найдена**\n🔍 **Домены:** {', '.join(domains)}\n📊 **Просканировано:** {scanned_files} файлов\n\"\"\"\n        return Data(data=not_found_result, text=error_msg)\n\n    def _return_json_error(self, error: Exception, raw_json: str) -> Data:\n        \"\"\"Возвращает ошибку парсинга JSON\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"JSON_PARSE_ERROR\",\n            \"error_message\": f\"Ошибка парсинга JSON: {str(error)}\",\n            \"raw_input\": raw_json[:500],\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: JSON parse error\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        return Data(data=error_result, text=f\"❌ **Ошибка парсинга JSON**\\n\\n{str(error)}\")\n\n    def _return_unexpected_error(self, error: Exception) -> Data:\n        \"\"\"Возвращает неожиданную ошибку\"\"\"\n        import traceback\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"UNEXPECTED_ERROR\",\n            \"error_message\": f\"Неожиданная ошибка: {str(error)}\",\n            \"traceback\": traceback.format_exc(),\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: {str(error)}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        print(f\"❌ UNEXPECTED ERROR: {str(error)}\")\n        traceback.print_exc()\n        return Data(data=error_result, text=f\"❌ **Неожиданная ошибка**\\n\\n{str(error)}\")\n\n    # ==========================================\n    # ФОРМАТИРОВАНИЕ РЕЗУЛЬТАТА\n    # ==========================================\n    def _format_success_message(self, result: Dict) -> str:\n        \"\"\"Формирует читаемое сообщение о результате\"\"\"\n        all_configs = result.get(\"all_configs\", [])\n        found_configs = len(all_configs)\n        scanned_files = result.get(\"scanned_files\", 0)\n        operation = result.get(\"operation\")\n        locations = result.get(\"locations\", [])\n        upstreams = result.get(\"upstreams\", [])\n        location_parameters = result.get(\"location_parameters\", [])\n        selected_dc = result.get(\"selected_dc\", [])\n\n        # 🆕 Новые данные о multi-DC\n        found_in_multiple_dc = result.get(\"found_in_multiple_dc\", False)\n        dc_count = result.get(\"dc_count\", 0)\n        unique_dcs = result.get(\"unique_dcs\", [])\n        domains_in_multiple_dc = result.get(\"domains_in_multiple_dc\", [])\n        domain_dc_mapping = result.get(\"domain_dc_mapping\", {})\n\n        msg = f\"✅ **Найдено {found_configs} конфигурац{'ия' if found_configs == 1 else 'ий' if 2 <= found_configs <= 4 else 'ий'}**\\n\\n\"\n\n        # 🆕 Предупреждение о нескольких ЦОД\n        if found_in_multiple_dc:\n            msg += f\"⚠️ **ВНИМАНИЕ: Домен найден в {dc_count} ЦОД!**\\n\"\n            msg += f\"🏢 **ЦОД:** {', '.join(unique_dcs)}\\n\"\n            if domains_in_multiple_dc:\n                msg += f\"🌐 **Домены в нескольких ЦОД:** {', '.join(domains_in_multiple_dc)}\\n\"\n            msg += \"\\n\"\n\n        for i, cfg in enumerate(all_configs):\n            if i > 0:\n                msg += \"\\n\" + (\"-\" * 40) + \"\\n\\n\"\n            msg += f\"📁 **Файл:** `{os.path.basename(cfg['config_file'])}`\\n\"\n            server_names = cfg.get(\"server_names\", [])\n            msg += f\"🌐 **Server names:** {', '.join(server_names[:3])}{'...' if len(server_names) > 3 else ''}\\n\"\n            matching_domains = cfg.get(\"matching_domains\", [])\n            msg += f\"✅ **Совпадения:** {', '.join(matching_domains)}\\n\"\n            inferred_dc = cfg.get(\"inferred_dc\", [])\n            if inferred_dc:\n                msg += f\"🏢 **DC:** {', '.join(inferred_dc)}\\n\"\n            else:\n                msg += f\"🏢 **DC:** N/A\\n\"\n\n        msg += f\"\\n📊 **Просканировано:** {scanned_files} файлов\"\n\n        if selected_dc:\n            msg += f\"\\n🗺 **Selected DC:** {', '.join(selected_dc)}\"\n        if operation:\n            msg += f\"\\n🔄 **Operation:** {operation}\"\n        if locations:\n            msg += f\"\\n📍 **Locations:** {', '.join(locations[:5])}\"\n        if upstreams:\n            for up in upstreams[:2]:\n                ips = up.get(\"ip_addresses\", [])\n                up_type = up.get(\"type\", \"unknown\")\n                msg += f\"\\n🔗 **Upstream ({up_type}):** {', '.join(ips[:3])}\"\n        if location_parameters:\n            msg += f\"\\n⚙️ **Location params:** {len(location_parameters)} записей\"\n\n        # 🆕 Расширенное примечание\n        if found_in_multiple_dc:\n            msg += \"\\n\\n⚠️ **ВАЖНО:** Конфигурация найдена в нескольких ЦОД. \"\n            msg += \"Убедитесь, что изменения применяются ко всем необходимым площадкам!\"\n            # Детальный маппинг\n            if domain_dc_mapping:\n                msg += \"\\n\\n📋 **Детали по доменам:**\"\n                for domain, dcs in domain_dc_mapping.items():\n                    if len(dcs) > 1:\n                        msg += f\"\\n  • `{domain}` → {', '.join(dcs)}\"\n        elif found_configs > 1:\n            msg += \"\\n\\nℹ️ **Примечание:** Найдено несколько конфигураций. Проверьте все варианты.\"\n\n        return msg\n"
              },
              "config_base_path": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Config Base Path",
                "dynamic": false,
                "info": "Путь к родительской папке с конфигами (например, /path/to/mos_ru_nginx/)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "config_base_path",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/production_kor_sites"
              }
            },
            "tool_mode": false
          },
          "selected_output": "config_file_path",
          "showNode": true,
          "type": "UniversalSearchConfigComponent"
        },
        "dragging": false,
        "id": "UniversalSearchConfigComponent-3wswc",
        "measured": {
          "height": 317,
          "width": 320
        },
        "position": {
          "x": -178.25037854442857,
          "y": 535.1570145732131
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UpstreamConfigBlockSplitter-RP41F",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Splits upstream blocks, skips multi-DC domains with warnings",
            "display_name": "Upstream Config Block Splitter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "selected_block"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Config Items DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "build_config_dataframe",
                "name": "config_items_df",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Total Count",
                "group_outputs": false,
                "hidden": null,
                "method": "build_total_count",
                "name": "total_count",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Metadata",
                "group_outputs": false,
                "hidden": null,
                "method": "build_metadata",
                "name": "metadata",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Warnings",
                "group_outputs": false,
                "hidden": null,
                "method": "build_warnings",
                "name": "warnings_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\nimport json\nimport pandas as pd\nfrom typing import Union, List, Dict, Any\n\n\nclass UpstreamConfigBlockSplitter(Component):\n    \"\"\"\n    Splits upstream config blocks into DataFrame for Loop processing.\n    Includes location_path, operation, upstreams, and agent1_data.\n    Skips domains in multiple DCs and generates warnings.\n    \"\"\"\n\n    display_name = \"Upstream Config Block Splitter\"\n    description = \"Splits upstream blocks, skips multi-DC domains with warnings\"\n    documentation = \"\"\n    icon = \"split\"\n\n    inputs = [\n        HandleInput(\n            name=\"selected_block\",\n            display_name=\"Selected Block\",\n            input_types=[\"Message\", \"Data\", \"dict\"],\n            info=\"Output from UpstreamExtractor containing upstreams\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Config Items DataFrame\",\n            name=\"config_items_df\",\n            info=\"DataFrame with location_path, operation, upstreams, agent1_data\",\n            method=\"build_config_dataframe\",\n        ),\n        Output(\n            display_name=\"Total Count\",\n            name=\"total_count\",\n            info=\"Total number of blocks to process\",\n            method=\"build_total_count\",\n        ),\n        Output(\n            display_name=\"Metadata\",\n            name=\"metadata\",\n            info=\"Metadata including warnings for multi-DC domains\",\n            method=\"build_metadata\",\n        ),\n        Output(\n            display_name=\"Warnings\",\n            name=\"warnings_output\",\n            info=\"All warnings including multi-DC skipped domains\",\n            method=\"build_warnings\",\n        ),\n    ]\n\n    def process_input_data(self, data: Union[Message, Data, dict, str]) -> dict:\n        \"\"\"Convert input to dictionary format\"\"\"\n        try:\n            if isinstance(data, Message):\n                text = data.text if hasattr(data, 'text') else str(data)\n                return json.loads(text)\n            elif isinstance(data, Data):\n                if hasattr(data, 'data'):\n                    data_content = data.data\n                    if isinstance(data_content, str):\n                        return json.loads(data_content)\n                    return data_content\n                elif hasattr(data, 'to_dict'):\n                    return data.to_dict()\n                else:\n                    return dict(data)\n            elif isinstance(data, dict):\n                return data\n            elif isinstance(data, str):\n                return json.loads(data)\n            else:\n                raise ValueError(f\"Unexpected input type: {type(data)}\")\n        except json.JSONDecodeError as e:\n            self.log(f\"JSON decode error: {str(e)}\")\n            raise ValueError(f\"Invalid JSON in input: {str(e)}\")\n        except Exception as e:\n            self.log(f\"Error processing input: {str(e)}\")\n            raise\n\n    def extract_config_blocks(self, input_data: dict) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n        \"\"\"\n        Extract config blocks from input data.\n        Returns tuple: (blocks_to_process, warnings)\n        Skips domains that are in multiple DCs.\n        \"\"\"\n        \n        warnings = input_data.get('warnings', []).copy()  # Копируем существующие warnings\n        \n        # Получаем информацию о multi-DC\n        domains_in_multiple_dc = set(input_data.get('domains_in_multiple_dc', []))\n        domain_dc_mapping = input_data.get('domain_dc_mapping', {})\n        \n        self.log(f\"🔍 Domains in multiple DC: {domains_in_multiple_dc}\")\n        \n        # Сначала пробуем найти selected_blocks (старый формат)\n        if 'selected_blocks' in input_data:\n            blocks = input_data['selected_blocks']\n            if isinstance(blocks, list):\n                return self._filter_multi_dc_blocks(blocks, domains_in_multiple_dc, domain_dc_mapping, warnings)\n            elif isinstance(blocks, dict):\n                return self._filter_multi_dc_blocks([blocks], domains_in_multiple_dc, domain_dc_mapping, warnings)\n        \n        # Если есть массив upstreams на верхнем уровне (новый формат от UpstreamExtractor)\n        if 'upstreams' in input_data and isinstance(input_data['upstreams'], list):\n            blocks = []\n            operation = input_data.get('operation', 'MODIFY_UPSTREAM')\n            \n            # Получаем agent1_data\n            agent1_data = input_data.get('agent1_data', {})\n            \n            # Извлекаем payload из agent1_data\n            payload = agent1_data.get('payload', [])\n            \n            # Создаём маппинг domain -> payload_item\n            domain_to_payload = {}\n            for item in payload:\n                domain = item.get('domain', '')\n                if domain:\n                    domain_to_payload[domain] = item\n            \n            self.log(f\"📋 Found {len(payload)} items in agent1_data.payload\")\n            \n            # Для каждого upstream создаем блок\n            for upstream in input_data['upstreams']:\n                domain = upstream.get('domain', '')\n                location = upstream.get('location', '/')\n                \n                # ПРОВЕРКА НА MULTI-DC\n                if domain in domains_in_multiple_dc:\n                    dcs = domain_dc_mapping.get(domain, [])\n                    warning = {\n                        \"type\": \"MULTI_DC_SKIPPED\",\n                        \"domain\": domain,\n                        \"location\": location,\n                        \"datacenters\": dcs,\n                        \"upstream_name\": upstream.get('upstream_name', ''),\n                        \"message\": f\"⚠️ Домен {domain} пропущен: найден в нескольких ЦОД ({', '.join(dcs)}). Требуется ручная обработка или выбор конкретного ЦОД.\",\n                        \"action_required\": True\n                    }\n                    warnings.append(warning)\n                    self.log(f\"⚠️ SKIPPED: {domain} is in multiple DCs: {dcs}\")\n                    continue  # Пропускаем этот upstream\n                \n                # Находим соответствующий payload item для этого домена\n                payload_item = domain_to_payload.get(domain, {})\n                \n                # Извлекаем данные из payload_item\n                from_location = payload_item.get('from_location')\n                to_location = payload_item.get('to_location')\n                requested_upstreams = payload_item.get('upstreams', [])\n                \n                block = {\n                    'location_path': location,\n                    'domain': domain,\n                    'operation': operation,\n                    'upstream_name': upstream.get('upstream_name', ''),\n                    'upstream_config': upstream.get('upstream_config', {}),\n                    'from_location': from_location,\n                    'to_location': to_location,\n                    'upstreams': [upstream],\n                    'payload_item': payload_item,\n                    'requested_upstreams': requested_upstreams,\n                    'config_info': upstream.get('config_info', {}),\n                }\n                blocks.append(block)\n                self.log(f\"✅ Added block for {domain}{location}: upstream={upstream.get('upstream_name')}\")\n            \n            self.log(f\"📊 Extracted {len(blocks)} blocks (skipped {len(domains_in_multiple_dc)} multi-DC domains)\")\n            return blocks, warnings\n        \n        # Пробуем найти в поле selected_block\n        if 'selected_block' in input_data:\n            block_data = input_data['selected_block']\n            if isinstance(block_data, list):\n                return self._filter_multi_dc_blocks(block_data, domains_in_multiple_dc, domain_dc_mapping, warnings)\n            elif isinstance(block_data, dict):\n                if 'selected_blocks' in block_data:\n                    return self._filter_multi_dc_blocks(\n                        block_data['selected_blocks'], \n                        domains_in_multiple_dc, \n                        domain_dc_mapping, \n                        warnings\n                    )\n                elif 'upstreams' in block_data:\n                    return self.extract_config_blocks(block_data)\n        \n        self.log(\"⚠️ Warning: No config blocks found in input data\")\n        return [], warnings\n\n    def _filter_multi_dc_blocks(\n        self, \n        blocks: List[Dict], \n        domains_in_multiple_dc: set, \n        domain_dc_mapping: dict,\n        warnings: List[Dict]\n    ) -> tuple[List[Dict], List[Dict]]:\n        \"\"\"Filter out blocks for domains in multiple DCs\"\"\"\n        filtered_blocks = []\n        \n        for block in blocks:\n            domain = block.get('domain', '')\n            \n            if domain in domains_in_multiple_dc:\n                dcs = domain_dc_mapping.get(domain, [])\n                warning = {\n                    \"type\": \"MULTI_DC_SKIPPED\",\n                    \"domain\": domain,\n                    \"location\": block.get('location_path', block.get('location', '/')),\n                    \"datacenters\": dcs,\n                    \"message\": f\"⚠️ Домен {domain} пропущен: найден в нескольких ЦОД ({', '.join(dcs)}). Требуется ручная обработка.\",\n                    \"action_required\": True\n                }\n                warnings.append(warning)\n                self.log(f\"⚠️ SKIPPED: {domain} is in multiple DCs: {dcs}\")\n            else:\n                filtered_blocks.append(block)\n        \n        return filtered_blocks, warnings\n\n    def build_config_dataframe(self) -> DataFrame:\n        \"\"\"Convert config blocks into DataFrame, excluding multi-DC domains\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n            \n            if 'error' in input_data and not input_data.get('upstreams') and not input_data.get('selected_blocks'):\n                self.log(f\"Error in input data: {input_data.get('error')}\")\n                return DataFrame(pd.DataFrame(columns=['error'], data=[{'error': input_data.get('error')}]))\n            \n            config_blocks, warnings = self.extract_config_blocks(input_data)\n            \n            # Сохраняем warnings для других outputs\n            self._cached_warnings = warnings\n            self._cached_input_data = input_data\n            \n            if not config_blocks:\n                # Проверяем, есть ли пропущенные из-за multi-DC\n                multi_dc_warnings = [w for w in warnings if w.get('type') == 'MULTI_DC_SKIPPED']\n                \n                if multi_dc_warnings:\n                    self.log(f\"⚠️ All domains skipped due to multi-DC. Warnings: {len(multi_dc_warnings)}\")\n                    # Возвращаем DataFrame с информацией о пропуске\n                    return DataFrame(pd.DataFrame(columns=[\n                        'index', 'location_path', 'operation', 'upstreams', 'agent1_data', 'status'\n                    ], data=[{\n                        'index': 0,\n                        'location_path': '',\n                        'operation': input_data.get('operation', ''),\n                        'upstreams': '{}',\n                        'agent1_data': json.dumps({\n                            'skipped_reason': 'multi_dc',\n                            'warnings': multi_dc_warnings\n                        }),\n                        'status': 'SKIPPED_MULTI_DC'\n                    }]))\n                \n                self.log(\"No config blocks found, returning empty DataFrame\")\n                return DataFrame(pd.DataFrame(columns=[\n                    'index', 'location_path', 'operation', 'upstreams', 'agent1_data'\n                ]))\n            \n            # Получаем общие данные\n            agent1_data = input_data.get('agent1_data', {})\n            \n            # DataFrame с расширенной структурой\n            df_data = []\n            for idx, block in enumerate(config_blocks):\n                if not isinstance(block, dict):\n                    self.log(f\"Warning: Block {idx} is not a dict, skipping\")\n                    continue\n                \n                # Обрабатываем upstreams\n                upstreams_data = block.get('upstreams', [])\n                domain = block.get('domain', '')\n                \n                # Формируем данные upstream для агента\n                if upstreams_data and isinstance(upstreams_data[0], dict) and 'upstream_config' in upstreams_data[0]:\n                    upstream_obj = upstreams_data[0]\n                    agent_upstream_data = {\n                        'upstream_name': upstream_obj.get('upstream_name', ''),\n                        'main_servers': upstream_obj.get('upstream_config', {}).get('main', {}).get('servers', []),\n                        'backup_servers': upstream_obj.get('upstream_config', {}).get('backup', {}).get('servers', []),\n                        'domains': upstream_obj.get('upstream_config', {}).get('domains', []),\n                        'system_id': upstream_obj.get('upstream_config', {}).get('system_id', ''),\n                        'environment': upstream_obj.get('upstream_config', {}).get('environment', ''),\n                    }\n                    upstreams_json = json.dumps(agent_upstream_data, ensure_ascii=False)\n                else:\n                    upstreams_json = json.dumps(upstreams_data, ensure_ascii=False)\n                \n                # Формируем agent1_info из payload_item\n                payload_item = block.get('payload_item', {})\n                requested_upstreams = block.get('requested_upstreams', [])\n                \n                agent1_info = {\n                    'domain': domain,\n                    'domains': [domain] if domain else [],\n                    'location': block.get('location_path', '/'),\n                    'requested_upstreams': requested_upstreams,\n                    'preserve_directives': payload_item.get('preserve_directives', True),\n                    'parameters': payload_item.get('parameters', []),\n                    'location_parameters': payload_item.get('location_parameters', []),\n                    'server_block_parameters': payload_item.get('server_block_parameters', []),\n                    'kms_mentioned': payload_item.get('kms_mentioned', False),\n                    'kms_locations': payload_item.get('kms_locations', []),\n                    'public_locations': payload_item.get('public_locations', []),\n                    'data_complete': payload_item.get('data_complete', True),\n                    'from_location': block.get('from_location'),\n                    'to_location': block.get('to_location'),\n                    'confidence': payload_item.get('confidence', 0),\n                    'warnings': payload_item.get('warnings', []),\n                    'ambiguities': payload_item.get('ambiguities', []),\n                    'config_info': block.get('config_info', {}),\n                }\n\n                row = {\n                    'index': idx,\n                    'domain': domain,\n                    'location_path': block.get('location_path', '/'),\n                    'operation': block.get('operation', input_data.get('operation', 'MODIFY_UPSTREAM')),\n                    'upstreams': upstreams_json,\n                    'agent1_data': json.dumps(agent1_info, ensure_ascii=False),\n                }\n                df_data.append(row)\n            \n            if not df_data:\n                self.log(\"No valid blocks processed, returning empty DataFrame\")\n                return DataFrame(pd.DataFrame(columns=['error'], data=[{'error': 'No valid blocks to process'}]))\n            \n            df = pd.DataFrame(df_data)\n            self.log(f\"✅ Created DataFrame with {len(df)} rows (excluded {len([w for w in warnings if w.get('type') == 'MULTI_DC_SKIPPED'])} multi-DC domains)\")\n            \n            return DataFrame(df)\n            \n        except Exception as e:\n            error_msg = f\"Error building DataFrame: {str(e)}\"\n            self.log(error_msg)\n            import traceback\n            self.log(f\"Traceback: {traceback.format_exc()}\")\n            return DataFrame(pd.DataFrame(columns=['error'], data=[{'error': error_msg}]))\n\n    def build_total_count(self) -> Data:\n        \"\"\"Return total count of config blocks (excluding multi-DC)\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n            config_blocks, warnings = self.extract_config_blocks(input_data)\n            \n            # Считаем пропущенные\n            multi_dc_skipped = [w for w in warnings if w.get('type') == 'MULTI_DC_SKIPPED']\n            \n            # Извлекаем информацию о locations\n            agent1_data = input_data.get('agent1_data', {})\n            primary_location = agent1_data.get('location', '')\n            additional_locations = agent1_data.get('locations', [])\n            \n            count_data = {\n                \"total_blocks\": len(config_blocks),\n                \"skipped_multi_dc\": len(multi_dc_skipped),\n                \"total_with_skipped\": len(config_blocks) + len(multi_dc_skipped),\n                \"has_data\": len(config_blocks) > 0,\n                \"has_skipped\": len(multi_dc_skipped) > 0,\n                \"operation\": input_data.get(\"operation\", \"\"),\n                \"upstream_processing_needed\": input_data.get(\"upstream_processing_needed\", False),\n                \"config_file\": input_data.get(\"config_file\", \"\"),\n                \"config_key\": input_data.get(\"config_key\", \"\"),\n                \"primary_location\": primary_location,\n                \"all_locations\": [primary_location] + additional_locations if primary_location else additional_locations,\n                \"skipped_domains\": [w.get('domain') for w in multi_dc_skipped],\n            }\n            \n            return Data(data=count_data)\n            \n        except Exception as e:\n            error_msg = f\"Error getting total count: {str(e)}\"\n            self.log(error_msg)\n            return Data(data={\"total_blocks\": 0, \"has_data\": False, \"error\": error_msg})\n\n    def build_metadata(self) -> Data:\n        \"\"\"Extract and return metadata including multi-DC info\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n            config_blocks, warnings = self.extract_config_blocks(input_data)\n            \n            multi_dc_skipped = [w for w in warnings if w.get('type') == 'MULTI_DC_SKIPPED']\n            \n            metadata = {\n                \"status\": input_data.get(\"status\", \"\"),\n                \"operation\": input_data.get(\"operation\", \"\"),\n                \"upstream_processing_needed\": input_data.get(\"upstream_processing_needed\", False),\n                \"config_file\": input_data.get(\"config_file\", \"\"),\n                \"config_key\": input_data.get(\"config_key\", \"\"),\n                # Multi-DC info\n                \"found_in_multiple_dc\": input_data.get(\"found_in_multiple_dc\", False),\n                \"domains_in_multiple_dc\": input_data.get(\"domains_in_multiple_dc\", []),\n                \"domain_dc_mapping\": input_data.get(\"domain_dc_mapping\", {}),\n                \"unique_dcs\": input_data.get(\"unique_dcs\", []),\n                \"dc_count\": input_data.get(\"dc_count\", 1),\n                # Processing stats\n                \"blocks_to_process\": len(config_blocks),\n                \"blocks_skipped_multi_dc\": len(multi_dc_skipped),\n                \"has_warnings\": len(warnings) > 0,\n                \"warnings_count\": len(warnings),\n            }\n            \n            # Добавляем данные agent1 если есть\n            if 'agent1_data' in input_data:\n                metadata['agent1_data'] = input_data['agent1_data']\n            \n            # Добавляем full_config_data если нужно\n            if 'full_config_data' in input_data:\n                metadata['has_full_config'] = True\n                metadata['server_names'] = input_data.get('full_config_data', {}).get('server_names', [])\n            \n            if 'error' in input_data:\n                metadata['error'] = input_data['error']\n            \n            return Data(data=metadata)\n            \n        except Exception as e:\n            error_msg = f\"Error extracting metadata: {str(e)}\"\n            self.log(error_msg)\n            return Data(data={\"error\": error_msg})\n\n    def build_warnings(self) -> Data:\n        \"\"\"Return all warnings including multi-DC skipped domains\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n            _, warnings = self.extract_config_blocks(input_data)\n            \n            # Группируем warnings по типу\n            multi_dc_warnings = [w for w in warnings if w.get('type') == 'MULTI_DC_SKIPPED']\n            other_warnings = [w for w in warnings if w.get('type') != 'MULTI_DC_SKIPPED']\n            \n            # Формируем человекочитаемое сообщение\n            summary_messages = []\n            \n            if multi_dc_warnings:\n                domains = [w.get('domain') for w in multi_dc_warnings]\n                summary_messages.append(\n                    f\"⚠️ ВНИМАНИЕ: {len(multi_dc_warnings)} домен(ов) пропущено из-за наличия в нескольких ЦОД: {', '.join(domains)}. \"\n                    f\"Для этих доменов требуется выбрать конкретный ЦОД или обработать вручную.\"\n                )\n            \n            if other_warnings:\n                summary_messages.append(f\"ℹ️ Дополнительные предупреждения: {len(other_warnings)}\")\n            \n            warnings_data = {\n                \"has_warnings\": len(warnings) > 0,\n                \"total_warnings\": len(warnings),\n                \"multi_dc_warnings\": multi_dc_warnings,\n                \"multi_dc_count\": len(multi_dc_warnings),\n                \"other_warnings\": other_warnings,\n                \"other_count\": len(other_warnings),\n                \"all_warnings\": warnings,\n                \"summary\": \"\\n\".join(summary_messages) if summary_messages else \"✅ Нет предупреждений\",\n                \"action_required\": any(w.get('action_required', False) for w in warnings),\n                \"skipped_domains\": [w.get('domain') for w in multi_dc_warnings],\n            }\n            \n            if multi_dc_warnings:\n                self.log(f\"⚠️ Generated {len(multi_dc_warnings)} multi-DC warnings\")\n            \n            return Data(data=warnings_data)\n            \n        except Exception as e:\n            error_msg = f\"Error building warnings: {str(e)}\"\n            self.log(error_msg)\n            return Data(data={\n                \"has_warnings\": True,\n                \"error\": error_msg,\n                \"all_warnings\": [{\"type\": \"ERROR\", \"message\": error_msg}]\n            })"
              },
              "selected_block": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Selected Block",
                "dynamic": false,
                "info": "Output from UpstreamExtractor containing upstreams",
                "input_types": [
                  "Message",
                  "Data",
                  "dict"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "selected_block",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "config_items_df",
          "showNode": true,
          "type": "UpstreamConfigBlockSplitter"
        },
        "dragging": false,
        "id": "UpstreamConfigBlockSplitter-RP41F",
        "measured": {
          "height": 181,
          "width": 320
        },
        "position": {
          "x": 771.7810354519484,
          "y": 607.023087841694
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-vfp3E",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template with safe handling of missing keys.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": true,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep",
              "missing_key_placeholder"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "hidden": null,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template with safe handling of missing keys.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data. Missing keys will be replaced with 'None'.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n        MessageTextInput(\n            name=\"missing_key_placeholder\",\n            display_name=\"Missing Key Placeholder\",\n            advanced=True,\n            value=\"None\",\n            info=\"Text to use when a template key is not found in the data.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def safe_format(self, template: str, data_dict: dict) -> str:\n        \"\"\"\n        Safely format template by replacing missing keys with placeholder.\n        \n        Args:\n            template: Template string with {key} placeholders\n            data_dict: Dictionary with data to substitute\n            \n        Returns:\n            Formatted string with missing keys replaced by placeholder\n        \"\"\"\n        import re\n        \n        # Find all {key} patterns in template\n        pattern = r'\\{([^}]+)\\}'\n        keys = re.findall(pattern, template)\n        \n        # Create safe dict with placeholders for missing keys\n        safe_dict = {}\n        for key in keys:\n            if key in data_dict:\n                safe_dict[key] = data_dict[key]\n            else:\n                safe_dict[key] = self.missing_key_placeholder or \"None\"\n                self.log(f\"Warning: Key '{key}' not found in data, using placeholder\")\n        \n        try:\n            return template.format(**safe_dict)\n        except KeyError as e:\n            self.log(f\"Error formatting template: {e}\")\n            # Fallback: return template as-is\n            return template\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.safe_format(self.pattern, row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.safe_format(self.pattern, data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data, clean_data=self.clean_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "missing_key_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Missing Key Placeholder",
                "dynamic": false,
                "info": "Text to use when a template key is not found in the data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "missing_key_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "None"
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data. Missing keys will be replaced with 'None'.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-vfp3E",
        "measured": {
          "height": 343,
          "width": 320
        },
        "position": {
          "x": 1195.3706676832853,
          "y": 1307.5929891757823
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-Ciqh9",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003169567463043492,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-Ciqh9",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 1610.6709991495493,
          "y": 1605.2797354640677
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 5.664384450845375,
      "y": 84.45084214582016,
      "zoom": 0.47764146819121883
    }
  },
  "description": "Language Architect at Work!",
  "endpoint_name": null,
  "id": "7823d652-1b0a-4f86-b10a-0d96a73eccb9",
  "is_component": false,
  "last_tested_version": "1.6.0",
  "name": "YAML Processing Subflow Upstreams",
  "tags": []
}