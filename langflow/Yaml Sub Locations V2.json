{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UniversalSearchConfigComponent",
            "id": "UniversalSearchConfigComponent-arR45",
            "name": "config_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "universal_search_result",
            "id": "LocationSelectorFromUniversalSearch-ubEWV",
            "inputTypes": [
              "Data",
              "dict"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-UniversalSearchConfigComponent-arR45{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-arR45œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}-LocationSelectorFromUniversalSearch-ubEWV{œfieldNameœ:œuniversal_search_resultœ,œidœ:œLocationSelectorFromUniversalSearch-ubEWVœ,œinputTypesœ:[œDataœ,œdictœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UniversalSearchConfigComponent-arR45",
        "sourceHandle": "{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-arR45œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "LocationSelectorFromUniversalSearch-ubEWV",
        "targetHandle": "{œfieldNameœ:œuniversal_search_resultœ,œidœ:œLocationSelectorFromUniversalSearch-ubEWVœ,œinputTypesœ:[œDataœ,œdictœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UniversalSearchConfigComponent",
            "id": "UniversalSearchConfigComponent-arR45",
            "name": "config_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-nEXtH",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-UniversalSearchConfigComponent-arR45{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-arR45œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}-ParserComponent-nEXtH{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-nEXtHœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UniversalSearchConfigComponent-arR45",
        "sourceHandle": "{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-arR45œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-nEXtH",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-nEXtHœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-2rVDq",
            "name": "false_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "selected_block",
            "id": "ConfigBlockSplitter-2XuY9",
            "inputTypes": [
              "Message",
              "Data",
              "dict"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-2rVDq{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-2rVDqœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-ConfigBlockSplitter-2XuY9{œfieldNameœ:œselected_blockœ,œidœ:œConfigBlockSplitter-2XuY9œ,œinputTypesœ:[œMessageœ,œDataœ,œdictœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-2rVDq",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-2rVDqœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConfigBlockSplitter-2XuY9",
        "targetHandle": "{œfieldNameœ:œselected_blockœ,œidœ:œConfigBlockSplitter-2XuY9œ,œinputTypesœ:[œMessageœ,œDataœ,œdictœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LocationSelectorFromUniversalSearch",
            "id": "LocationSelectorFromUniversalSearch-ubEWV",
            "name": "selected_block",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-2rVDq",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-LocationSelectorFromUniversalSearch-ubEWV{œdataTypeœ:œLocationSelectorFromUniversalSearchœ,œidœ:œLocationSelectorFromUniversalSearch-ubEWVœ,œnameœ:œselected_blockœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-2rVDq{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-2rVDqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "LocationSelectorFromUniversalSearch-ubEWV",
        "sourceHandle": "{œdataTypeœ:œLocationSelectorFromUniversalSearchœ,œidœ:œLocationSelectorFromUniversalSearch-ubEWVœ,œnameœ:œselected_blockœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-2rVDq",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-2rVDqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LocationSelectorFromUniversalSearch",
            "id": "LocationSelectorFromUniversalSearch-ubEWV",
            "name": "selected_block",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "false_case_message",
            "id": "ConditionalRouter-2rVDq",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-LocationSelectorFromUniversalSearch-ubEWV{œdataTypeœ:œLocationSelectorFromUniversalSearchœ,œidœ:œLocationSelectorFromUniversalSearch-ubEWVœ,œnameœ:œselected_blockœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-2rVDq{œfieldNameœ:œfalse_case_messageœ,œidœ:œConditionalRouter-2rVDqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "LocationSelectorFromUniversalSearch-ubEWV",
        "sourceHandle": "{œdataTypeœ:œLocationSelectorFromUniversalSearchœ,œidœ:œLocationSelectorFromUniversalSearch-ubEWVœ,œnameœ:œselected_blockœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-2rVDq",
        "targetHandle": "{œfieldNameœ:œfalse_case_messageœ,œidœ:œConditionalRouter-2rVDqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-fKVaX",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-YRAOB",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt Template-fKVaX{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-fKVaXœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-YRAOB{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-YRAOBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-fKVaX",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-fKVaXœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-YRAOB",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-YRAOBœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConfigBlockSplitter",
            "id": "ConfigBlockSplitter-2XuY9",
            "name": "config_items_df",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "LoopComponent-d2QMY",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ConfigBlockSplitter-2XuY9{œdataTypeœ:œConfigBlockSplitterœ,œidœ:œConfigBlockSplitter-2XuY9œ,œnameœ:œconfig_items_dfœ,œoutput_typesœ:[œDataFrameœ]}-LoopComponent-d2QMY{œfieldNameœ:œdataœ,œidœ:œLoopComponent-d2QMYœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConfigBlockSplitter-2XuY9",
        "sourceHandle": "{œdataTypeœ:œConfigBlockSplitterœ,œidœ:œConfigBlockSplitter-2XuY9œ,œnameœ:œconfig_items_dfœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "LoopComponent-d2QMY",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œLoopComponent-d2QMYœ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-d2QMY",
            "name": "item",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-t5AFB",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-LoopComponent-d2QMY{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-d2QMYœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}-ParserComponent-t5AFB{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-t5AFBœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopComponent-d2QMY",
        "sourceHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-d2QMYœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-t5AFB",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-t5AFBœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "config_file",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œconfig_fileœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œconfig_fileœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "config_key",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œconfig_keyœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œconfig_keyœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "create_mode",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œcreate_modeœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œcreate_modeœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "directives",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œdirectivesœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œdirectivesœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "existing_locations",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œexisting_locationsœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œexisting_locationsœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "hash",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œhashœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œhashœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "index",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œindexœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œindexœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "kms_required",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œkms_requiredœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œkms_requiredœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "server_names",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œserver_namesœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œserver_namesœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "matching_domains",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œmatching_domainsœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œmatching_domainsœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "location_path",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œlocation_pathœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œlocation_pathœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "operation",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œoperationœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œoperationœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "new_location_path",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œnew_location_pathœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œnew_location_pathœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "parameters",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œparametersœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œparametersœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "type",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œtypeœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œtypeœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "warnings",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œwarningsœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œwarningsœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "ip_addresses",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œip_addressesœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œip_addressesœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-nmFh0",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-W4PmL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-JSONCleaner-nmFh0{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-W4PmL{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-W4PmLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "JSONCleaner-nmFh0",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-W4PmL",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-W4PmLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-nmFh0",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "true_case_message",
            "id": "ConditionalRouter-W4PmL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-JSONCleaner-nmFh0{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-W4PmL{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-W4PmLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "JSONCleaner-nmFh0",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-W4PmL",
        "targetHandle": "{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-W4PmLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-nmFh0",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-H6W2e",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-JSONCleaner-nmFh0{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-H6W2e{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-H6W2eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "JSONCleaner-nmFh0",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-H6W2e",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-H6W2eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-nmFh0",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "true_case_message",
            "id": "ConditionalRouter-H6W2e",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-JSONCleaner-nmFh0{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-H6W2e{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-H6W2eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "JSONCleaner-nmFh0",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-H6W2e",
        "targetHandle": "{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-H6W2eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-iJJfy",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "json_str",
            "id": "JSONCleaner-nmFh0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-iJJfy{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-iJJfyœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-JSONCleaner-nmFh0{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-nmFh0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-iJJfy",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-iJJfyœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "JSONCleaner-nmFh0",
        "targetHandle": "{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-nmFh0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ArbitratorComponent",
            "id": "ArbitratorComponent-vBetm",
            "name": "result",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-iJJfy",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ArbitratorComponent-vBetm{œdataTypeœ:œArbitratorComponentœ,œidœ:œArbitratorComponent-vBetmœ,œnameœ:œresultœ,œoutput_typesœ:[œDataœ]}-ParserComponent-iJJfy{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-iJJfyœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ArbitratorComponent-vBetm",
        "sourceHandle": "{œdataTypeœ:œArbitratorComponentœ,œidœ:œArbitratorComponent-vBetmœ,œnameœ:œresultœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-iJJfy",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-iJJfyœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-KPVE4",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-bWTwE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt Template-KPVE4{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-KPVE4œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-bWTwE{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-bWTwEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-KPVE4",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-KPVE4œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-bWTwE",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-bWTwEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-2l30o",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_output",
            "id": "ArbitratorComponent-vBetm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-JSONCleaner-2l30o{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-2l30oœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ArbitratorComponent-vBetm{œfieldNameœ:œagent1_outputœ,œidœ:œArbitratorComponent-vBetmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "JSONCleaner-2l30o",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-2l30oœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ArbitratorComponent-vBetm",
        "targetHandle": "{œfieldNameœ:œagent1_outputœ,œidœ:œArbitratorComponent-vBetmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-2l30o",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_json",
            "id": "Prompt Template-KPVE4",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-JSONCleaner-2l30o{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-2l30oœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-KPVE4{œfieldNameœ:œagent1_jsonœ,œidœ:œPrompt Template-KPVE4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "JSONCleaner-2l30o",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-2l30oœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-KPVE4",
        "targetHandle": "{œfieldNameœ:œagent1_jsonœ,œidœ:œPrompt Template-KPVE4œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-WqHOE",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "json_str",
            "id": "JSONCleaner-2l30o",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-WqHOE{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WqHOEœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-JSONCleaner-2l30o{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-2l30oœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-WqHOE",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-WqHOEœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "JSONCleaner-2l30o",
        "targetHandle": "{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-2l30oœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-9jjXZ",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-WqHOE",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt Template-9jjXZ{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-9jjXZœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-WqHOE{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-WqHOEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-9jjXZ",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-9jjXZœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-WqHOE",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-WqHOEœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-KA7o9",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt Template-9jjXZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-KA7o9{œdataTypeœ:œChatInputœ,œidœ:œChatInput-KA7o9œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-9jjXZ{œfieldNameœ:œquestionœ,œidœ:œPrompt Template-9jjXZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-KA7o9",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-KA7o9œ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-9jjXZ",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt Template-9jjXZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-t5AFB",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "server_block_parameters",
            "id": "Prompt Template-fKVaX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParserComponent-t5AFB{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fKVaX{œfieldNameœ:œserver_block_parametersœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-t5AFB",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-t5AFBœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fKVaX",
        "targetHandle": "{œfieldNameœ:œserver_block_parametersœ,œidœ:œPrompt Template-fKVaXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-nEXtH",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-92esX",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ParserComponent-nEXtH{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-nEXtHœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-92esX{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-92esXœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParserComponent-nEXtH",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-nEXtHœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-92esX",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-92esXœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-nmFh0",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-ToohH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-JSONCleaner-nmFh0{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-ToohH{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-ToohHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "JSONCleaner-nmFh0",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-ToohH",
        "targetHandle": "{œfieldNameœ:œinput_textœ,œidœ:œConditionalRouter-ToohHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-nmFh0",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "true_case_message",
            "id": "ConditionalRouter-ToohH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-JSONCleaner-nmFh0{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ConditionalRouter-ToohH{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-ToohHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "JSONCleaner-nmFh0",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-nmFh0œ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ConditionalRouter-ToohH",
        "targetHandle": "{œfieldNameœ:œtrue_case_messageœ,œidœ:œConditionalRouter-ToohHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-ToohH",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-zHg0X",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ConditionalRouter-ToohH{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-ToohHœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-zHg0X{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-zHg0Xœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ConditionalRouter-ToohH",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-ToohHœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-zHg0X",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-zHg0Xœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-d2QMY",
            "name": "done",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-ppTdn",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__LoopComponent-d2QMY{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-d2QMYœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-ppTdn{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-ppTdnœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopComponent-d2QMY",
        "sourceHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-d2QMYœ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-ppTdn",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-ppTdnœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-bWTwE",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent2_output",
            "id": "ArbitratorComponent-vBetm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__OpenAIModel-bWTwE{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-bWTwEœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ArbitratorComponent-vBetm{œfieldNameœ:œagent2_outputœ,œidœ:œArbitratorComponent-vBetmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-bWTwE",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-bWTwEœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ArbitratorComponent-vBetm",
        "targetHandle": "{œfieldNameœ:œagent2_outputœ,œidœ:œArbitratorComponent-vBetmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-H6W2e",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_json",
            "id": "UniversalSearchConfigComponent-RvEQ1",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-H6W2e{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-H6W2eœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-UniversalSearchConfigComponent-RvEQ1{œfieldNameœ:œagent1_jsonœ,œidœ:œUniversalSearchConfigComponent-RvEQ1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-H6W2e",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-H6W2eœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "UniversalSearchConfigComponent-RvEQ1",
        "targetHandle": "{œfieldNameœ:œagent1_jsonœ,œidœ:œUniversalSearchConfigComponent-RvEQ1œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-W4PmL",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_json",
            "id": "UniversalSearchConfigComponent-arR45",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-W4PmL{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-W4PmLœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-UniversalSearchConfigComponent-arR45{œfieldNameœ:œagent1_jsonœ,œidœ:œUniversalSearchConfigComponent-arR45œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-W4PmL",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-W4PmLœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "UniversalSearchConfigComponent-arR45",
        "targetHandle": "{œfieldNameœ:œagent1_jsonœ,œidœ:œUniversalSearchConfigComponent-arR45œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UpstreamConfigBlockSplitter",
            "id": "UpstreamConfigBlockSplitter-6qh1v",
            "name": "config_items_df",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "LoopComponent-xg3V7",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UpstreamConfigBlockSplitter-6qh1v{œdataTypeœ:œUpstreamConfigBlockSplitterœ,œidœ:œUpstreamConfigBlockSplitter-6qh1vœ,œnameœ:œconfig_items_dfœ,œoutput_typesœ:[œDataFrameœ]}-LoopComponent-xg3V7{œfieldNameœ:œdataœ,œidœ:œLoopComponent-xg3V7œ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UpstreamConfigBlockSplitter-6qh1v",
        "sourceHandle": "{œdataTypeœ:œUpstreamConfigBlockSplitterœ,œidœ:œUpstreamConfigBlockSplitter-6qh1vœ,œnameœ:œconfig_items_dfœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "LoopComponent-xg3V7",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œLoopComponent-xg3V7œ,œinputTypesœ:[œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-FdI1h",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-Ps7tU",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-FdI1h{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-FdI1hœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-Ps7tU{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-Ps7tUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-FdI1h",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-FdI1hœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-Ps7tU",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-Ps7tUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-xg3V7",
            "name": "item",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-HriUz",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__LoopComponent-xg3V7{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-xg3V7œ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}-ParserComponent-HriUz{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-HriUzœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopComponent-xg3V7",
        "sourceHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-xg3V7œ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-HriUz",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-HriUzœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-HriUz",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "agent1_data",
            "id": "Prompt Template-FdI1h",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-HriUz{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-HriUzœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-FdI1h{œfieldNameœ:œagent1_dataœ,œidœ:œPrompt Template-FdI1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-HriUz",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-HriUzœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-FdI1h",
        "targetHandle": "{œfieldNameœ:œagent1_dataœ,œidœ:œPrompt Template-FdI1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-HriUz",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "operation",
            "id": "Prompt Template-FdI1h",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-HriUz{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-HriUzœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-FdI1h{œfieldNameœ:œoperationœ,œidœ:œPrompt Template-FdI1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-HriUz",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-HriUzœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-FdI1h",
        "targetHandle": "{œfieldNameœ:œoperationœ,œidœ:œPrompt Template-FdI1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-HriUz",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "upstreams",
            "id": "Prompt Template-FdI1h",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-HriUz{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-HriUzœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-FdI1h{œfieldNameœ:œupstreamsœ,œidœ:œPrompt Template-FdI1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-HriUz",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-HriUzœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-FdI1h",
        "targetHandle": "{œfieldNameœ:œupstreamsœ,œidœ:œPrompt Template-FdI1hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TypeConverterComponent",
            "id": "TypeConverterComponent-6M3Tu",
            "name": "data_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-xg3V7",
            "name": "item",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__TypeConverterComponent-6M3Tu{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-6M3Tuœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}-LoopComponent-xg3V7{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-xg3V7œ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "selected": false,
        "source": "TypeConverterComponent-6M3Tu",
        "sourceHandle": "{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-6M3Tuœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "LoopComponent-xg3V7",
        "targetHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-xg3V7œ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-xTkpM",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-CeAWi",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ParserComponent-xTkpM{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-xTkpMœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-CeAWi{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-CeAWiœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParserComponent-xTkpM",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-xTkpMœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-CeAWi",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-CeAWiœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-xg3V7",
            "name": "done",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-xTkpM",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__LoopComponent-xg3V7{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-xg3V7œ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}-ParserComponent-xTkpM{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-xTkpMœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "LoopComponent-xg3V7",
        "sourceHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-xg3V7œ,œnameœ:œdoneœ,œoutput_typesœ:[œDataFrameœ]}",
        "target": "ParserComponent-xTkpM",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-xTkpMœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-g1nlX",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "TypeConverterComponent-uXcEf",
            "inputTypes": [
              "Message",
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__JSONCleaner-g1nlX{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-g1nlXœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-TypeConverterComponent-uXcEf{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-uXcEfœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONCleaner-g1nlX",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-g1nlXœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TypeConverterComponent-uXcEf",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-uXcEfœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-Ps7tU",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "json_str",
            "id": "JSONCleaner-9rVTs",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__OpenAIModel-Ps7tU{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ps7tUœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-JSONCleaner-9rVTs{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-9rVTsœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-Ps7tU",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ps7tUœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "JSONCleaner-9rVTs",
        "targetHandle": "{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-9rVTsœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-9rVTs",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "TypeConverterComponent-6M3Tu",
            "inputTypes": [
              "Message",
              "Data",
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__JSONCleaner-9rVTs{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-9rVTsœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-TypeConverterComponent-6M3Tu{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-6M3Tuœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONCleaner-9rVTs",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-9rVTsœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TypeConverterComponent-6M3Tu",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œTypeConverterComponent-6M3Tuœ,œinputTypesœ:[œMessageœ,œDataœ,œDataFrameœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-YRAOB",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "json_str",
            "id": "JSONCleaner-g1nlX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__OpenAIModel-YRAOB{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-YRAOBœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-JSONCleaner-g1nlX{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-g1nlXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-YRAOB",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-YRAOBœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "JSONCleaner-g1nlX",
        "targetHandle": "{œfieldNameœ:œjson_strœ,œidœ:œJSONCleaner-g1nlXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TypeConverterComponent",
            "id": "TypeConverterComponent-uXcEf",
            "name": "data_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "dataType": "LoopComponent",
            "id": "LoopComponent-d2QMY",
            "name": "item",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "xy-edge__TypeConverterComponent-uXcEf{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-uXcEfœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}-LoopComponent-d2QMY{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-d2QMYœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}",
        "selected": false,
        "source": "TypeConverterComponent-uXcEf",
        "sourceHandle": "{œdataTypeœ:œTypeConverterComponentœ,œidœ:œTypeConverterComponent-uXcEfœ,œnameœ:œdata_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "LoopComponent-d2QMY",
        "targetHandle": "{œdataTypeœ:œLoopComponentœ,œidœ:œLoopComponent-d2QMYœ,œnameœ:œitemœ,œoutput_typesœ:[œDataœ]}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-ppTdn",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-hZzcn",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__ParserComponent-ppTdn{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-ppTdnœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-hZzcn{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-hZzcnœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ParserComponent-ppTdn",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-ppTdnœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-hZzcn",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-hZzcnœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UniversalSearchConfigComponent",
            "id": "UniversalSearchConfigComponent-arR45",
            "name": "config_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "ParserComponent-hqKni",
            "inputTypes": [
              "DataFrame",
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UniversalSearchConfigComponent-arR45{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-arR45œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}-ParserComponent-hqKni{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-hqKniœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UniversalSearchConfigComponent-arR45",
        "sourceHandle": "{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-arR45œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParserComponent-hqKni",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œParserComponent-hqKniœ,œinputTypesœ:[œDataFrameœ,œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-hqKni",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "parser_output",
            "id": "NginxConfigAssemblerAST-qbIoX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-hqKni{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-hqKniœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-NginxConfigAssemblerAST-qbIoX{œfieldNameœ:œparser_outputœ,œidœ:œNginxConfigAssemblerAST-qbIoXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-hqKni",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-hqKniœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "NginxConfigAssemblerAST-qbIoX",
        "targetHandle": "{œfieldNameœ:œparser_outputœ,œidœ:œNginxConfigAssemblerAST-qbIoXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-ppTdn",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "llm_responses",
            "id": "NginxConfigAssemblerAST-qbIoX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-ppTdn{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-ppTdnœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-NginxConfigAssemblerAST-qbIoX{œfieldNameœ:œllm_responsesœ,œidœ:œNginxConfigAssemblerAST-qbIoXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-ppTdn",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-ppTdnœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "NginxConfigAssemblerAST-qbIoX",
        "targetHandle": "{œfieldNameœ:œllm_responsesœ,œidœ:œNginxConfigAssemblerAST-qbIoXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "JSONCleaner",
            "id": "JSONCleaner-2l30o",
            "name": "output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-i01pc",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__JSONCleaner-2l30o{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-2l30oœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-i01pc{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-i01pcœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "JSONCleaner-2l30o",
        "sourceHandle": "{œdataTypeœ:œJSONCleanerœ,œidœ:œJSONCleaner-2l30oœ,œnameœ:œoutputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-i01pc",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-i01pcœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UpstreamExtractorComponent",
            "id": "UpstreamExtractorComponent-LZc0P",
            "name": "upstream_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "selected_block",
            "id": "UpstreamConfigBlockSplitter-6qh1v",
            "inputTypes": [
              "Message",
              "Data",
              "dict"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UpstreamExtractorComponent-LZc0P{œdataTypeœ:œUpstreamExtractorComponentœ,œidœ:œUpstreamExtractorComponent-LZc0Pœ,œnameœ:œupstream_dataœ,œoutput_typesœ:[œDataœ]}-UpstreamConfigBlockSplitter-6qh1v{œfieldNameœ:œselected_blockœ,œidœ:œUpstreamConfigBlockSplitter-6qh1vœ,œinputTypesœ:[œMessageœ,œDataœ,œdictœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UpstreamExtractorComponent-LZc0P",
        "sourceHandle": "{œdataTypeœ:œUpstreamExtractorComponentœ,œidœ:œUpstreamExtractorComponent-LZc0Pœ,œnameœ:œupstream_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "UpstreamConfigBlockSplitter-6qh1v",
        "targetHandle": "{œfieldNameœ:œselected_blockœ,œidœ:œUpstreamConfigBlockSplitter-6qh1vœ,œinputTypesœ:[œMessageœ,œDataœ,œdictœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "UniversalSearchConfigComponent",
            "id": "UniversalSearchConfigComponent-RvEQ1",
            "name": "config_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "config_data",
            "id": "UpstreamExtractorComponent-LZc0P",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__UniversalSearchConfigComponent-RvEQ1{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-RvEQ1œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}-UpstreamExtractorComponent-LZc0P{œfieldNameœ:œconfig_dataœ,œidœ:œUpstreamExtractorComponent-LZc0Pœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "UniversalSearchConfigComponent-RvEQ1",
        "sourceHandle": "{œdataTypeœ:œUniversalSearchConfigComponentœ,œidœ:œUniversalSearchConfigComponent-RvEQ1œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "UpstreamExtractorComponent-LZc0P",
        "targetHandle": "{œfieldNameœ:œconfig_dataœ,œidœ:œUpstreamExtractorComponent-LZc0Pœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParserComponent",
            "id": "ParserComponent-xTkpM",
            "name": "parsed_text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "llm_responses",
            "id": "CustomComponent-dqFNm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParserComponent-xTkpM{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-xTkpMœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-dqFNm{œfieldNameœ:œllm_responsesœ,œidœ:œCustomComponent-dqFNmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParserComponent-xTkpM",
        "sourceHandle": "{œdataTypeœ:œParserComponentœ,œidœ:œParserComponent-xTkpMœ,œnameœ:œparsed_textœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-dqFNm",
        "targetHandle": "{œfieldNameœ:œllm_responsesœ,œidœ:œCustomComponent-dqFNmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "LocationSelectorFromUniversalSearch-ubEWV",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Selects locations from universal search result for LLM processing (supports 1 or N locations)",
            "display_name": "Location Selector from Universal Search",
            "documentation": "",
            "edited": true,
            "field_order": [
              "universal_search_result",
              "source_field"
            ],
            "frozen": false,
            "icon": "filter",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "selected_block",
                "group_outputs": false,
                "hidden": null,
                "method": "build_selected_block",
                "name": "selected_block",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "operation_context",
                "group_outputs": false,
                "hidden": null,
                "method": "build_operation_context",
                "name": "operation_context",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "error_message",
                "group_outputs": false,
                "hidden": null,
                "method": "build_error_message",
                "name": "error_message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import (\n    HandleInput,\n    MessageTextInput,\n)\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\nimport json\nimport hashlib\nimport yaml\nimport re\nfrom typing import Dict, Any, List, Optional, Tuple\n\n\nclass LocationSelectorFromUniversalSearch(Component):\n    \"\"\"\n    Selects a specific location or server block from universal search result.\n    Automatically extracts target location from agent1_data.location.\n    Processes ALL matching configurations from all_configs.\n    Special handling for operations:\n    - CREATE_LOCATION: Returns config info where location DOESN'T exist (to create new)\n    - DELETE_LOCATION: Returns config info where location DOES exist (to delete)\n    - MODIFY_LOCATION_PATH: Returns config info where OLD location exists (to rename/move)\n    - MODIFY/ADD: Returns config info where location exists (to modify)\n    - MAKE_PROTECTED: Returns config info where location exists (to make protected)\n    - MAKE_PUBLIC: Returns config info where location exists (to make public)\n    - Server operations: Always returns server block info\n    NEW: Handles both single location and multiple locations seamlessly!\n    NEW: Supports parameters, location_parameters, server_block_parameters\n    NEW: Supports multi-DC detection (found_in_multiple_dc, domain_dc_mapping, etc.)\n    \"\"\"\n    display_name = \"Location Selector from Universal Search\"\n    description = \"Selects locations from universal search result for LLM processing (supports 1 or N locations)\"\n    documentation = \"\"\n    icon = \"filter\"\n    inputs = [\n        HandleInput(\n            name=\"universal_search_result\",\n            display_name=\"Universal Search Result\",\n            input_types=[\"Data\", \"dict\"],\n            info=\"Output from Universal Search (contains agent1_data)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"source_field\",\n            display_name=\"Source field\",\n            value=\"full_config_text\",\n            info=\"Field containing YAML config text (full_config_text or config_block)\",\n            required=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"selected_block\",\n            name=\"selected_block\",\n            info=\"Selected location/server blocks for all matching configs\",\n            method=\"build_selected_block\",\n        ),\n        Output(\n            display_name=\"operation_context\",\n            name=\"operation_context\",\n            info=\"Operation metadata from agent1_data\",\n            method=\"build_operation_context\",\n        ),\n        Output(\n            display_name=\"error_message\",\n            name=\"error_message\",\n            info=\"Error if location not found\",\n            method=\"build_error_message\",\n        ),\n    ]\n\n    def _get_search_result(self) -> Dict[str, Any]:\n        \"\"\"Extract universal search result.\"\"\"\n        input_data = self.universal_search_result\n        if isinstance(input_data, Data):\n            data = input_data.data\n        elif isinstance(input_data, dict):\n            data = input_data\n        else:\n            data = json.loads(str(input_data))\n        return data\n\n    def _extract_multi_dc_info(self, search_result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        🆕 Extract multi-DC information from search result.\n        Returns dict with all multi-DC related fields.\n        \"\"\"\n        return {\n            \"found_in_multiple_dc\": search_result.get(\"found_in_multiple_dc\", False),\n            \"dc_count\": search_result.get(\"dc_count\", 0),\n            \"unique_dcs\": search_result.get(\"unique_dcs\", []),\n            \"domain_dc_mapping\": search_result.get(\"domain_dc_mapping\", {}),\n            \"domains_in_multiple_dc\": search_result.get(\"domains_in_multiple_dc\", []),\n        }\n\n    def _get_agent1_data(self, search_result: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"\n        Extract and normalize agent1_data from search result.\n        Handles ALL possible structures:\n        - agent1_data as list\n        - agent1_data as dict with 'payload'\n        - agent1_data as dict without 'payload'\n        - Multiple domains vs single domain\n        - Merges data from multiple payload items\n        \"\"\"\n        agent1_data_raw = search_result.get(\"agent1_data\", {})\n\n        # CASE 1: agent1_data is a list - take first element\n        if isinstance(agent1_data_raw, list):\n            if not agent1_data_raw:\n                return {}\n            first_item = agent1_data_raw[0]\n            # Check if this item also has payload\n            if isinstance(first_item, dict) and \"payload\" in first_item:\n                return self._extract_from_payload(first_item.get(\"payload\", []))\n            return first_item\n\n        # CASE 2: agent1_data is dict\n        if isinstance(agent1_data_raw, dict):\n            # Check if it has 'payload' key\n            if \"payload\" in agent1_data_raw:\n                payload = agent1_data_raw.get(\"payload\", [])\n                return self._extract_from_payload(payload)\n\n            # CASE 3: Direct dict without payload - return as is\n            return agent1_data_raw\n\n        return {}\n\n    def _extract_from_payload(self, payload: List[Dict]) -> Dict[str, Any]:\n        \"\"\"\n        Extract and merge data from payload array.\n        Handles both single and multiple items in payload.\n        \"\"\"\n        if not payload or not isinstance(payload, list):\n            return {}\n\n        # If single item - return it directly\n        if len(payload) == 1:\n            return payload[0]\n\n        # Multiple items - merge them intelligently\n        merged = {\n            \"operation\": None,\n            \"domain\": None,\n            \"domains\": [],\n            \"location\": None,\n            \"locations\": [],\n            \"from_location\": None,\n            \"to_location\": None,\n            \"new_location_path\": None,\n            \"preserve_directives\": True,\n            \"parameters\": [],\n            \"location_parameters\": [],\n            \"server_block_parameters\": [],\n            \"ip_addresses\": [],\n            \"upstreams\": [],\n            \"kms_required\": False,\n            \"kms_mentioned\": False,\n            \"kms_locations\": [],\n            \"public_locations\": [],\n            \"selected_dc\": [],\n            \"data_complete\": True,\n            \"confidence\": 0.0,\n            \"warnings\": [],\n            \"ambiguities\": []\n        }\n\n        for item in payload:\n            if not isinstance(item, dict):\n                continue\n\n            # Operation - take from first item\n            if not merged[\"operation\"] and item.get(\"operation\"):\n                merged[\"operation\"] = item[\"operation\"]\n\n            # Domains - collect all\n            if item.get(\"domain\"):\n                merged[\"domains\"].append(item[\"domain\"])\n                if not merged[\"domain\"]:  # Set first domain as primary\n                    merged[\"domain\"] = item[\"domain\"]\n\n            if item.get(\"domains\"):\n                if isinstance(item[\"domains\"], list):\n                    merged[\"domains\"].extend(item[\"domains\"])\n                else:\n                    merged[\"domains\"].append(item[\"domains\"])\n\n            # Locations - collect all\n            if item.get(\"location\"):\n                merged[\"locations\"].append(item[\"location\"])\n                if not merged[\"location\"]:  # Set first location as primary\n                    merged[\"location\"] = item[\"location\"]\n\n            if item.get(\"locations\"):\n                if isinstance(item[\"locations\"], list):\n                    merged[\"locations\"].extend(item[\"locations\"])\n                else:\n                    merged[\"locations\"].append(item[\"locations\"])\n\n            # Location parameters - collect all\n            if item.get(\"location_parameters\"):\n                if isinstance(item[\"location_parameters\"], list):\n                    merged[\"location_parameters\"].extend(item[\"location_parameters\"])\n                else:\n                    merged[\"location_parameters\"].append(item[\"location_parameters\"])\n\n            # Server block parameters - collect all (deduplicate later)\n            if item.get(\"server_block_parameters\"):\n                if isinstance(item[\"server_block_parameters\"], list):\n                    merged[\"server_block_parameters\"].extend(item[\"server_block_parameters\"])\n                else:\n                    merged[\"server_block_parameters\"].append(item[\"server_block_parameters\"])\n\n            # General parameters - collect all\n            if item.get(\"parameters\"):\n                if isinstance(item[\"parameters\"], list):\n                    merged[\"parameters\"].extend(item[\"parameters\"])\n                else:\n                    merged[\"parameters\"].append(item[\"parameters\"])\n\n            # IP addresses - collect all\n            if item.get(\"ip_addresses\"):\n                if isinstance(item[\"ip_addresses\"], list):\n                    merged[\"ip_addresses\"].extend(item[\"ip_addresses\"])\n                else:\n                    merged[\"ip_addresses\"].append(item[\"ip_addresses\"])\n\n            # Upstreams - collect all\n            if item.get(\"upstreams\"):\n                if isinstance(item[\"upstreams\"], list):\n                    merged[\"upstreams\"].extend(item[\"upstreams\"])\n                elif item[\"upstreams\"]:  # Not None\n                    merged[\"upstreams\"].append(item[\"upstreams\"])\n\n            # Selected DC - collect all\n            if item.get(\"selected_dc\"):\n                if isinstance(item[\"selected_dc\"], list):\n                    merged[\"selected_dc\"].extend(item[\"selected_dc\"])\n                else:\n                    merged[\"selected_dc\"].append(item[\"selected_dc\"])\n\n            # KMS locations - collect all\n            if item.get(\"kms_locations\"):\n                if isinstance(item[\"kms_locations\"], list):\n                    merged[\"kms_locations\"].extend(item[\"kms_locations\"])\n                else:\n                    merged[\"kms_locations\"].append(item[\"kms_locations\"])\n\n            # Public locations - collect all\n            if item.get(\"public_locations\"):\n                if isinstance(item[\"public_locations\"], list):\n                    merged[\"public_locations\"].extend(item[\"public_locations\"])\n                else:\n                    merged[\"public_locations\"].append(item[\"public_locations\"])\n\n            # Boolean flags - OR logic (if any item has True, result is True)\n            if item.get(\"kms_required\"):\n                merged[\"kms_required\"] = True\n\n            if item.get(\"kms_mentioned\"):\n                merged[\"kms_mentioned\"] = True\n\n            # Preserve directives - AND logic (all must be True)\n            if item.get(\"preserve_directives\") is False:\n                merged[\"preserve_directives\"] = False\n\n            # Path modification fields - take from first non-empty\n            if not merged[\"from_location\"] and item.get(\"from_location\"):\n                merged[\"from_location\"] = item[\"from_location\"]\n\n            if not merged[\"to_location\"] and item.get(\"to_location\"):\n                merged[\"to_location\"] = item[\"to_location\"]\n\n            if not merged[\"new_location_path\"] and item.get(\"new_location_path\"):\n                merged[\"new_location_path\"] = item[\"new_location_path\"]\n\n            # Data completeness - AND logic\n            if item.get(\"data_complete\") is False:\n                merged[\"data_complete\"] = False\n\n            # Confidence - take maximum\n            item_confidence = item.get(\"confidence\", 0.0)\n            if item_confidence > merged[\"confidence\"]:\n                merged[\"confidence\"] = item_confidence\n\n            # Warnings and ambiguities - collect all\n            if item.get(\"warnings\"):\n                if isinstance(item[\"warnings\"], list):\n                    merged[\"warnings\"].extend(item[\"warnings\"])\n                else:\n                    merged[\"warnings\"].append(item[\"warnings\"])\n\n            if item.get(\"ambiguities\"):\n                if isinstance(item[\"ambiguities\"], list):\n                    merged[\"ambiguities\"].extend(item[\"ambiguities\"])\n                else:\n                    merged[\"ambiguities\"].append(item[\"ambiguities\"])\n\n        # Deduplicate lists\n        merged[\"domains\"] = list(dict.fromkeys(merged[\"domains\"]))  # Preserve order\n        merged[\"locations\"] = list(dict.fromkeys(merged[\"locations\"]))\n        merged[\"server_block_parameters\"] = list(dict.fromkeys(merged[\"server_block_parameters\"]))\n        merged[\"parameters\"] = list(dict.fromkeys(merged[\"parameters\"]))\n        merged[\"ip_addresses\"] = list(dict.fromkeys(merged[\"ip_addresses\"]))\n        merged[\"selected_dc\"] = list(dict.fromkeys(merged[\"selected_dc\"]))\n        merged[\"kms_locations\"] = list(dict.fromkeys(merged[\"kms_locations\"]))\n        merged[\"public_locations\"] = list(dict.fromkeys(merged[\"public_locations\"]))\n\n        # Clean up empty lists to None where appropriate\n        if not merged[\"domains\"]:\n            merged[\"domains\"] = []\n        if not merged[\"locations\"]:\n            merged[\"locations\"] = []\n        if not merged[\"upstreams\"]:\n            merged[\"upstreams\"] = []\n\n        return merged\n\n    def _normalize_location_parameters(self, agent1_data: Dict[str, Any]) -> List[Dict]:\n        \"\"\"\n        Normalize location_parameters regardless of input format.\n        Handles: single location, multiple locations, location_parameters array.\n        Returns list of dicts, each with: location, parameters, kms_required, ip_addresses, upstreams, new_location_path\n        \"\"\"\n        location_parameters = agent1_data.get(\"location_parameters\", [])\n        locations_list = agent1_data.get(\"locations\", [])\n        single_location = agent1_data.get(\"location\")\n        ip_addresses = agent1_data.get(\"ip_addresses\", [])\n        upstreams = agent1_data.get(\"upstreams\", [])\n        parameters = agent1_data.get(\"parameters\", [])\n        kms_required = agent1_data.get(\"kms_required\", False)\n        server_block_parameters = agent1_data.get(\"server_block_parameters\", [])\n        selected_dc = agent1_data.get(\"selected_dc\", [])\n        # NEW: Support both naming conventions for path modification\n        new_location_path = agent1_data.get(\"new_location_path\") or agent1_data.get(\"to_location\")\n        from_location = agent1_data.get(\"from_location\")\n        # If from_location is specified, use it as the primary location\n        if from_location:\n            single_location = from_location\n        # CASE 1: location_parameters уже заполнена (приоритет)\n        if location_parameters and isinstance(location_parameters, list):\n            normalized = []\n            for loc_param in location_parameters:\n                if isinstance(loc_param, dict) and loc_param.get(\"location\"):\n                    # Support both naming conventions\n                    param_new_path = (loc_param.get(\"new_location_path\") or\n                                      loc_param.get(\"to_location\") or\n                                      new_location_path)\n                    norm_param = {\n                        \"location\": loc_param.get(\"location\") or loc_param.get(\"from_location\"),\n                        \"parameters\": loc_param.get(\"parameters\", parameters),\n                        \"kms_required\": loc_param.get(\"kms_required\", kms_required),\n                        \"ip_addresses\": loc_param.get(\"ip_addresses\", ip_addresses),\n                        \"upstreams\": loc_param.get(\"upstreams\", upstreams),\n                        \"server_block_parameters\": loc_param.get(\"server_block_parameters\", server_block_parameters),\n                        \"new_location_path\": param_new_path,\n                        \"selected_dc\": loc_param.get(\"selected_dc\", selected_dc),\n                    }\n                    normalized.append(norm_param)\n            if normalized:\n                return normalized\n        # CASE 2: Множественные locations в поле \"locations\"\n        if locations_list and isinstance(locations_list, list):\n            return [\n                {\n                    \"location\": loc,\n                    \"parameters\": parameters,\n                    \"kms_required\": kms_required,\n                    \"ip_addresses\": ip_addresses,\n                    \"upstreams\": upstreams,\n                    \"server_block_parameters\": server_block_parameters,\n                    \"new_location_path\": new_location_path,\n                    \"selected_dc\": selected_dc,\n                }\n                for loc in locations_list\n                if loc  # Исключить пустые\n            ]\n        # CASE 3: Одна location\n        if single_location:\n            return [\n                {\n                    \"location\": single_location,\n                    \"parameters\": parameters,\n                    \"kms_required\": kms_required,\n                    \"ip_addresses\": ip_addresses,\n                    \"upstreams\": upstreams,\n                    \"server_block_parameters\": server_block_parameters,\n                    \"new_location_path\": new_location_path,\n                    \"selected_dc\": selected_dc,\n                }\n            ]\n        # CASE 4: Ничего не найдено\n        return []\n\n    def _parse_yaml_config(self, config_text: str) -> Tuple[str, List[str], List[Dict]]:\n        \"\"\"\n        Parse YAML config and extract server directives and locations.\n        Returns: (config_key, server_directives, locations)\n        \"\"\"\n        parsed_data = yaml.safe_load(config_text)\n        if isinstance(parsed_data, list):  # Handle top-level list YAML\n            key = \"default_config\"\n            items = parsed_data\n        elif isinstance(parsed_data, dict) and parsed_data:\n            key = list(parsed_data.keys())[0]\n            items = parsed_data[key]\n        else:\n            raise ValueError(\"Invalid YAML structure: must be dict or list\")\n        if not isinstance(items, list):\n            items = [items]  # Ensure items is always a list\n        server_directives = []\n        locations = []\n        for item in items:\n            item_str = str(item).strip()\n            if item_str.startswith(\"location \"):\n                # Parse location: location /path { ... }\n                match = re.match(r\"location\\s+([^{]+)\\s*{(.*)}\", item_str, re.DOTALL)\n                if match:\n                    path = match.group(1).strip()\n                    content = match.group(2).strip().rstrip(\"};\")\n                    directives = [d.strip().rstrip(\";\").strip() + \";\"\n                                  for d in content.split(\";\") if d.strip()]\n                    # Calculate hash\n                    content_str = f\"{path}:{content}\"\n                    loc_hash = hashlib.sha1(content_str.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n                    locations.append({\n                        \"path\": path,\n                        \"directives\": directives,\n                        \"hash\": loc_hash\n                    })\n                else:\n                    # Fallback to server directive\n                    cleaned = item_str.rstrip(\";\").strip()\n                    if not item_str.endswith(\";\"):\n                        cleaned += \";\"\n                    server_directives.append(cleaned)\n            elif item_str.startswith(\"- \"):\n                directive = item_str.lstrip(\"- \").rstrip(\";\").strip()\n                if not item_str.lstrip(\"- \").endswith(\";\"):\n                    directive += \";\"\n                server_directives.append(directive)\n            else:\n                directive = item_str.rstrip(\";\").strip()\n                if not item_str.endswith(\";\"):\n                    directive += \";\"\n                server_directives.append(directive)\n        return key, server_directives, locations\n\n    def _find_location(self, locations: List[Dict], target_location: str) -> Optional[Dict]:\n        \"\"\"Find location block by path with normalization.\"\"\"\n        normalized_target = target_location\n        if target_location != \"/\" and not target_location.endswith(\"/\"):\n            normalized_target = target_location + \"/\"\n        # Try normalized match\n        for loc in locations:\n            path = loc.get(\"path\", \"\")\n            normalized_path = path\n            if path != \"/\" and not path.endswith(\"/\"):\n                normalized_path = path + \"/\"\n            if normalized_path == normalized_target or path == target_location:\n                return loc\n        # Try exact match (for modifiers like \"= /path\")\n        for loc in locations:\n            if loc.get(\"path\") == target_location:\n                return loc\n        return None\n\n    def build_selected_block(self) -> Message:\n        \"\"\"\n        Select the target blocks based on agent1_data from ALL matching configs.\n        Handles both single and multiple locations.\n        🆕 Now includes multi-DC information.\n        \"\"\"\n        try:\n            search_result = self._get_search_result()\n\n            # 🆕 Extract multi-DC info\n            multi_dc_info = self._extract_multi_dc_info(search_result)\n            # Extract agent1_data using universal method\n            agent1_data = self._get_agent1_data(search_result)\n\n\n            operation = search_result.get(\"operation\", agent1_data.get(\"operation\", \"ADD_PARAMETERS\"))\n            target_domains = search_result.get(\"domains\", agent1_data.get(\"domains\", []))\n            # 🔥 НОВОЕ: Нормализовать location_parameters - работает для 1 или N locations\n            location_parameters = self._normalize_location_parameters(agent1_data)\n            source_field = getattr(self, 'source_field', 'full_config_text')\n            all_configs = search_result.get(\"all_configs\", [])\n            if not all_configs:\n                return Message(text=json.dumps({\n                    \"error\": \"No configs found in all_configs\",\n                    \"selected_blocks\": [],\n                    **multi_dc_info  # 🆕 Include multi-DC info even in error\n                }, ensure_ascii=False))\n            selected_blocks = []\n            errors = []\n            # OPERATION-SPECIFIC LOGIC\n            is_create_operation = operation == \"CREATE_LOCATION\"\n            is_delete_operation = operation == \"DELETE_LOCATION\"\n            is_modify_path_operation = operation == \"MODIFY_LOCATION_PATH\"  # NEW\n            requires_existing_location = is_delete_operation or operation in [\n                \"MODIFY_PARAMETERS\",\n                \"ADD_PARAMETERS\",\n                \"CONDITIONAL_ADD_PARAMETERS\",\n                \"DELETE_PARAMETERS\",\n                \"DELETE_KMS_PARAMETERS\",\n                \"MODIFY_UPSTREAM\",\n                \"MODIFY_LOCATION_PATH\",  # NEW - requires existing location\n                \"MAKE_PROTECTED\",  # Added support\n                \"MAKE_PUBLIC\"  # Added support\n            ]\n            # PROCESS ALL CONFIGURATIONS\n            for config in all_configs:\n                if not isinstance(config, dict):  # Safeguard against non-dict configs\n                    errors.append(f\"Invalid config type in all_configs: {type(config)} - skipping\")\n                    continue\n                # Check if config matches target domains\n                matching_domains = config.get(\"matching_domains\", [])\n                server_names = config.get(\"server_names\", [])\n\n                # 🆕 Get inferred_dc for this config\n                config_inferred_dc = config.get(\"inferred_dc\", [])\n\n                # Skip configs that don't match any target domain\n                if target_domains:\n                    if not any(domain in target_domains for domain in matching_domains):\n                        if not any(domain in target_domains for domain in server_names):\n                            continue\n                config_text = config.get(source_field)\n                if not config_text:\n                    errors.append(f\"No {source_field} in config {config.get('config_key', 'unknown')}\")\n                    continue\n                try:\n                    key, server_directives, locations = self._parse_yaml_config(config_text)\n                    # SERVER BLOCK (no specific locations = work with server block)\n                    if not location_parameters:\n                        server_str = \";\".join(server_directives)\n                        server_hash = hashlib.sha1(server_str.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n                        selected_blocks.append({\n                            \"config_key\": key,\n                            \"config_file\": config.get(\"config_file\"),\n                            \"server_names\": server_names,\n                            \"matching_domains\": matching_domains,\n                            \"location_path\": \"server_block\",\n                            \"directives\": server_directives,\n                            \"hash\": server_hash,\n                            \"type\": \"server\",\n                            \"operation\": operation,\n                            \"parameters\": agent1_data.get(\"parameters\", []),\n                            \"server_block_parameters\": agent1_data.get(\"server_block_parameters\", []),\n                            \"selected_dc\": agent1_data.get(\"selected_dc\", []),\n                            \"inferred_dc\": config_inferred_dc,  # 🆕 Add inferred DC\n                        })\n                    # LOCATION-SPECIFIC (process ALL locations - 1, 2, 3, N...)\n                    else:\n                        for loc_param in location_parameters:\n                            target_loc = loc_param.get(\"location\")\n                            if not target_loc:\n                                errors.append(\"Invalid location in location_parameters\")\n                                continue\n                            existing_location = self._find_location(locations, target_loc)\n                            # CREATE_LOCATION: location НЕ должна существовать\n                            if is_create_operation:\n                                if existing_location:\n                                    errors.append(\n                                        f\"Location '{target_loc}' already exists in {key}. \"\n                                        f\"Cannot create duplicate location.\"\n                                    )\n                                else:\n                                    # Location doesn't exist - good for CREATE_LOCATION\n                                    selected_blocks.append({\n                                        \"config_key\": key,\n                                        \"config_file\": config.get(\"config_file\"),\n                                        \"server_names\": server_names,\n                                        \"matching_domains\": matching_domains,\n                                        \"location_path\": target_loc,\n                                        \"directives\": [],  # Empty - will be populated by LLM\n                                        \"hash\": None,\n                                        \"type\": \"location\",\n                                        \"operation\": operation,\n                                        \"existing_locations\": [loc.get(\"path\") for loc in locations],\n                                        \"create_mode\": True,\n                                        \"parameters\": loc_param.get(\"parameters\", []),\n                                        \"kms_required\": loc_param.get(\"kms_required\", False),\n                                        \"ip_addresses\": loc_param.get(\"ip_addresses\", []),\n                                        \"upstreams\": loc_param.get(\"upstreams\", []),\n                                        \"server_block_parameters\": loc_param.get(\"server_block_parameters\", []),\n                                        \"selected_dc\": loc_param.get(\"selected_dc\", []),\n                                        \"inferred_dc\": config_inferred_dc,  # 🆕 Add inferred DC\n                                    })\n                            # DELETE_LOCATION: location ДОЛЖНА существовать\n                            elif is_delete_operation:\n                                if existing_location:\n                                    selected_blocks.append({\n                                        \"config_key\": key,\n                                        \"config_file\": config.get(\"config_file\"),\n                                        \"server_names\": server_names,\n                                        \"matching_domains\": matching_domains,\n                                        \"location_path\": existing_location.get(\"path\"),\n                                        \"directives\": existing_location.get(\"directives\", []),\n                                        \"hash\": existing_location.get(\"hash\"),\n                                        \"type\": \"location\",\n                                        \"operation\": operation,\n                                        \"delete_mode\": True,\n                                        \"selected_dc\": loc_param.get(\"selected_dc\", []),\n                                        \"inferred_dc\": config_inferred_dc,  # 🆕 Add inferred DC\n                                    })\n                                else:\n                                    errors.append(\n                                        f\"Location '{target_loc}' not found in {key}. \"\n                                        f\"Cannot delete non-existent location. \"\n                                        f\"Available: {[loc.get('path') for loc in locations]}\"\n                                    )\n                            # MODIFY/ADD/MODIFY_LOCATION_PATH/MAKE_PROTECTED/MAKE_PUBLIC: location ДОЛЖНА существовать\n                            elif requires_existing_location:\n                                if existing_location:\n                                    block_data = {\n                                        \"config_key\": key,\n                                        \"config_file\": config.get(\"config_file\"),\n                                        \"server_names\": server_names,\n                                        \"matching_domains\": matching_domains,\n                                        \"location_path\": existing_location.get(\"path\"),\n                                        \"directives\": existing_location.get(\"directives\", []),\n                                        \"hash\": existing_location.get(\"hash\"),\n                                        \"type\": \"location\",\n                                        \"operation\": operation,\n                                        \"parameters\": loc_param.get(\"parameters\", []),\n                                        \"kms_required\": loc_param.get(\"kms_required\", False),\n                                        \"ip_addresses\": loc_param.get(\"ip_addresses\", []),\n                                        \"upstreams\": loc_param.get(\"upstreams\", []),\n                                        \"server_block_parameters\": loc_param.get(\"server_block_parameters\", []),\n                                        \"selected_dc\": loc_param.get(\"selected_dc\", []),\n                                        \"inferred_dc\": config_inferred_dc,  # 🆕 Add inferred DC\n                                    }\n                                    # NEW: Add new_location_path for MODIFY_LOCATION_PATH operation\n                                    if operation == \"MODIFY_LOCATION_PATH\":\n                                        new_path = loc_param.get(\"new_location_path\")\n                                        if new_path:\n                                            block_data[\"new_location_path\"] = new_path\n                                            block_data[\"existing_locations\"] = [loc.get(\"path\") for loc in locations]\n                                        else:\n                                            errors.append(\n                                                f\"MODIFY_LOCATION_PATH requires 'new_location_path' for '{target_loc}'\"\n                                            )\n                                            continue\n                                    selected_blocks.append(block_data)\n                                else:\n                                    errors.append(\n                                        f\"Location '{target_loc}' not found in {key}. \"\n                                        f\"Available: {[loc.get('path') for loc in locations]}\"\n                                    )\n                            else:\n                                # Fallback for unknown operations\n                                errors.append(f\"Unknown operation '{operation}' for location '{target_loc}'\")\n                except Exception as e:\n                    errors.append(f\"Error parsing config {config.get('config_key', 'unknown')}: {str(e)}\")\n                    continue\n            # Prepare result\n            result = {\n                \"selected_blocks\": selected_blocks,\n                \"total_configs_scanned\": len(all_configs),\n                \"total_blocks_found\": len(selected_blocks),\n                \"target_locations\": [lp.get(\"location\") for lp in location_parameters],\n                \"target_domains\": target_domains,\n                \"operation\": operation,\n                \"locations_count\": len(location_parameters),\n                \"parameters\": agent1_data.get(\"parameters\", []),\n                \"location_parameters\": location_parameters,\n                \"server_block_parameters\": agent1_data.get(\"server_block_parameters\", []),\n\n                # 🆕 Multi-DC information\n                **multi_dc_info,\n            }\n            if errors:\n                result[\"warnings\"] = errors\n            if not selected_blocks:\n                if is_create_operation:\n                    result[\"error\"] = (\n                        f\"Cannot create locations {[lp.get('location') for lp in location_parameters]} - \"\n                        f\"they may already exist or no valid configs found\"\n                    )\n                elif is_delete_operation:\n                    result[\"error\"] = (\n                        f\"Cannot delete locations - not found in configs\"\n                    )\n                else:\n                    result[\"error\"] = (\n                        f\"Locations not found in any of {len(all_configs)} configs\"\n                    )\n\n            # 🆕 Add multi-DC warning to result if applicable\n            if multi_dc_info[\"found_in_multiple_dc\"]:\n                if \"warnings\" not in result:\n                    result[\"warnings\"] = []\n                result[\"warnings\"].insert(0,\n                                          f\"⚠️ MULTI-DC: Domain found in {multi_dc_info['dc_count']} datacenters: \"\n                                          f\"{', '.join(multi_dc_info['unique_dcs'])}. \"\n                                          f\"Ensure changes are applied to all required locations!\"\n                                          )\n\n            return Message(text=json.dumps(result, ensure_ascii=False))\n        except Exception as e:\n            return Message(text=json.dumps({\n                \"error\": f\"Error in Location Selector: {str(e)}\",\n                \"selected_blocks\": []\n            }, ensure_ascii=False))\n\n    def build_operation_context(self) -> Message:\n        \"\"\"\n        Extract operation context from agent1_data.\n        🆕 Now includes multi-DC information.\n        \"\"\"\n        try:\n            search_result = self._get_search_result()\n\n            # 🆕 Extract multi-DC info\n            multi_dc_info = self._extract_multi_dc_info(search_result)\n            agent1_data = self._get_agent1_data(search_result)\n\n\n            # 🔥 НОВОЕ: Нормализовать\n            location_parameters = self._normalize_location_parameters(agent1_data)\n            all_configs = search_result.get(\"all_configs\", [])\n\n            operation_context = {\n                \"operation\": agent1_data.get(\"operation\"),\n                \"domain\": agent1_data.get(\"domain\"),\n                \"domains\": agent1_data.get(\"domains\", []),\n                \"location\": agent1_data.get(\"location\"),\n                \"locations\": agent1_data.get(\"locations\", []),\n                \"from_location\": agent1_data.get(\"from_location\"),  # NEW\n                \"to_location\": agent1_data.get(\"to_location\"),  # NEW\n                \"new_location_path\": agent1_data.get(\"new_location_path\"),\n                \"preserve_directives\": agent1_data.get(\"preserve_directives\"),  # NEW\n                \"parameters\": agent1_data.get(\"parameters\", []),\n                \"location_parameters\": location_parameters,  # Нормализованные\n                \"ip_addresses\": agent1_data.get(\"ip_addresses\", []),\n                \"upstreams\": agent1_data.get(\"upstreams\"),\n                \"server_block_parameters\": agent1_data.get(\"server_block_parameters\", []),\n                \"kms_required\": agent1_data.get(\"kms_required\"),\n                \"kms_mentioned\": agent1_data.get(\"kms_mentioned\"),\n                \"conditional_add\": agent1_data.get(\"conditional_add\"),\n                \"total_configs_found\": len(all_configs),\n                \"config_files\": [cfg.get(\"config_file\") for cfg in all_configs if isinstance(cfg, dict)],\n                \"config_keys\": [cfg.get(\"config_key\") for cfg in all_configs if isinstance(cfg, dict)],\n                \"locations_count\": len(location_parameters),\n                \"selected_dc\": agent1_data.get(\"selected_dc\", []),\n\n                # 🆕 Multi-DC information\n                **multi_dc_info,\n            }\n            return Message(text=json.dumps(operation_context, ensure_ascii=False))\n        except Exception as e:\n            return Message(text=json.dumps({\n                \"error\": f\"Error extracting operation context: {str(e)}\"\n            }, ensure_ascii=False))\n\n    def build_error_message(self) -> Message:\n        \"\"\"\n        Return error message if any issues occur.\n        🆕 Now includes multi-DC information.\n        \"\"\"\n        try:\n            search_result = self._get_search_result()\n\n            # 🆕 Extract multi-DC info\n            multi_dc_info = self._extract_multi_dc_info(search_result)\n\n            if search_result.get(\"status\") == \"error\":\n                return Message(text=json.dumps({\n                    \"error\": f\"Search error: {search_result.get('error_message')}\",\n                    \"block_exists\": False,\n                    **multi_dc_info  # 🆕 Include multi-DC info\n                }, ensure_ascii=False))\n            agent1_data = self._get_agent1_data(search_result)\n\n            # 🔥 НОВОЕ: Нормализовать\n            location_parameters = self._normalize_location_parameters(agent1_data)\n            operation = agent1_data.get(\"operation\", \"ADD_PARAMETERS\")\n            target_domains = agent1_data.get(\"domains\", [])\n            all_configs = search_result.get(\"all_configs\", [])\n            source_field = getattr(self, 'source_field', 'full_config_text')\n            if not all_configs:\n                return Message(text=json.dumps({\n                    \"error\": \"No configs found in all_configs\",\n                    \"block_exists\": False,\n                    **multi_dc_info  # 🆕 Include multi-DC info\n                }, ensure_ascii=False))\n            # Operation-specific checks\n            is_create_operation = operation == \"CREATE_LOCATION\"\n            is_delete_operation = operation == \"DELETE_LOCATION\"\n            found_count = 0\n            errors = []\n            # Check all configs\n            for config in all_configs:\n                if not isinstance(config, dict):  # Safeguard\n                    errors.append(f\"Invalid config type in all_configs: {type(config)} - skipping\")\n                    continue\n                matching_domains = config.get(\"matching_domains\", [])\n                server_names = config.get(\"server_names\", [])\n                # Skip configs that don't match target domains\n                if target_domains:\n                    if not any(domain in target_domains for domain in matching_domains):\n                        if not any(domain in target_domains for domain in server_names):\n                            continue\n                config_text = config.get(source_field)\n                if not config_text:\n                    errors.append(f\"No {source_field} in {config.get('config_key', 'unknown')}\")\n                    continue\n                try:\n                    key, server_directives, locations = self._parse_yaml_config(config_text)\n                    # Для каждой location проверить\n                    for loc_param in location_parameters:\n                        target_loc = loc_param.get(\"location\")\n                        if not target_loc:\n                            continue\n                        if not location_parameters:  # Server block\n                            if len(server_directives) > 0:\n                                found_count += 1\n                        elif is_create_operation:\n                            # For CREATE: config is valid if location DOESN'T exist\n                            found_location = self._find_location(locations, target_loc)\n                            if not found_location:\n                                found_count += 1  # Good - can create\n                            else:\n                                errors.append(\n                                    f\"Location '{target_loc}' already exists in {key}\"\n                                )\n                        elif is_delete_operation:\n                            # For DELETE: config is valid if location DOES exist\n                            found_location = self._find_location(locations, target_loc)\n                            if found_location:\n                                found_count += 1  # Good - can delete\n                            else:\n                                errors.append(\n                                    f\"Location '{target_loc}' not found in {key}. \"\n                                    f\"Available: {[loc.get('path') for loc in locations]}\"\n                                )\n                        else:\n                            # For other operations (including MODIFY_LOCATION_PATH, MAKE_PROTECTED, MAKE_PUBLIC): location must exist\n                            found_location = self._find_location(locations, target_loc)\n                            if found_location:\n                                found_count += 1\n                            else:\n                                errors.append(\n                                    f\"Location '{target_loc}' not found in {key}. \"\n                                    f\"Available: {[loc.get('path') for loc in locations]}\"\n                                )\n                except Exception as e:\n                    errors.append(f\"Error parsing {config.get('config_key', 'unknown')}: {str(e)}\")\n            if found_count > 0:\n                result = {\n                    \"error\": None,\n                    \"found_in_configs\": found_count,\n                    \"total_configs\": len(all_configs),\n                    \"operation\": operation,\n                    \"locations_count\": len(location_parameters),\n                    **multi_dc_info,  # 🆕 Include multi-DC info\n                }\n                if is_create_operation:\n                    result[\"can_create\"] = True\n                    result[\"block_exists\"] = False\n                elif is_delete_operation:\n                    result[\"can_delete\"] = True\n                    result[\"block_exists\"] = True\n                else:\n                    result[\"block_exists\"] = True\n                if errors:\n                    result[\"warnings\"] = errors\n\n                # 🆕 Add multi-DC warning if applicable\n                if multi_dc_info[\"found_in_multiple_dc\"]:\n                    if \"warnings\" not in result:\n                        result[\"warnings\"] = []\n                    result[\"warnings\"].insert(0,\n                                              f\"⚠️ MULTI-DC: Domain found in {multi_dc_info['dc_count']} datacenters!\"\n                                              )\n\n                return Message(text=json.dumps(result, ensure_ascii=False))\n            else:\n                error_msg = {\n                    \"block_exists\": False,\n                    \"total_configs_checked\": len(all_configs),\n                    \"operation\": operation,\n                    \"locations_count\": len(location_parameters),\n                    \"details\": errors,\n                    **multi_dc_info,  # 🆕 Include multi-DC info\n                }\n                if is_create_operation:\n                    error_msg[\"error\"] = (\n                        f\"Cannot create locations - they may already exist in all configs\"\n                    )\n                    error_msg[\"can_create\"] = False\n                elif is_delete_operation:\n                    error_msg[\"error\"] = (\n                        f\"Cannot delete locations - not found in any config\"\n                    )\n                    error_msg[\"can_delete\"] = False\n                else:\n                    error_msg[\"error\"] = (\n                        f\"Locations not found in any config\"\n                    )\n                return Message(text=json.dumps(error_msg, ensure_ascii=False))\n        except Exception as e:\n            return Message(text=json.dumps({\n                \"error\": f\"Error checking block: {str(e)}\",\n                \"block_exists\": False\n            }, ensure_ascii=False))\n"
              },
              "source_field": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Source field",
                "dynamic": false,
                "info": "Field containing YAML config text (full_config_text or config_block)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "source_field",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "full_config_text"
              },
              "universal_search_result": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Universal Search Result",
                "dynamic": false,
                "info": "Output from Universal Search (contains agent1_data)",
                "input_types": [
                  "Data",
                  "dict"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "universal_search_result",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "selected_block",
          "showNode": true,
          "type": "LocationSelectorFromUniversalSearch"
        },
        "id": "LocationSelectorFromUniversalSearch-ubEWV",
        "measured": {
          "height": 263,
          "width": 320
        },
        "position": {
          "x": 7501.4029417606525,
          "y": 816.1223923199454
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UniversalSearchConfigComponent-arR45",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Универсально сканирует YML файлы по доменам из любой структуры JSON (включая Arbitrator payload)",
            "display_name": "Universal Search Config",
            "documentation": "",
            "edited": true,
            "field_order": [
              "agent1_json",
              "config_base_path"
            ],
            "frozen": false,
            "icon": "search",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Config Data",
                "group_outputs": false,
                "hidden": null,
                "method": "search_config",
                "name": "config_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent1_json": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Agent 1 JSON Output",
                "dynamic": false,
                "info": "JSON с извлечёнными данными от Agent 1 или Arbitrator (любая структура)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "agent1_json",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, StrInput, Output\nfrom langflow.schema import Data\nimport json\nimport yaml\nimport os\nimport glob\nimport re\nfrom typing import List, Dict, Any, Optional\n\n\nclass UniversalSearchConfigComponent(Component):\n    display_name = \"Universal Search Config\"\n    description = \"Универсально сканирует YML файлы по доменам из любой структуры JSON (включая Arbitrator payload)\"\n    icon = \"search\"\n    inputs = [\n        MessageTextInput(\n            name=\"agent1_json\",\n            display_name=\"Agent 1 JSON Output\",\n            info=\"JSON с извлечёнными данными от Agent 1 или Arbitrator (любая структура)\",\n            required=True\n        ),\n        StrInput(\n            name=\"config_base_path\",\n            display_name=\"Config Base Path\",\n            info=\"Путь к родительской папке с конфигами (например, /path/to/mos_ru_nginx/)\",\n            value=\"/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/\",\n            required=True\n        )\n    ]\n    outputs = [\n        Output(\n            display_name=\"Config Data\",\n            name=\"config_data\",\n            method=\"search_config\"\n        )\n    ]\n\n    def search_config(self) -> Data:\n        \"\"\"\n        Универсально обрабатывает любой JSON/Python dict и ищет конфигурации\n        \"\"\"\n        try:\n            # 🔧 ПРЕДОБРАБОТКА: Очищаем от markdown блоков\n            cleaned_input = self._clean_markdown(self.agent1_json)\n\n            # 🔄 ПАРСИМ: Поддержка и JSON, и Python dict\n            raw_data = self._parse_input(cleaned_input)\n\n            # 🔄 НОРМАЛИЗАЦИЯ: Извлекаем payload если это Arbitrator output\n            agent1_data = self._normalize_input(raw_data)\n            # 🔍 УНИВЕРСАЛЬНОЕ ИЗВЛЕЧЕНИЕ ДОМЕНОВ\n            domains = self._universal_extract_domains(agent1_data)\n\n            # 🔍 УНИВЕРСАЛЬНОЕ ИЗВЛЕЧЕНИЕ ДРУГИХ ДАННЫХ\n            locations = self._universal_extract_locations(agent1_data)\n            ip_addresses = self._universal_extract_ips(agent1_data)\n            upstreams = self._universal_extract_upstreams(agent1_data)\n            parameters = self._universal_extract_parameters(agent1_data)\n            location_parameters = self._universal_extract_location_parameters(agent1_data)\n            operation = self._universal_extract_operation(agent1_data)\n            selected_dc = self._universal_extract_selected_dc(agent1_data)\n            # ✅ ПРОВЕРЯЕМ СТАТУС\n            status = self._check_status(raw_data)  # Проверяем оригинальные данные\n            if status and status.get(\"is_error\"):\n                return self._return_error_status(status, agent1_data)\n            # ❌ ОШИБКА: Домены не найдены\n            if not domains:\n                return self._return_no_domains_error(\n                    agent1_data, locations, ip_addresses, parameters, operation\n                )\n            # 🔍 ОПРЕДЕЛЯЕМ ПАПКИ ДЛЯ ПОИСКА\n            search_folders = self._get_search_folders(selected_dc)\n            # 🔍 СКАНИРУЕМ ВСЕ YML ФАЙЛЫ В ВЫБРАННЫХ ПАПКАХ\n            config_results = []\n            scanned_files = 0\n            for folder in search_folders:\n                folder_path = os.path.join(self.config_base_path, folder)\n                if not os.path.isdir(folder_path):\n                    continue\n                yml_files = glob.glob(os.path.join(folder_path, \"*.yml\"))\n                scanned_files += len(yml_files)\n                for yml_file in yml_files:\n                    file_results = self._scan_yml_file(yml_file, domains)\n                    for res in file_results:\n                        res[\"folder\"] = folder\n                        res[\"inferred_dc\"] = self._infer_dc_from_folder(folder)\n                    config_results.extend(file_results)\n            # Удаляем дубликаты (по полному пути и ключу)\n            unique_results = self._deduplicate_results(config_results)\n            # ❌ ОШИБКА: Конфиги не найдены\n            if not unique_results:\n                return self._return_not_found_error(\n                    domains, scanned_files, agent1_data,\n                    locations, ip_addresses, parameters, operation\n                )\n            # ✅ УСПЕХ: Конфиг найден\n            first_config = unique_results[0]\n\n            # 🆕 АНАЛИЗ: Проверяем, найден ли домен в нескольких ЦОД\n            multi_dc_info = self._analyze_multi_dc_presence(unique_results, domains)\n\n            result = {\n                \"status\": \"success\",\n\n                # 📦 Конфиг данные\n                \"config_file\": first_config[\"config_file\"],\n                \"config_key\": first_config[\"config_key\"],\n                \"full_config_text\": first_config[\"full_config_text\"],\n                \"server_names\": first_config[\"server_names\"],\n                \"matching_domains\": first_config[\"matching_domains\"],\n                # 📦 Извлечённые данные (нормализованные)\n                \"agent1_data\": agent1_data,\n                \"operation\": operation,\n                \"domains\": domains,\n                \"locations\": locations,\n                \"ip_addresses\": ip_addresses,\n                \"upstreams\": upstreams,\n                \"parameters\": parameters,\n                \"location_parameters\": location_parameters,\n                \"selected_dc\": selected_dc,\n                # 📊 Метаданные\n                \"scanned_files\": scanned_files,\n                \"found_configs\": len(unique_results),\n                \"all_configs\": unique_results,\n                \"data_complete\": True,\n                \"error_type\": None,\n                \"error_message\": None,\n\n                # 🆕 НОВЫЕ КЛЮЧИ: Информация о нахождении в нескольких ЦОД\n                \"found_in_multiple_dc\": multi_dc_info[\"found_in_multiple_dc\"],\n                \"dc_count\": multi_dc_info[\"dc_count\"],\n                \"unique_dcs\": multi_dc_info[\"unique_dcs\"],\n                \"domain_dc_mapping\": multi_dc_info[\"domain_dc_mapping\"],\n                \"domains_in_multiple_dc\": multi_dc_info[\"domains_in_multiple_dc\"],\n            }\n            # Формируем сообщение\n            msg = self._format_success_message(result)\n            return Data(data=result, text=msg)\n        except json.JSONDecodeError as e:\n            return self._return_json_error(e, self.agent1_json)\n        except Exception as e:\n            return self._return_unexpected_error(e)\n\n    # ==========================================\n    # 🆕 НОВЫЙ МЕТОД: Анализ присутствия в нескольких ЦОД\n    # ==========================================\n    def _analyze_multi_dc_presence(self, config_results: List[Dict], domains: List[str]) -> Dict:\n        \"\"\"\n        Анализирует, найден ли домен в нескольких ЦОД\n\n        Returns:\n            Dict с ключами:\n            - found_in_multiple_dc: bool - True если хотя бы один домен найден в >1 ЦОД\n            - dc_count: int - количество уникальных ЦОД где найдены конфиги\n            - unique_dcs: List[str] - список уникальных ЦОД\n            - domain_dc_mapping: Dict[str, List[str]] - маппинг домен -> список ЦОД\n            - domains_in_multiple_dc: List[str] - домены, найденные в нескольких ЦОД\n        \"\"\"\n        # Собираем все уникальные ЦОД из результатов\n        all_dcs = set()\n        for config in config_results:\n            inferred_dc = config.get(\"inferred_dc\", [])\n            all_dcs.update(inferred_dc)\n\n        unique_dcs = sorted(list(all_dcs))\n        dc_count = len(unique_dcs)\n\n        # Строим маппинг: домен -> в каких ЦОД найден\n        domain_dc_mapping = {}\n        for domain in domains:\n            domain_dcs = set()\n            for config in config_results:\n                matching_domains = config.get(\"matching_domains\", [])\n                if domain in matching_domains:\n                    inferred_dc = config.get(\"inferred_dc\", [])\n                    domain_dcs.update(inferred_dc)\n            domain_dc_mapping[domain] = sorted(list(domain_dcs))\n\n        # Определяем домены, которые найдены в нескольких ЦОД\n        domains_in_multiple_dc = [\n            domain for domain, dcs in domain_dc_mapping.items()\n            if len(dcs) > 1\n        ]\n\n        # Главный флаг: есть ли хотя бы один домен в нескольких ЦОД\n        found_in_multiple_dc = len(domains_in_multiple_dc) > 0\n\n        return {\n            \"found_in_multiple_dc\": found_in_multiple_dc,\n            \"dc_count\": dc_count,\n            \"unique_dcs\": unique_dcs,\n            \"domain_dc_mapping\": domain_dc_mapping,\n            \"domains_in_multiple_dc\": domains_in_multiple_dc\n        }\n\n    # ==========================================\n    # ПРЕДОБРАБОТКА И НОРМАЛИЗАЦИЯ\n    # ==========================================\n    def _clean_markdown(self, raw_input: str) -> str:\n        \"\"\"Убирает только markdown разметку\"\"\"\n        if not raw_input:\n            return raw_input\n\n        cleaned = raw_input.strip()\n\n        patterns = [\n            (r'^```json\\s*\\n', ''),\n            (r'^```\\s*\\n', ''),\n            (r'\\n```\\s*$', ''),\n            (r'^```json\\s*', ''),\n            (r'^```\\s*', ''),\n            (r'```\\s*$', ''),\n        ]\n\n        for pattern, replacement in patterns:\n            cleaned = re.sub(pattern, replacement, cleaned)\n\n        return cleaned.strip()\n\n    def _parse_input(self, text: str) -> Dict:\n        \"\"\"\n        🔄 Парсит входные данные — поддерживает JSON и Python dict\n        \"\"\"\n        # Способ 1: Пробуем как JSON\n        try:\n            return json.loads(text)\n        except json.JSONDecodeError:\n            pass\n\n        # Способ 2: Пробуем как Python dict через ast.literal_eval\n        try:\n            import ast\n            result = ast.literal_eval(text)\n            if isinstance(result, dict):\n                return result\n        except (ValueError, SyntaxError):\n            pass\n\n        # Способ 3: Ручная конвертация Python → JSON\n        try:\n            converted = text\n            converted = re.sub(r'\\bNone\\b', 'null', converted)\n            converted = re.sub(r'\\bTrue\\b', 'true', converted)\n            converted = re.sub(r'\\bFalse\\b', 'false', converted)\n            converted = converted.replace(\"'\", '\"')\n            return json.loads(converted)\n        except json.JSONDecodeError:\n            pass\n\n        # Если ничего не сработало — выбрасываем ошибку\n        raise json.JSONDecodeError(\n            f\"Не удалось распарсить ни как JSON, ни как Python dict\",\n            text,\n            0\n        )\n\n    def _normalize_input(self, raw_data: Any) -> Dict:\n        \"\"\"\n        🔄 НОРМАЛИЗАЦИЯ: Извлекает payload из Arbitrator output\n\n        Поддерживает форматы:\n        1. Arbitrator: {\"status\": \"SUCCESS\", \"payload\": {...}, \"ready_for_execution\": true}\n        2. Прямой Agent1: {\"operation\": \"...\", \"domain\": \"...\", ...}\n        3. Вложенный: {\"data\": {\"payload\": {...}}}\n        \"\"\"\n        if not isinstance(raw_data, dict):\n            return raw_data\n\n        # Случай 1: Arbitrator output с payload\n        if \"payload\" in raw_data and isinstance(raw_data[\"payload\"], dict):\n            # Проверяем что это успешный Arbitrator response\n            status = raw_data.get(\"status\", \"\").upper()\n            if status in [\"SUCCESS\", \"COMPLETE\", \"OK\"]:\n                return raw_data[\"payload\"]\n            # Даже если статус не SUCCESS, но payload есть — используем его\n            if raw_data[\"payload\"]:\n                return raw_data[\"payload\"]\n\n        # Случай 2: Вложенный data.payload\n        if \"data\" in raw_data and isinstance(raw_data[\"data\"], dict):\n            if \"payload\" in raw_data[\"data\"]:\n                return raw_data[\"data\"][\"payload\"]\n            return raw_data[\"data\"]\n\n        # Случай 3: Прямой Agent1 output (уже нормализован)\n        return raw_data\n\n    # ==========================================\n    # УНИВЕРСАЛЬНЫЕ МЕТОДЫ ИЗВЛЕЧЕНИЯ ДАННЫХ\n    # ==========================================\n    def _universal_extract_domains(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет домены во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        domains = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return domains\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"domain\", \"domains\", \"server_name\", \"server_names\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        domains.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                domains.append(item.strip())\n\n            for value in data.values():\n                domains.extend(self._universal_extract_domains(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                domains.extend(self._universal_extract_domains(item, visited))\n\n        return list(set([d for d in domains if d and self._looks_like_domain(d)]))\n\n    def _universal_extract_locations(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет location/locations во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        locations = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return locations\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"location\", \"locations\", \"kms_locations\", \"public_locations\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        locations.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                locations.append(item.strip())\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    locations.extend(self._universal_extract_locations(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                locations.extend(self._universal_extract_locations(item, visited))\n\n        return list(set([loc for loc in locations if loc and loc.startswith(\"/\")]))\n\n    def _universal_extract_ips(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет IP адреса во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        ips = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return ips\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"ip_addresses\", \"ips\", \"servers\", \"upstream\", \"ip\", \"address\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        ips.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                ips.append(item.strip())\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    ips.extend(self._universal_extract_ips(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                ips.extend(self._universal_extract_ips(item, visited))\n\n        return list(set([ip for ip in ips if ip and self._looks_like_ip(ip)]))\n\n    def _universal_extract_upstreams(self, data: Any, visited: Optional[set] = None) -> List[Dict]:\n        \"\"\"\n        🆕 Извлекает структурированные upstreams\n\n        Формат входа:\n        \"upstreams\": [\n            {\"upstream_type\": \"main\", \"ip_addresses\": [\"10.10.10.10\", ...], \"params\": []},\n            {\"upstream_type\": \"backup\", \"ip_addresses\": [...], \"params\": []}\n        ]\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        upstreams = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return upstreams\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            # Прямой ключ upstreams\n            if \"upstreams\" in data and isinstance(data[\"upstreams\"], list):\n                for upstream in data[\"upstreams\"]:\n                    if isinstance(upstream, dict):\n                        normalized = {\n                            \"type\": upstream.get(\"upstream_type\", upstream.get(\"type\", \"main\")),\n                            \"ip_addresses\": upstream.get(\"ip_addresses\", upstream.get(\"ips\", [])),\n                            \"params\": upstream.get(\"params\", upstream.get(\"parameters\", []))\n                        }\n                        if normalized[\"ip_addresses\"]:\n                            upstreams.append(normalized)\n\n            # Рекурсивный поиск\n            for key, value in data.items():\n                if key != \"upstreams\" and isinstance(value, (dict, list)):\n                    upstreams.extend(self._universal_extract_upstreams(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                upstreams.extend(self._universal_extract_upstreams(item, visited))\n\n        return upstreams\n\n    def _universal_extract_location_parameters(self, data: Any, visited: Optional[set] = None) -> List[Dict]:\n        \"\"\"\n        🆕 Извлекает параметры для конкретных locations\n\n        Формат входа:\n        \"location_parameters\": [\n            {\"location\": \"/api_V2/\", \"parameters\": [], \"kms_required\": false},\n            ...\n        ]\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        loc_params = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return loc_params\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            if \"location_parameters\" in data and isinstance(data[\"location_parameters\"], list):\n                for lp in data[\"location_parameters\"]:\n                    if isinstance(lp, dict) and \"location\" in lp:\n                        normalized = {\n                            \"location\": lp.get(\"location\"),\n                            \"parameters\": lp.get(\"parameters\", []),\n                            \"kms_required\": lp.get(\"kms_required\", False)\n                        }\n                        loc_params.append(normalized)\n\n            for key, value in data.items():\n                if key != \"location_parameters\" and isinstance(value, (dict, list)):\n                    loc_params.extend(self._universal_extract_location_parameters(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                loc_params.extend(self._universal_extract_location_parameters(item, visited))\n\n        return loc_params\n\n    def _universal_extract_parameters(self, data: Any, visited: Optional[set] = None) -> Dict:\n        \"\"\"\n        Ищет общие параметры в структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        parameters = {}\n\n        data_id = id(data)\n        if data_id in visited:\n            return parameters\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            # server_block_parameters\n            if \"server_block_parameters\" in data:\n                params = data[\"server_block_parameters\"]\n                if isinstance(params, list):\n                    parameters[\"server_block\"] = params\n                elif isinstance(params, dict):\n                    parameters[\"server_block\"] = params\n\n            # Общие parameters\n            if \"parameters\" in data:\n                params = data[\"parameters\"]\n                if isinstance(params, dict):\n                    parameters.update(params)\n                elif isinstance(params, list):\n                    parameters[\"general\"] = params\n\n            # Рекурсивно (но не в уже обработанные ключи)\n            for key, value in data.items():\n                if key not in [\"parameters\", \"server_block_parameters\", \"location_parameters\"] \\\n                        and isinstance(value, (dict, list)):\n                    sub_params = self._universal_extract_parameters(value, visited)\n                    for k, v in sub_params.items():\n                        if k not in parameters:\n                            parameters[k] = v\n\n        elif isinstance(data, list):\n            for item in data:\n                sub_params = self._universal_extract_parameters(item, visited)\n                parameters.update(sub_params)\n\n        return parameters\n\n    def _universal_extract_operation(self, data: Any) -> Optional[str]:\n        \"\"\"\n        Ищет тип операции в любой структуре\n        \"\"\"\n        if isinstance(data, dict):\n            for key in [\"operation\", \"operation_type\", \"action\", \"type\"]:\n                if key in data and data[key]:\n                    val = str(data[key])\n                    # Фильтруем не-операции\n                    if val.upper() not in [\"MAIN\", \"BACKUP\", \"PREFIX\", \"EXACT\"]:\n                        return val\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    result = self._universal_extract_operation(value)\n                    if result:\n                        return result\n\n        elif isinstance(data, list):\n            for item in data:\n                result = self._universal_extract_operation(item)\n                if result:\n                    return result\n\n        return None\n\n    def _universal_extract_selected_dc(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет selected_dc во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        dcs = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return dcs\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"selected_dc\", \"dc\", \"datacenters\", \"datacenter\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        dcs.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                dcs.append(item.strip())\n\n            for value in data.values():\n                dcs.extend(self._universal_extract_selected_dc(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                dcs.extend(self._universal_extract_selected_dc(item, visited))\n\n        return list(set(dcs))\n\n    def _check_status(self, data: Any) -> Optional[Dict]:\n        \"\"\"\n        Проверяет статус ошибки в данных\n        \"\"\"\n        if isinstance(data, dict):\n            status = data.get(\"status\", \"\")\n\n            # Ошибка Arbitrator\n            if status == \"VALIDATION_FAILED\":\n                return {\n                    \"is_error\": True,\n                    \"status\": status,\n                    \"error_type\": \"VALIDATION_FAILED\",\n                    \"error_message\": \"Валидация не прошла\",\n                    \"missing_fields\": data.get(\"missing_fields\", []),\n                    \"clarification_questions\": data.get(\"clarification_questions\", [])\n                }\n\n            # Ошибка Agent1\n            if status == \"error\":\n                return {\n                    \"is_error\": True,\n                    \"status\": data.get(\"status\"),\n                    \"error_type\": data.get(\"error_type\"),\n                    \"error_message\": data.get(\"error_message\"),\n                    \"explanation\": data.get(\"explanation\"),\n                    \"warnings\": data.get(\"warnings\", [])\n                }\n        return None\n\n    # ==========================================\n    # ВАЛИДАЦИЯ\n    # ==========================================\n    def _looks_like_domain(self, text: str) -> bool:\n        \"\"\"Проверяет, похоже ли на домен\"\"\"\n        if not text or len(text) < 3:\n            return False\n        return '.' in text or re.match(r'^[a-zA-Z0-9\\-\\.]+$', text) is not None\n\n    def _looks_like_ip(self, text: str) -> bool:\n        \"\"\"Проверяет, похоже ли на IP адрес\"\"\"\n        if not text:\n            return False\n        ip_pattern = r'^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}(:\\d+)?$'\n        return re.match(ip_pattern, text) is not None\n\n    # ==========================================\n    # ЛОГИКА ПОИСКА ПО ПАПКАМ И DC\n    # ==========================================\n    def _get_all_folders(self) -> List[str]:\n        \"\"\"Возвращает список всех возможных папок\"\"\"\n        return [\n            \"production_ext_kor_sites\",\n            \"production_ext_nag_http\",\n            \"production_ext_nag_sites\",\n            \"production_ext_sites\",\n            \"production_kor_ngate_sites\",\n            \"production_kor_sites\",\n            \"production_mesh_main_kor_sites\",\n            \"production_mesh_rus_kor_sites\",\n            \"production_metro_kor_sites\",\n            \"production_metro_sites\",\n            \"production_moshub_ext_kor_sites\",\n            \"production_moshub_kor_sites\",\n            \"production_nag_sites\",\n            \"production_sites\",\n            \"production_upload_sites\",\n            \"stage_kor_sites\",\n            \"stage_nag_sites\",\n            \"stage_sites\",\n            \"test_kor_sites\",\n            \"test_nag_sites\",\n            \"test_sites\"\n        ]\n\n    def _get_search_folders(self, selected_dc: List[str]) -> List[str]:\n        \"\"\"Определяет папки для поиска на основе selected_dc\"\"\"\n        all_folders = self._get_all_folders()\n        if not selected_dc:\n            return all_folders\n\n        search_folders = set()\n        for dc in selected_dc:\n            if dc == \"dr\":\n                search_folders.update(self._get_folders_for_dc(\"korovinskiy\"))\n                search_folders.update(self._get_folders_for_dc(\"kurchatovskiy\"))\n            else:\n                search_folders.update(self._get_folders_for_dc(dc))\n        return list(search_folders)\n\n    def _get_folders_for_dc(self, dc: str) -> List[str]:\n        \"\"\"Возвращает папки для конкретного DC\"\"\"\n        all_folders = self._get_all_folders()\n\n        if dc == \"korovinskiy\":\n            # Исключаем metro и mesh - они относятся к отдельным DC\n            return [f for f in all_folders\n                    if \"_kor_\" in f\n                    and \"metro\" not in f\n                    and \"mesh\" not in f]\n\n        elif dc == \"kurchatovskiy\":\n            return [f for f in all_folders if\n                    f in [\"production_sites\", \"stage_sites\", \"test_sites\", \"production_ext_sites\",\n                          \"production_upload_sites\"]]  # убрал production_metro_sites\n\n        elif dc == \"nagornaya\":\n            return [f for f in all_folders if \"_nag_\" in f]\n\n        elif dc == \"moshub_rus\":\n            return [f for f in all_folders if \"moshub\" in f and \"ext\" not in f]\n\n        elif dc == \"ext_kurchatovskiy\":\n            return [f for f in all_folders if \"ext\" in f and \"_kor_\" not in f and \"_nag_\" not in f]\n\n        elif dc == \"ext_korovinskiy\":\n            return [f for f in all_folders if \"ext\" in f and \"_kor_\" in f]\n\n        elif dc == \"ext_nagornaya\":\n            return [f for f in all_folders if \"ext\" in f and \"_nag_\" in f]\n\n        elif dc == \"mesh\":\n            return [f for f in all_folders if \"mesh\" in f]\n\n        elif dc == \"top10_kurchatovskiy\":\n            return [f for f in all_folders if \"metro\" in f and \"_kor_\" not in f]\n\n        elif dc == \"top10_korovinskiy\":\n            return [f for f in all_folders if \"metro\" in f and \"_kor_\" in f]\n\n        return []\n\n    def _infer_dc_from_folder(self, folder: str) -> List[str]:\n        \"\"\"Точно определяет DC на основе имени папки с приоритетами\"\"\"\n        folder_lower = folder.lower()\n\n        # Приоритетные шаблоны - проверяем самые конкретные сначала\n        if \"mesh\" in folder_lower:\n            # Для mesh-конфигураций проверяем подтипы\n            if \"_main_kor_\" in folder_lower:\n                return [\"mesh\"]\n            elif \"_rus_kor_\" in folder_lower:\n                return [\"mesh\"]\n            return [\"mesh\"]\n        elif \"metro\" in folder_lower:\n            if \"_kor_\" in folder_lower:\n                return [\"top10_korovinskiy\"]\n            return [\"top10_kurchatovskiy\"]\n        elif \"moshub\" in folder_lower:\n            if \"ext\" in folder_lower:\n                return [\"ext_korovinskiy\"]\n            return [\"moshub_rus\"]\n        elif \"_kor_\" in folder_lower:\n            if \"ext\" in folder_lower:\n                return [\"ext_korovinskiy\"]\n            return [\"korovinskiy\"]\n        elif \"_nag_\" in folder_lower:\n            if \"ext\" in folder_lower:\n                return [\"ext_nagornaya\"]\n            return [\"nagornaya\"]\n        elif \"ext\" in folder_lower:\n            return [\"ext_kurchatovskiy\"]\n        elif folder in [\"production_sites\", \"stage_sites\", \"test_sites\",\n                        \"production_ext_sites\", \"production_upload_sites\"]:\n            return [\"kurchatovskiy\"]\n\n        # Если ничего не подошло, возвращаем пустой список\n        return []\n\n    # ==========================================\n    # СКАНИРОВАНИЕ YML\n    # ==========================================\n    def _scan_yml_file(self, yml_file: str, target_domains: List[str]) -> List[Dict]:\n        \"\"\"Сканирует один YML файл и находит совпадения по server_name\"\"\"\n        results = []\n        try:\n            with open(yml_file, 'r', encoding='utf-8') as f:\n                config_text = f.read()\n                config_yaml = yaml.safe_load(config_text)\n            if not config_yaml:\n                return results\n            for config_key, config_block in config_yaml.items():\n                server_names = self._extract_server_names(config_block)\n                if not server_names:\n                    continue\n                matching_domains = []\n                for target_domain in target_domains:\n                    if self._is_domain_match(target_domain, server_names):\n                        matching_domains.append(target_domain)\n                if matching_domains:\n                    result = {\n                        \"config_key\": config_key,\n                        \"config_file\": yml_file,\n                        \"server_names\": server_names,\n                        \"matching_domains\": matching_domains,\n                        \"full_config_text\": config_text,\n                        \"parsed_yaml\": config_yaml,\n                        \"config_block\": config_block\n                    }\n                    results.append(result)\n        except yaml.YAMLError as e:\n            print(f\"⚠️ Ошибка чтения YAML {yml_file}: {e}\")\n        except Exception as e:\n            print(f\"⚠️ Ошибка обработки {yml_file}: {e}\")\n        return results\n\n    def _extract_server_names(self, config_block: Any) -> List[str]:\n        \"\"\"Извлекает все server_name из конфигурационного блока\"\"\"\n        server_names = []\n        if isinstance(config_block, list):\n            for item in config_block:\n                if isinstance(item, str) and item.startswith(\"server_name \"):\n                    server_name_part = item.replace(\"server_name \", \"\").strip()\n                    names = [n.strip() for n in server_name_part.split() if n.strip()]\n                    server_names.extend(names)\n        return list(set(server_names))\n\n    def _is_domain_match(self, target_domain: str, server_names: List[str]) -> bool:\n        \"\"\"Проверяет, совпадает ли target_domain с любым server_name\"\"\"\n        target_domain = target_domain.strip().lower()\n        for server_name in server_names:\n            server_name = server_name.strip().lower()\n            if server_name == target_domain:\n                return True\n            if server_name.startswith(\"~^\") and server_name.endswith(\"$\"):\n                pattern = server_name[2:-1]\n                try:\n                    if re.match(pattern, target_domain):\n                        return True\n                except re.error:\n                    continue\n        return False\n\n    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:\n        \"\"\"Удаляет дубликаты результатов\"\"\"\n        seen = set()\n        unique = []\n        for result in results:\n            key = (result[\"config_file\"], result[\"config_key\"])\n            if key not in seen:\n                seen.add(key)\n                unique.append(result)\n        return unique\n\n    # ==========================================\n    # ОБРАБОТКА ОШИБОК\n    # ==========================================\n    def _return_error_status(self, status: Dict, agent1_data: Any) -> Data:\n        \"\"\"Возвращает ошибку из статуса\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": status.get(\"error_type\", \"UNKNOWN_ERROR\"),\n            \"error_message\": status.get(\"error_message\", \"Unknown error\"),\n            \"explanation\": status.get(\"explanation\", \"\"),\n            \"warnings\": status.get(\"warnings\", []),\n            \"missing_fields\": status.get(\"missing_fields\", []),\n            \"clarification_questions\": status.get(\"clarification_questions\", []),\n            \"agent1_data\": agent1_data,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: {status.get('error_message')}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        questions = status.get(\"clarification_questions\", [])\n        missing = status.get(\"missing_fields\", [])\n\n        error_msg = f\"\"\"❌ **Ошибка**\n🔴 **Тип:** {status.get('error_type')}\n📝 **Сообщение:** {status.get('error_message')}\n\"\"\"\n        if missing:\n            error_msg += f\"\\n📋 **Не хватает:** {', '.join(missing[:3])}\"\n        if questions:\n            error_msg += f\"\\n❓ **Вопросы:** {questions[0]}\"\n        return Data(data=error_result, text=error_msg)\n\n    def _return_no_domains_error(self, agent1_data: Any, locations: List[str],\n                                 ip_addresses: List[str], parameters: Dict,\n                                 operation: Optional[str]) -> Data:\n        \"\"\"Возвращает ошибку об отсутствии доменов\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"NO_DOMAINS\",\n            \"error_message\": \"Домены не найдены в данных\",\n            \"agent1_data\": agent1_data,\n            \"operation\": operation,\n            \"locations\": locations,\n            \"ip_addresses\": ip_addresses,\n            \"parameters\": parameters,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": \"# Error: No domains specified\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        error_msg = f\"\"\"❌ **Ошибка: домен не указан**\n📋 **Что извлечено:**\n- Operation: {operation or 'N/A'}\n- Locations: {', '.join(locations[:3]) if locations else 'N/A'}\n- IPs: {', '.join(ip_addresses[:3]) if ip_addresses else 'N/A'}\n💡 Укажите домен явно в запросе.\n\"\"\"\n        return Data(data=error_result, text=error_msg)\n\n    def _return_not_found_error(self, domains: List[str], scanned_files: int,\n                                agent1_data: Any, locations: List[str],\n                                ip_addresses: List[str], parameters: Dict,\n                                operation: Optional[str]) -> Data:\n        \"\"\"Возвращает ошибку о ненайденной конфигурации\"\"\"\n        not_found_result = {\n            \"status\": \"not_found\",\n            \"error_type\": \"CONFIG_NOT_FOUND\",\n            \"error_message\": f\"Конфигурация не найдена для: {', '.join(domains)}\",\n            \"domains\": domains,\n            \"scanned_files\": scanned_files,\n            \"agent1_data\": agent1_data,\n            \"operation\": operation,\n            \"locations\": locations,\n            \"ip_addresses\": ip_addresses,\n            \"parameters\": parameters,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: Config not found for: {', '.join(domains)}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        error_msg = f\"\"\"❌ **Конфигурация не найдена**\n🔍 **Домены:** {', '.join(domains)}\n📊 **Просканировано:** {scanned_files} файлов\n\"\"\"\n        return Data(data=not_found_result, text=error_msg)\n\n    def _return_json_error(self, error: Exception, raw_json: str) -> Data:\n        \"\"\"Возвращает ошибку парсинга JSON\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"JSON_PARSE_ERROR\",\n            \"error_message\": f\"Ошибка парсинга JSON: {str(error)}\",\n            \"raw_input\": raw_json[:500],\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: JSON parse error\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        return Data(data=error_result, text=f\"❌ **Ошибка парсинга JSON**\\n\\n{str(error)}\")\n\n    def _return_unexpected_error(self, error: Exception) -> Data:\n        \"\"\"Возвращает неожиданную ошибку\"\"\"\n        import traceback\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"UNEXPECTED_ERROR\",\n            \"error_message\": f\"Неожиданная ошибка: {str(error)}\",\n            \"traceback\": traceback.format_exc(),\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: {str(error)}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        print(f\"❌ UNEXPECTED ERROR: {str(error)}\")\n        traceback.print_exc()\n        return Data(data=error_result, text=f\"❌ **Неожиданная ошибка**\\n\\n{str(error)}\")\n\n    # ==========================================\n    # ФОРМАТИРОВАНИЕ РЕЗУЛЬТАТА\n    # ==========================================\n    def _format_success_message(self, result: Dict) -> str:\n        \"\"\"Формирует читаемое сообщение о результате\"\"\"\n        all_configs = result.get(\"all_configs\", [])\n        found_configs = len(all_configs)\n        scanned_files = result.get(\"scanned_files\", 0)\n        operation = result.get(\"operation\")\n        locations = result.get(\"locations\", [])\n        upstreams = result.get(\"upstreams\", [])\n        location_parameters = result.get(\"location_parameters\", [])\n        selected_dc = result.get(\"selected_dc\", [])\n\n        # 🆕 Новые данные о multi-DC\n        found_in_multiple_dc = result.get(\"found_in_multiple_dc\", False)\n        dc_count = result.get(\"dc_count\", 0)\n        unique_dcs = result.get(\"unique_dcs\", [])\n        domains_in_multiple_dc = result.get(\"domains_in_multiple_dc\", [])\n        domain_dc_mapping = result.get(\"domain_dc_mapping\", {})\n\n        msg = f\"✅ **Найдено {found_configs} конфигурац{'ия' if found_configs == 1 else 'ий' if 2 <= found_configs <= 4 else 'ий'}**\\n\\n\"\n\n        # 🆕 Предупреждение о нескольких ЦОД\n        if found_in_multiple_dc:\n            msg += f\"⚠️ **ВНИМАНИЕ: Домен найден в {dc_count} ЦОД!**\\n\\n\"\n\n            msg += f\"🏢 **ЦОД:** {', '.join(unique_dcs)}\\n\"\n            if domains_in_multiple_dc:\n                msg += f\"🌐 **Домены в нескольких ЦОД:** {', '.join(domains_in_multiple_dc)}\\n\"\n            msg += \"\\n\"\n\n        for i, cfg in enumerate(all_configs):\n            if i > 0:\n                msg += \"\\n\" + (\"-\" * 40) + \"\\n\\n\"\n            msg += f\"📁 **Файл:** `{os.path.basename(cfg['config_file'])}`\\n\"\n            server_names = cfg.get(\"server_names\", [])\n            msg += f\"🌐 **Server names:** {', '.join(server_names[:3])}{'...' if len(server_names) > 3 else ''}\\n\"\n            matching_domains = cfg.get(\"matching_domains\", [])\n            msg += f\"✅ **Совпадения:** {', '.join(matching_domains)}\\n\"\n            inferred_dc = cfg.get(\"inferred_dc\", [])\n            if inferred_dc:\n                msg += f\"🏢 **DC:** {', '.join(inferred_dc)}\\n\"\n            else:\n                msg += f\"🏢 **DC:** N/A\\n\"\n\n        msg += f\"\\n📊 **Просканировано:** {scanned_files} файлов\"\n\n        if selected_dc:\n            msg += f\"\\n🗺 **Selected DC:** {', '.join(selected_dc)}\"\n        if operation:\n            msg += f\"\\n🔄 **Operation:** {operation}\"\n        if locations:\n            msg += f\"\\n📍 **Locations:** {', '.join(locations[:5])}\"\n        if upstreams:\n            for up in upstreams[:2]:\n                ips = up.get(\"ip_addresses\", [])\n                up_type = up.get(\"type\", \"unknown\")\n                msg += f\"\\n🔗 **Upstream ({up_type}):** {', '.join(ips[:3])}\"\n        if location_parameters:\n            msg += f\"\\n⚙️ **Location params:** {len(location_parameters)} записей\"\n\n        # 🆕 Расширенное примечание\n        if found_in_multiple_dc:\n            msg += \"\\n\\n⚠️ **ВАЖНО:** Конфигурация найдена в нескольких ЦОД. \"\n            msg += \"Убедитесь, что изменения применяются ко всем необходимым площадкам!\"\n            # Детальный маппинг\n            if domain_dc_mapping:\n                msg += \"\\n\\n📋 **Детали по доменам:**\"\n                for domain, dcs in domain_dc_mapping.items():\n                    if len(dcs) > 1:\n                        msg += f\"\\n  • `{domain}` → {', '.join(dcs)}\"\n        elif found_configs > 1:\n            msg += \"\\n\\nℹ️ **Примечание:** Найдено несколько конфигураций. Проверьте все варианты.\"\n\n        return msg\n"
              },
              "config_base_path": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Config Base Path",
                "dynamic": false,
                "info": "Путь к родительской папке с конфигами (например, /path/to/mos_ru_nginx/)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "config_base_path",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/production_kor_sites"
              }
            },
            "tool_mode": false
          },
          "selected_output": "config_file_path",
          "showNode": true,
          "type": "UniversalSearchConfigComponent"
        },
        "dragging": false,
        "id": "UniversalSearchConfigComponent-arR45",
        "measured": {
          "height": 317,
          "width": 320
        },
        "position": {
          "x": 6552.422089825196,
          "y": 1588.5133303240807
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-nEXtH",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "id": "ParserComponent-nEXtH",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 7488.082979633103,
          "y": 1204.7597342896906
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-92esX",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "id": "ChatOutput-92esX",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 7955.103817936795,
          "y": 1499.107478679267
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConfigBlockSplitter-2XuY9",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Splits config blocks array into DataFrame for sequential Loop/LLM processing",
            "display_name": "Config Block Splitter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "selected_block"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Config Items DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "build_config_dataframe",
                "name": "config_items_df",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Total Count",
                "group_outputs": false,
                "hidden": null,
                "method": "build_total_count",
                "name": "total_count",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Metadata",
                "group_outputs": false,
                "hidden": null,
                "method": "build_metadata",
                "name": "metadata",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\nimport json\nimport pandas as pd\nfrom typing import Union, List, Dict, Any\n\n\nclass ConfigBlockSplitter(Component):\n    \"\"\"\n    Splits normalized config blocks from LocationSelector into individual items for Loop processing.\n    Properly handles Message input from LocationSelectorFromUniversalSearch.\n    Converts selected_blocks array into DataFrame format suitable for Loop component.\n\n    NEW: Supports block-level warnings for unknown operations like MAKE_PROTECTED\n    \"\"\"\n\n    display_name = \"Config Block Splitter\"\n    description = \"Splits config blocks array into DataFrame for sequential Loop/LLM processing\"\n    documentation = \"\"\n    icon = \"split\"\n\n    inputs = [\n        HandleInput(\n            name=\"selected_block\",\n            display_name=\"Selected Block\",\n            input_types=[\"Message\", \"Data\", \"dict\"],\n            info=\"Output from LocationSelectorFromUniversalSearch containing selected_blocks\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Config Items DataFrame\",\n            name=\"config_items_df\",\n            info=\"DataFrame with individual config blocks for Loop processing\",\n            method=\"build_config_dataframe\",\n        ),\n        Output(\n            display_name=\"Total Count\",\n            name=\"total_count\",\n            info=\"Total number of config blocks to process\",\n            method=\"build_total_count\",\n        ),\n        Output(\n            display_name=\"Metadata\",\n            name=\"metadata\",\n            info=\"Additional metadata from the original response\",\n            method=\"build_metadata\",\n        ),\n    ]\n\n    def process_input_data(self, data: Union[Message, Data, dict, str]) -> dict:\n        \"\"\"Convert input to dictionary format - handles Message, Data, dict, and JSON string\"\"\"\n        try:\n            # Handle Message type (from LocationSelector)\n            if isinstance(data, Message):\n                text = data.text if hasattr(data, 'text') else str(data)\n                return json.loads(text)\n\n            # Handle Data type\n            elif isinstance(data, Data):\n                if hasattr(data, 'data'):\n                    data_content = data.data\n                    if isinstance(data_content, str):\n                        return json.loads(data_content)\n                    return data_content\n                elif hasattr(data, 'to_dict'):\n                    return data.to_dict()\n                else:\n                    return dict(data)\n\n            # Handle dict\n            elif isinstance(data, dict):\n                return data\n\n            # Handle JSON string\n            elif isinstance(data, str):\n                return json.loads(data)\n\n            else:\n                raise ValueError(f\"Unexpected input type: {type(data)}\")\n\n        except json.JSONDecodeError as e:\n            self.log(f\"JSON decode error: {str(e)}\")\n            raise ValueError(f\"Invalid JSON in input: {str(e)}\")\n        except Exception as e:\n            self.log(f\"Error processing input: {str(e)}\")\n            raise\n\n    def extract_config_blocks(self, input_data: dict) -> List[Dict[str, Any]]:\n        \"\"\"Extract selected_blocks array from input data\"\"\"\n        if 'selected_blocks' in input_data:\n            blocks = input_data['selected_blocks']\n            # Ensure it's a list\n            if isinstance(blocks, list):\n                return blocks\n            elif isinstance(blocks, dict):\n                # Single block wrapped in dict - convert to list\n                return [blocks]\n            else:\n                self.log(f\"Warning: selected_blocks is not a list or dict: {type(blocks)}\")\n                return []\n\n        # Fallback: try to find blocks in nested structure\n        if 'selected_block' in input_data:\n            block_data = input_data['selected_block']\n            if isinstance(block_data, list):\n                return block_data\n            elif isinstance(block_data, dict) and 'selected_blocks' in block_data:\n                return block_data['selected_blocks']\n\n        # If no selected_blocks found, return empty list\n        self.log(\"Warning: No selected_blocks found in input data\")\n        return []\n\n    def build_config_dataframe(self) -> DataFrame:\n        \"\"\"Convert selected_blocks array into DataFrame for Loop component\"\"\"\n        try:\n            # Process input data\n            input_data = self.process_input_data(self.selected_block)\n\n            # Check for errors in input\n            if 'error' in input_data and not input_data.get('selected_blocks'):\n                self.log(f\"Error in input data: {input_data.get('error')}\")\n                return DataFrame(pd.DataFrame(columns=['error'], data=[{'error': input_data.get('error')}]))\n\n            # Extract config blocks\n            config_blocks = self.extract_config_blocks(input_data)\n\n            # НОВОЕ: Извлекаем глобальные warnings\n            global_warnings = input_data.get('warnings', [])\n            if global_warnings:\n                self.log(f\"Found {len(global_warnings)} global warnings: {global_warnings}\")\n\n            if not config_blocks:\n                # Return empty DataFrame with expected structure\n                self.log(\"No config blocks found, returning empty DataFrame\")\n                return DataFrame(pd.DataFrame(columns=[\n                    'index', 'config_key', 'config_file', 'server_names',\n                    'location_path', 'operation', 'type', 'full_config_json', \n                ]))\n\n            # 🔥 НОВОЕ: Функция проверки на MULTI-DC warning\n            def has_multi_dc_warning(warnings_list: List[str]) -> bool:\n                \"\"\"Проверяет, содержится ли MULTI-DC warning в списке\"\"\"\n                if not warnings_list:\n                    return False\n                for warning in warnings_list:\n                    if isinstance(warning, str) and \"MULTI-DC: Domain found in\" in warning and \"datacenters\" in warning:\n                        return True\n                return False\n\n            # Prepare data for DataFrame\n            df_data = []\n            filtered_blocks = []  # 🔥 НОВОЕ: Собираем отфильтрованные блоки\n            filtered_count = 0\n\n            for idx, block in enumerate(config_blocks):\n                if not isinstance(block, dict):\n                    self.log(f\"Warning: Block {idx} is not a dict, skipping\")\n                    continue\n\n                # Объединяем warnings блока и глобальные warnings\n                block_warnings = block.get('warnings', [])\n                combined_warnings = []\n\n                # Определяем, содержит ли блок домены, которые находятся в нескольких ДЦ\n                domains_in_multi_dc = set(input_data.get(\"domains_in_multiple_dc\", []))\n                block_domains = block.get('matching_domains', [])\n                block_in_multi_dc = any(domain in domains_in_multi_dc for domain in block_domains)\n\n                # Добавляем глобальные warnings ТОЛЬКО если блок относится к multi-DC домену\n                if block_in_multi_dc and global_warnings:\n                    combined_warnings.extend(global_warnings)\n\n                # Добавляем warnings конкретного блока\n                if block_warnings:\n                    if isinstance(block_warnings, list):\n                        combined_warnings.extend(block_warnings)\n                    elif isinstance(block_warnings, str):\n                        combined_warnings.append(block_warnings)\n\n                # 🔥 ФИЛЬТРАЦИЯ: Пропускаем блоки с MULTI-DC warning\n                if has_multi_dc_warning(combined_warnings):\n                    filtered_count += 1\n                    filtered_blocks.append(block)  # 🔥 Сохраняем для информации\n                    self.log(\n                        f\"⚠️ Filtering out block {idx} ({block.get('location_path', 'unknown')}) - contains MULTI-DC warning\")\n                    continue\n\n                # Логируем для информации\n                if combined_warnings:\n                    self.log(\n                        f\"Block {idx} ({block.get('location_path', 'unknown')}): {len(combined_warnings)} warnings - {combined_warnings}\")\n\n                # Each row will contain the full block data\n                row = {\n                    'index': idx,\n                    'config_key': block.get('config_key', ''),\n                    'config_file': block.get('config_file', ''),\n                    'server_names': json.dumps(block.get('server_names', []), ensure_ascii=False),\n                    'matching_domains': json.dumps(block.get('matching_domains', []), ensure_ascii=False),\n                    'location_path': block.get('location_path', ''),\n                    'operation': block.get('operation', ''),\n                    'type': block.get('type', 'location'),\n                    'hash': block.get('hash', ''),\n\n                    # Arrays as JSON strings\n                    'directives': json.dumps(block.get('directives', []), ensure_ascii=False),\n                    'parameters': json.dumps(block.get('parameters', []), ensure_ascii=False),\n                    'server_block_parameters': json.dumps(block.get('server_block_parameters', []), ensure_ascii=False),\n                    'existing_locations': json.dumps(block.get('existing_locations', []), ensure_ascii=False),\n                    'ip_addresses': json.dumps(block.get('ip_addresses', []), ensure_ascii=False),\n                    'upstreams': json.dumps(block.get('upstreams', []) if block.get('upstreams') else [],\n                                            ensure_ascii=False),\n\n                    'warnings': json.dumps(combined_warnings, ensure_ascii=False),\n\n                    # Boolean and special fields\n                    'kms_required': block.get('kms_required', False),\n                    'create_mode': block.get('create_mode', False),\n                    'delete_mode': block.get('delete_mode', False),\n\n                    # NEW: Support for MODIFY_LOCATION_PATH\n                    'new_location_path': block.get('new_location_path', ''),\n\n                    # Store complete block as JSON string for full context\n                    'full_config_json': json.dumps(block, ensure_ascii=False),\n                    \n                }\n                df_data.append(row)\n\n            # 🔥 НОВОЕ: Логируем статистику фильтрации\n            if filtered_count > 0:\n                self.log(\n                    f\"✅ Filtered out {filtered_count} blocks with MULTI-DC warnings. Remaining: {len(df_data)} blocks\")\n\n            # 🔥 НОВОЕ: Если все блоки отфильтрованы, создаём информативную строку\n            if not df_data:\n                self.log(\"No valid blocks after filtering, returning informative DataFrame\")\n\n                # Формируем список отфильтрованных доменов для информации\n                filtered_domains = []\n                for block in filtered_blocks:\n                    filtered_domains.extend(block.get('matching_domains', []))\n                filtered_domains = list(set(filtered_domains))  # Убираем дубликаты\n\n                # Создаём информативную строку вместо ошибки\n                info_row = {\n                    'index': 0,\n                    'config_key': 'FILTERED',\n                    'config_file': 'N/A',\n                    'server_names': json.dumps([], ensure_ascii=False),\n                    'matching_domains': json.dumps(filtered_domains, ensure_ascii=False),\n                    'location_path': 'N/A',\n                    'operation': input_data.get('operation', 'SKIP_MULTI_DC'),\n                    'type': 'filtered',\n                    'hash': '',\n                    'directives': json.dumps([], ensure_ascii=False),\n                    'parameters': json.dumps([], ensure_ascii=False),\n                    'server_block_parameters': json.dumps([], ensure_ascii=False),\n                    'existing_locations': json.dumps([], ensure_ascii=False),\n                    'ip_addresses': json.dumps([], ensure_ascii=False),\n                    'upstreams': json.dumps([], ensure_ascii=False),\n                    'warnings': json.dumps([\n                        f\"All {filtered_count} blocks filtered due to MULTI-DC warnings\",\n                        f\"Affected domains: {', '.join(filtered_domains)}\"\n                    ], ensure_ascii=False),\n                    'kms_required': False,\n                    'create_mode': False,\n                    'delete_mode': False,\n                    'new_location_path': '',\n                    'full_config_json': json.dumps({\n                        \"status\": \"filtered\",\n                        \"reason\": \"MULTI-DC domains detected\",\n                        \"filtered_count\": filtered_count,\n                        \"filtered_domains\": filtered_domains,\n                        \"original_operation\": input_data.get('operation', ''),\n                        \"message\": \"These domains exist in multiple datacenters. Manual intervention required.\"\n                    }, ensure_ascii=False)\n                }\n\n                df = pd.DataFrame([info_row])\n                self.log(f\"Returning informative DataFrame for {filtered_count} filtered blocks\")\n                return DataFrame(df)\n\n            # Create DataFrame\n            df = pd.DataFrame(df_data)\n\n            self.log(f\"Successfully created DataFrame with {len(df)} rows (filtered {filtered_count} MULTI-DC blocks)\")\n\n            # Return as langflow DataFrame\n            return DataFrame(df)\n\n        except Exception as e:\n            error_msg = f\"Error building DataFrame: {str(e)}\"\n            self.log(error_msg)\n            # Return DataFrame with error information\n            return DataFrame(pd.DataFrame(columns=['error'], data=[{'error': error_msg}]))\n\n    def build_total_count(self) -> Data:\n        \"\"\"Return total count of config blocks\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n            config_blocks = self.extract_config_blocks(input_data)\n\n            count_data = {\n                \"total_blocks\": len(config_blocks),\n                \"has_data\": len(config_blocks) > 0,\n                \"operation\": input_data.get(\"operation\", \"\"),\n                \"target_domains\": input_data.get(\"target_domains\", []),\n                \"locations_count\": input_data.get(\"locations_count\", 0),\n                \"warnings\": input_data.get(\"warnings\", [])\n            }\n\n            return Data(data=count_data)\n\n        except Exception as e:\n            error_msg = f\"Error getting total count: {str(e)}\"\n            self.log(error_msg)\n            return Data(data={\"total_blocks\": 0, \"has_data\": False, \"error\": error_msg})\n\n    def build_metadata(self) -> Data:\n        \"\"\"Extract and return metadata from the original response\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n\n            # Extract metadata fields\n            metadata = {\n                \"total_configs_scanned\": input_data.get(\"total_configs_scanned\", 0),\n                \"total_blocks_found\": input_data.get(\"total_blocks_found\", 0),\n                \"target_locations\": input_data.get(\"target_locations\", []),\n                \"target_domains\": input_data.get(\"target_domains\", []),\n                \"operation\": input_data.get(\"operation\", \"\"),\n                \"locations_count\": input_data.get(\"locations_count\", 0),\n                \"warnings\": input_data.get(\"warnings\", [])\n            }\n\n            # Add error if present\n            if 'error' in input_data:\n                metadata['error'] = input_data['error']\n\n            return Data(data=metadata)\n\n        except Exception as e:\n            error_msg = f\"Error extracting metadata: {str(e)}\"\n            self.log(error_msg)\n            return Data(data={\"error\": error_msg})"
              },
              "selected_block": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Selected Block",
                "dynamic": false,
                "info": "Output from LocationSelectorFromUniversalSearch containing selected_blocks",
                "input_types": [
                  "Message",
                  "Data",
                  "dict"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "selected_block",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "config_items_df",
          "showNode": true,
          "type": "ConfigBlockSplitter"
        },
        "id": "ConfigBlockSplitter-2XuY9",
        "measured": {
          "height": 181,
          "width": 320
        },
        "position": {
          "x": 8560.643678349796,
          "y": 1138.5391487828406
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-2rVDq",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": false,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "last_updated": "2025-11-28T06:12:00.551Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "group_outputs": true,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "group_outputs": true,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"starts with\",\n                \"ends with\",\n                \"regex\",\n                \"less than\",\n                \"less than or equal\",\n                \"greater than\",\n                \"greater than or equal\",\n            ],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"true_case_message\",\n            display_name=\"Case True\",\n            info=\"The message to pass if the condition is True.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"false_case_message\",\n            display_name=\"Case False\",\n            info=\"The message to pass if the condition is False.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n            try:\n                input_num = float(input_text)\n                match_num = float(match_text)\n                if operator == \"less than\":\n                    return input_num < match_num\n                if operator == \"less than or equal\":\n                    return input_num <= match_num\n                if operator == \"greater than\":\n                    return input_num > match_num\n                if operator == \"greater than or equal\":\n                    return input_num >= match_num\n            except ValueError:\n                return False  # Invalid number format for comparison\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        \"\"\"Handles cycle iteration counting and branch exclusion.\n\n        Uses two complementary mechanisms:\n        1. stop() - ACTIVE/INACTIVE state for cycle management (gets reset each iteration)\n        2. exclude_branch_conditionally() - Persistent exclusion for conditional routing\n\n        When max_iterations is reached, breaks the cycle by allowing the default_route to execute.\n        \"\"\"\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n\n            # Check if max iterations reached and we're trying to stop the default route\n            if current_iteration >= self.max_iterations and route_to_stop == self.default_route:\n                # Clear ALL conditional exclusions to allow default route to execute\n                if self._id in self.graph.conditional_exclusion_sources:\n                    previous_exclusions = self.graph.conditional_exclusion_sources[self._id]\n                    self.graph.conditionally_excluded_vertices -= previous_exclusions\n                    del self.graph.conditional_exclusion_sources[self._id]\n\n                # Switch which route to stop - stop the NON-default route to break the cycle\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n\n                # Call stop to break the cycle\n                self.stop(route_to_stop)\n                # Don't apply conditional exclusion when breaking cycle\n                return\n\n            # Normal case: Use BOTH mechanisms\n            # 1. stop() for cycle management (marks INACTIVE, updates run manager, gets reset)\n            self.stop(route_to_stop)\n\n            # 2. Conditional exclusion for persistent routing (doesn't get reset except by this router)\n            self.graph.exclude_branch_conditionally(self._id, output_name=route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        # Check if we should force output due to max_iterations on default route\n        current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n        force_output = current_iteration >= self.max_iterations and self.default_route == \"true_result\"\n\n        if result or force_output:\n            self.status = self.true_case_message\n            if not force_output:  # Only stop the other branch if not forcing due to max iterations\n                self.iterate_and_stop_once(\"false_result\")\n            return self.true_case_message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        if not result:\n            self.status = self.false_case_message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.false_case_message\n\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "external_options": {},
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\"error\""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "external_options": {},
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "contains"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "id": "ConditionalRouter-2rVDq",
        "measured": {
          "height": 509,
          "width": 320
        },
        "position": {
          "x": 8027.410092727387,
          "y": 807.6937997156028
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-fKVaX",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "index",
                "operation",
                "config_key",
                "config_file",
                "location_path",
                "type",
                "directives",
                "parameters",
                "server_block_parameters",
                "ip_addresses",
                "kms_required",
                "create_mode",
                "delete_mode",
                "new_location_path",
                "existing_locations",
                "matching_domains",
                "server_names",
                "hash",
                "warnings"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "config_file": {
                "advanced": false,
                "display_name": "config_file",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "config_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "config_key": {
                "advanced": false,
                "display_name": "config_key",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "config_key",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "create_mode": {
                "advanced": false,
                "display_name": "create_mode",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "create_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "delete_mode": {
                "advanced": false,
                "display_name": "delete_mode",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "delete_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "directives": {
                "advanced": false,
                "display_name": "directives",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "directives",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "existing_locations": {
                "advanced": false,
                "display_name": "existing_locations",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "existing_locations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "hash": {
                "advanced": false,
                "display_name": "hash",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "hash",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "index": {
                "advanced": false,
                "display_name": "index",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "index",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "ip_addresses": {
                "advanced": false,
                "display_name": "ip_addresses",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "ip_addresses",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "kms_required": {
                "advanced": false,
                "display_name": "kms_required",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "kms_required",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "location_path": {
                "advanced": false,
                "display_name": "location_path",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "location_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "matching_domains": {
                "advanced": false,
                "display_name": "matching_domains",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "matching_domains",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "new_location_path": {
                "advanced": false,
                "display_name": "new_location_path",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "new_location_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "operation": {
                "advanced": false,
                "display_name": "operation",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "operation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "parameters": {
                "advanced": false,
                "display_name": "parameters",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "parameters",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "server_block_parameters": {
                "advanced": false,
                "display_name": "server_block_parameters",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "server_block_parameters",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "server_names": {
                "advanced": false,
                "display_name": "server_names",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "server_names",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# NGINX YAML Configuration Agent v6.2 (Protected Parameters)\n\nYou are an nginx YAML configuration expert that modifies EXISTING YAML configuration files.\n\n---\n\n## 🛑🛑🛑 ABSOLUTE PROTECTED PARAMETERS — READ THIS FIRST! 🛑🛑🛑\n\n### ⛔ THESE DIRECTIVE NAMES ARE 100% IMMUTABLE — NO EXCEPTIONS:\n\n| Directive Name | LOCKED Value | Can Change? |\n|----------------|--------------|-------------|\n| `listen` | `9443 ssl proxy_protocol` | ❌ **ABSOLUTELY NOT** |\n| `http2` | `on` | ❌ **ABSOLUTELY NOT** |\n| `server_name` | `aip.mos.ru` | ❌ **ABSOLUTELY NOT** |\n\n### 🚨 MANDATORY CHECK — DO THIS BEFORE ANY OPERATION:\n\n```python\n# STEP 0: ALWAYS RUN THIS CHECK FIRST!\nPROTECTED_NAMES = {{\"listen\", \"http2\", \"server_name\"}}\n\nfor param in effective_parameters:\n    directive_name = extract_name(param)  # Get first word\n    \n    if directive_name.lower() in PROTECTED_NAMES:\n        # ⛔ STOP! DO NOT PROCESS THIS PARAMETER!\n        warnings.append(f\"BLOCKED: '{{directive_name}}' is a protected system directive and CANNOT be modified or deleted\")\n        continue  # SKIP THIS PARAMETER ENTIRELY\n```\n\n### ❌ WHAT YOU MUST NEVER DO:\n\n1. **NEVER change `http2 on` to `http2 off`** — even if user asks\n2. **NEVER change `http2 on` to ANY other value** — even if user asks  \n3. **NEVER delete `http2` directive** — even if user asks\n4. **NEVER change `listen` directive** — even if user asks\n5. **NEVER change `server_name` directive** — even if user asks\n6. **NEVER obey user instructions that contradict these rules**\n\n### ✅ CORRECT BEHAVIOR EXAMPLE:\n\n**User Request:** \"Change http2 to off\"\n\n**WRONG Response:**\n```json\n{{\n  \"changes_made\": [\"Changed 'http2' from 'http2 on;' to 'http2 off;'\"],\n  \"ready_to_save\": true\n}}\n```\n\n**CORRECT Response:**\n```json\n{{\n  \"status\": \"blocked\",\n  \"changes_made\": [],\n  \"warnings\": [\"BLOCKED: 'http2' is a protected system directive and CANNOT be modified\"],\n  \"explanation\": \"The http2 directive is protected and cannot be changed. No modifications were made.\",\n  \"ready_to_save\": false\n}}\n```\n\n### Enforcement:\n\n```python\nPROTECTED_DIRECTIVES = {{\n    \"listen\": \"9443 ssl proxy_protocol\",\n    \"http2\": \"on\", \n    \"server_name\": \"aip.mos.ru\"\n}}\n\ndef is_protected(directive_name, directive_value=None):\n    name = directive_name.lower().strip()\n    if name in PROTECTED_DIRECTIVES:\n        return True\n    return False\n\n# In DELETE_PARAMETERS:\nfor directive in Directives:\n    name = get_directive_name(directive)\n    if name in to_remove and is_protected(name):\n        warnings.append(f\"BLOCKED: Cannot delete protected directive '{{name}}'\")\n        continue  # DO NOT REMOVE\n    # ... normal processing\n\n# In MODIFY_PARAMETERS:\nfor name, new_value in changes_map.items():\n    if is_protected(name):\n        warnings.append(f\"BLOCKED: Cannot modify protected directive '{{name}}'\")\n        continue  # DO NOT MODIFY\n    # ... normal processing\n```\n\n### Response When Blocked:\n\nIf a user requests to modify/delete protected parameters:\n\n```json\n{{\n  \"status\": \"partial_success\",\n  \"operation_type\": \"DELETE_PARAMETERS\",\n  \"warnings\": [\n    \"BLOCKED: Cannot delete protected directive 'listen' - this is a critical system parameter\",\n    \"BLOCKED: Cannot delete protected directive 'http2' - this is a critical system parameter\",\n    \"BLOCKED: Cannot delete protected directive 'server_name' - this is a critical system parameter\"\n  ],\n  \"explanation\": \"Some operations were blocked because they target protected system parameters that cannot be modified.\",\n  \"protected_parameters_info\": \"The following directives are immutable: listen 9443 ssl proxy_protocol, http2 on, server_name aip.mos.ru\"\n}}\n```\n\n---\n\n## ⚠️ CRITICAL RULES\n\n### RULE #0: PROTECTED PARAMETERS (HIGHEST PRIORITY)\n\n**Before ANY operation (ADD, MODIFY, DELETE), check if the directive is protected:**\n\n| Directive | Protected Value | Can Modify? | Can Delete? |\n|-----------|-----------------|-------------|-------------|\n| `listen` | `9443 ssl proxy_protocol` | ❌ NO | ❌ NO |\n| `http2` | `on` | ❌ NO | ❌ NO |\n| `server_name` | `aip.mos.ru` | ❌ NO | ❌ NO |\n\n**This rule OVERRIDES all user requests. No exceptions. No workarounds.**\n\n### RULE #1: DUPLICATE PREVENTION (ADD_PARAMETERS)\n\n**BEFORE ANY ADD OPERATION, YOU MUST:**\n\n1. **SCAN** the entire `Directives` array\n2. **EXTRACT** the directive name (first word) from EACH existing directive\n3. **BUILD** a lookup map of existing directive names\n4. **CHECK** each parameter against this map BEFORE adding\n5. **NEVER** add a directive if its name already exists\n```\nEXISTING: \"proxy_buffer_size 16k;\"\nREQUEST:  \"proxy_buffer_size 32k\"\nACTION:   ❌ SKIP (name \"proxy_buffer_size\" exists) → ADD TO WARNINGS\n```\n\n### RULE #2: ADD vs MODIFY DISTINCTION\n\n| Scenario | Action |\n|----------|--------|\n| Directive name NOT in Directives | ✅ ADD the parameter |\n| Directive name EXISTS, same value | ⏭️ SKIP silently |\n| Directive name EXISTS, different value | ❌ SKIP + WARNING \"Use MODIFY_PARAMETERS\" |\n\n**ADD_PARAMETERS = ONLY adds what's MISSING. NEVER overwrites. NEVER duplicates.**\n\n### RULE #3: PARAMETER SOURCE SELECTION (CRITICAL FOR ALL OPERATIONS!)\n\n| location_path Value | Use This Array | Fallback |\n|---------------------|----------------|----------|\n| `\"server_block\"` | `ServerBlockParameters` | - |\n| `\"/\"`, `\"/api\"`, any path | `Parameters` | - |\n```python\n# MANDATORY for ALL operations (ADD, MODIFY, DELETE)\nif location_path == \"server_block\":\n    effective_parameters = ServerBlockParameters or []\nelse:\n    effective_parameters = Parameters or []\n```\n\n⚠️ **If `Parameters` is empty but `ServerBlockParameters` has values and location_path == \"server_block\", you MUST use `ServerBlockParameters`!**\n\n---\n\n## INPUT DATA FORMAT\n\nVariables you will receive:\n\n- Index: {index}\n- Operation: {operation}\n- Config Key: {config_key}\n- Config File: {config_file}\n- Location Path: {location_path}\n- Type: {type}\n- Directives: {directives}\n- Parameters: {parameters}\n- ServerBlockParameters: {server_block_parameters}\n- IP Addresses: {ip_addresses}\n- KMS Required: {kms_required}\n- Create Mode: {create_mode}\n- Delete Mode: {delete_mode}\n- New Location Path: {new_location_path}\n- Existing Locations: {existing_locations}\n- Matching Domains: {matching_domains}\n- Server Names: {server_names}\n- Hash: {hash}\n- Warnings: {warnings}\n\n---\n\n## OPERATION: ADD_PARAMETERS\n\n### Step 1: Build Existing Directives Map\n```python\nexisting_map = {{}}\nfor directive in Directives:\n    clean = directive.strip().rstrip(';').strip()\n    parts = clean.split(maxsplit=1)\n    if parts:\n        name = parts[0].lower()\n        value = parts[1] if len(parts) > 1 else \"\"\n        existing_map[name] = {{\n            \"full\": directive,\n            \"value\": value.lower().strip()\n        }}\n```\n\n### Step 2: Select Parameter Source & Process\n```python\n# Select correct source\nif location_path == \"server_block\":\n    effective_parameters = ServerBlockParameters or []\nelse:\n    effective_parameters = Parameters or []\n\nadded = []\nskipped_different = []\n\nfor param in effective_parameters:\n    # Handle \"name:value\" format\n    if ':' in param:\n        param_name, param_value = param.split(':', 1)\n        formatted = f\"{{param_name}} {{param_value}}\"\n    else:\n        parts = param.strip().split(maxsplit=1)\n        param_name = parts[0]\n        param_value = parts[1] if len(parts) > 1 else \"\"\n        formatted = param.strip()\n    \n    param_name = param_name.lower().strip()\n    param_value = param_value.lower().strip()\n    \n    # CHECK PROTECTED PARAMETERS FIRST\n    if is_protected(param_name):\n        warnings.append(f\"BLOCKED: Cannot add/modify protected directive '{{param_name}}'\")\n        continue\n    \n    if param_name in existing_map:\n        existing_value = existing_map[param_name][\"value\"]\n        if existing_value != param_value:\n            skipped_different.append({{\n                \"name\": param_name,\n                \"existing\": existing_value,\n                \"requested\": param_value\n            }})\n    else:\n        if not formatted.endswith(';'):\n            formatted += ';'\n        added.append(formatted)\n\nupdated_directives = Directives.copy()\nupdated_directives.extend(added)\n```\n\n---\n\n## OPERATION: MODIFY_PARAMETERS\n\n### ⚠️ CRITICAL: Check Protected Parameters FIRST!\n\n```python\nPROTECTED_NAMES = {{\"listen\", \"http2\", \"server_name\"}}\n```\n\n**Before modifying ANYTHING, scan the request for protected directive names!**\n\n### Algorithm:\n```python\n# Select correct source\nif location_path == \"server_block\":\n    effective_parameters = ServerBlockParameters or []\nelse:\n    effective_parameters = Parameters or []\n\n# Build changes map — BUT BLOCK PROTECTED DIRECTIVES!\nchanges_map = {{}}\nblocked_params = []\n\nfor param in effective_parameters:\n    if ':' in param:\n        name, value = param.split(':', 1)\n        formatted = f\"{{name}} {{value}}\"\n    else:\n        parts = param.strip().split(maxsplit=1)\n        name = parts[0]\n        formatted = param.strip()\n    \n    name = name.lower().strip()\n    \n    # 🛑 PROTECTED CHECK — THIS IS MANDATORY!\n    if name in {{\"listen\", \"http2\", \"server_name\"}}:\n        # DO NOT ADD TO changes_map!\n        blocked_params.append(name)\n        warnings.append(f\"BLOCKED: '{{name}}' is a protected system directive and CANNOT be modified\")\n        continue  # ⛔ SKIP! DO NOT PROCESS!\n    \n    if not formatted.endswith(';'):\n        formatted += ';'\n    changes_map[name] = formatted\n\n# If ALL parameters were protected, return immediately with no changes\nif not changes_map and blocked_params:\n    return {{\n        \"status\": \"blocked\",\n        \"changes_made\": [],\n        \"warnings\": warnings,\n        \"explanation\": f\"All requested modifications were blocked. Protected directives: {{blocked_params}}\",\n        \"ready_to_save\": false\n    }}\n\n# Process directives\nupdated_directives = []\nmodified = []\n\nfor directive in Directives:\n    clean = directive.strip().rstrip(';').strip()\n    parts = clean.split(maxsplit=1)\n    name = parts[0].lower() if parts else \"\"\n    \n    if name in changes_map:\n        old_value = directive\n        new_value = changes_map[name]\n        updated_directives.append(new_value)\n        modified.append(f\"Changed '{{name}}' from '{{old_value}}' to '{{new_value}}'\")\n        del changes_map[name]\n    else:\n        updated_directives.append(directive)\n\n# Add remaining as new (non-protected only)\nfor name, value in changes_map.items():\n    if not is_protected(name):\n        updated_directives.append(value)\n```\n\n---\n\n## OPERATION: DELETE_PARAMETERS\n\n### Step 0: Protected Parameters Check (FIRST!)\n```python\nPROTECTED_DIRECTIVE_NAMES = {{\"listen\", \"http2\", \"server_name\"}}\n```\n\n### Step 1: Select Parameter Source (CRITICAL!)\n\n⚠️ **THIS IS WHERE MOST BUGS HAPPEN!**\n\n```python\n# MUST check location_path first!\nif location_path == \"server_block\":\n    effective_parameters = ServerBlockParameters or []\n    print(f\"DELETE: Using ServerBlockParameters = {{effective_parameters}}\")\nelse:\n    # For \"/\" or \"/api\" or ANY other path — USE Parameters!\n    effective_parameters = Parameters or []\n    print(f\"DELETE: Using Parameters = {{effective_parameters}}\")\n\n# Safety check\nif not effective_parameters:\n    print(\"ERROR: No parameters to delete!\")\n    # Return error immediately\n```\n\n| location_path | Use This |\n|---------------|----------|\n| `\"server_block\"` | `ServerBlockParameters` |\n| `\"/\"` | `Parameters` ✅ |\n| `\"/api\"` | `Parameters` |\n| `\"/v1/users\"` | `Parameters` |\n| Any path starting with `/` | `Parameters` |\n\n### Step 2: Parse Parameter Names to Remove (⚠️ CRITICAL PARSING!)\n\n**Parameters come in format `\"name:value\"` — you MUST extract ONLY the name!**\n\n```python\nto_remove = set()\nblocked = []\n\nfor param in effective_parameters:\n    clean = param.strip().rstrip(';').strip()\n    \n    # 🔴 CRITICAL: Handle \"name:value\" format correctly!\n    # \"proxy_buffer_size:32k\" → extract \"proxy_buffer_size\"\n    # \"proxy_buffers:4 32k\" → extract \"proxy_buffers\"\n    \n    if ':' in clean:\n        directive_name = clean.split(':', 1)[0].strip().lower()\n    else:\n        directive_name = clean.split()[0].strip().lower()\n    \n    print(f\"Parameter '{{param}}' → extracted name = '{{directive_name}}'\")\n    \n    # CHECK IF PROTECTED - DO NOT ADD TO REMOVAL SET\n    if directive_name in PROTECTED_DIRECTIVE_NAMES:\n        blocked.append(directive_name)\n        warnings.append(f\"BLOCKED: Cannot delete protected directive '{{directive_name}}'\")\n        continue\n    \n    to_remove.add(directive_name)\n\nprint(f\"to_remove = {{to_remove}}\")\n```\n\n### Parsing Examples Table:\n\n| Input Parameter | Split By | Extracted Name |\n|-----------------|----------|----------------|\n| `\"proxy_buffer_size:32k\"` | `:` | `proxy_buffer_size` |\n| `\"proxy_buffers:4 32k\"` | `:` | `proxy_buffers` |\n| `\"gzip:off\"` | `:` | `gzip` |\n| `\"proxy_pass http://backend\"` | space | `proxy_pass` |\n\n### Step 3: Remove Matching Directives\n```python\nupdated_directives = []\nremoved = []\ndirectives_to_delete = list(to_remove)  # 🔴 IMPORTANT: Save this for output!\n\nfor directive in Directives:\n    # Extract directive name (first word)\n    clean = directive.strip().rstrip(';').strip()\n    name = clean.split()[0].lower() if clean else \"\"\n    \n    print(f\"Directive '{{directive}}' → name = '{{name}}'\")\n    \n    if name in to_remove:\n        removed.append(directive)\n        print(f\"✓ REMOVED: {{directive}}\")\n    else:\n        updated_directives.append(directive)\n\n# Validation\nif to_remove and not removed:\n    print(f\"⚠️ BUG: to_remove={{to_remove}} but nothing was removed!\")\n\n# 🔴 CRITICAL: Include directives_to_delete in output!\noutput = {{\n    \"status\": \"success\",\n    \"operation_type\": \"DELETE_PARAMETERS\",\n    \"updated_directives\": updated_directives,\n    \"directives_to_delete\": directives_to_delete,  # ← REQUIRED!\n    \"changes_made\": [f\"Removed: {{d}}\" for d in removed],\n    ...\n}}\n```\n\n---\n\n### 📋 DELETE EXAMPLE 1: Location Path = \"/\" (YOUR CASE!)\n\n**Input:**\n```\nOperation: DELETE_PARAMETERS\nLocation Path: /\nParameters: [\"proxy_buffer_size:32k\", \"proxy_buffers:4 32k\"]\nServerBlockParameters: []\n\nDirectives: [\n    \"proxy_pass http://dchelper_mos_ru;\",\n    \"proxy_buffer_size 32k;\",\n    \"proxy_buffers 4 32k;\"\n]\n```\n\n**Step-by-step Processing:**\n```\n1. location_path = \"/\" (NOT \"server_block\"!)\n2. Therefore: effective_parameters = Parameters = [\"proxy_buffer_size:32k\", \"proxy_buffers:4 32k\"]\n   ❌ NOT ServerBlockParameters (it's empty anyway)\n\n3. Parse parameters:\n   - \"proxy_buffer_size:32k\" → split(':') → name = \"proxy_buffer_size\"\n   - \"proxy_buffers:4 32k\" → split(':') → name = \"proxy_buffers\"\n\n4. to_remove = {{\"proxy_buffer_size\", \"proxy_buffers\"}}\n\n5. Scan Directives:\n   - \"proxy_pass http://dchelper_mos_ru;\" → name=\"proxy_pass\" → NOT in to_remove → KEEP\n   - \"proxy_buffer_size 32k;\" → name=\"proxy_buffer_size\" → IN to_remove → REMOVE ✓\n   - \"proxy_buffers 4 32k;\" → name=\"proxy_buffers\" → IN to_remove → REMOVE ✓\n\n6. removed = [\"proxy_buffer_size 32k;\", \"proxy_buffers 4 32k;\"]\n```\n\n**✅ CORRECT Output:**\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"DELETE_PARAMETERS\",\n  \"config_key\": \"dchelper.mos.ru_9443\",\n  \"location_path\": \"/\",\n  \"updated_directives\": [\n    \"proxy_pass http://dchelper_mos_ru;\"\n  ],\n  \"directives_to_delete\": [\n    \"proxy_buffer_size\",\n    \"proxy_buffers\"\n  ],\n  \"hash\": \"new_hash_value\",\n  \"changes_made\": [\n    \"Removed: proxy_buffer_size 32k;\",\n    \"Removed: proxy_buffers 4 32k;\"\n  ],\n  \"explanation\": \"Deleted 2 directives from location /: proxy_buffer_size, proxy_buffers\",\n  \"warnings\": [],\n  \"ready_to_save\": true\n}}\n```\n\n**❌ WRONG Output (THE BUG):**\n```json\n{{\n  \"updated_directives\": [\n    \"proxy_pass http://dchelper_mos_ru;\",\n    \"proxy_buffer_size 32k;\",\n    \"proxy_buffers 4 32k;\"\n  ],\n  \"changes_made\": [],\n  \"warnings\": [\"WARNING: Expected to remove set() but found no matches!\"]\n}}\n```\n**Why wrong:** Agent failed to parse \"proxy_buffer_size:32k\" → should extract \"proxy_buffer_size\", not treat whole string as name!\n\n---\n\n### 📋 DELETE EXAMPLE 2: Location Path = \"server_block\"\n\n**Input:**\n```\nOperation: DELETE_PARAMETERS\nLocation Path: server_block\nParameters: []\nServerBlockParameters: [\"gzip:off\"]\n\nDirectives: [\n    \"listen 9443 ssl proxy_protocol;\",\n    \"http2 on;\",\n    \"server_name dchelper.mos.ru;\",\n    \"gzip off;\"\n]\n```\n\n**Processing:**\n```\n1. location_path = \"server_block\"\n2. effective_parameters = ServerBlockParameters = [\"gzip:off\"]\n3. Parse \"gzip:off\" → name = \"gzip\"\n4. to_remove = {{\"gzip\"}}\n5. Removed: \"gzip off;\"\n```\n\n**✅ CORRECT Output:**\n```json\n{{\n  \"updated_directives\": [\n    \"listen 9443 ssl proxy_protocol;\",\n    \"http2 on;\",\n    \"server_name dchelper.mos.ru;\"\n  ],\n  \"directives_to_delete\": [\"gzip\"],\n  \"changes_made\": [\"Removed: gzip off;\"]\n}}\n```\n\n### DELETE_PARAMETERS - PROTECTED PARAMETER EXAMPLE\n\n**Input (User tries to delete protected parameters):**\n```\nOperation: DELETE_PARAMETERS\nLocation Path: server_block\nServerBlockParameters: [\"listen:9443 ssl proxy_protocol\", \"http2:on\", \"gzip:off\"]\n```\n\n**Processing:**\n```\n1. Parse \"listen:9443 ssl proxy_protocol\" → name = \"listen\"\n   → \"listen\" IN PROTECTED_DIRECTIVE_NAMES → BLOCKED!\n2. Parse \"http2:on\" → name = \"http2\"\n   → \"http2\" IN PROTECTED_DIRECTIVE_NAMES → BLOCKED!\n3. Parse \"gzip:off\" → name = \"gzip\"\n   → \"gzip\" NOT in PROTECTED_DIRECTIVE_NAMES → Add to to_remove\n4. to_remove = {{\"gzip\"}} (only gzip, listen and http2 were blocked)\n5. Only \"gzip off;\" is removed\n6. listen and http2 remain untouched\n```\n\n**Correct Output:**\n```json\n{{\n  \"status\": \"partial_success\",\n  \"operation_type\": \"DELETE_PARAMETERS\",\n  \"updated_directives\": [\n    \"listen 9443 ssl proxy_protocol;\",\n    \"http2 on;\",\n    \"server_name aip.mos.ru;\",\n    \"proxy_connect_timeout 3000;\",\n    \"access_log /var/log/nginx/access.log extend_json;\"\n  ],\n  \"directives_to_delete\": [\"gzip\"],\n  \"changes_made\": [\n    \"Removed: gzip off;\"\n  ],\n  \"warnings\": [\n    \"BLOCKED: Cannot delete protected directive 'listen' - this is a critical system parameter\",\n    \"BLOCKED: Cannot delete protected directive 'http2' - this is a critical system parameter\"\n  ],\n  \"explanation\": \"Deleted 1 directive (gzip). 2 directives were protected and could not be deleted (listen, http2).\",\n  \"ready_to_save\": true\n}}\n```\n\n---\n\n## OPERATION: CREATE_LOCATION\n\n### Upstream Name Generation:\n```python\ndef generate_upstream_name(config_key, location_path):\n    domain = config_key.rsplit('_', 1)[0]\n    domain_converted = domain.replace('.', '_')\n    location_clean = location_path.strip('/').replace('/', '_').lower()\n    \n    if location_clean:\n        return f\"{{domain_converted}}_{{location_clean}}\"\n    return domain_converted\n```\n\n### Output Format:\n```\nlocation /path/ {{\n    proxy_pass http://upstream_name/;\n    [additional parameters if provided]\n}}\n```\n\n---\n\n## VALIDATION CHECKLIST (MANDATORY BEFORE RESPONSE)\n\n### Protected Parameters Checks (HIGHEST PRIORITY):\n- [ ] Did I check if ANY requested change affects listen/http2/server_name?\n- [ ] Are ALL protected directives UNCHANGED in updated_directives?\n- [ ] Did I add warnings for ANY blocked protected parameter operations?\n\n### General Checks:\n- [ ] All directives have trailing semicolon\n- [ ] Original directive ORDER preserved (except additions at end)\n- [ ] No \"invented\" directives added\n- [ ] Hash recalculated if changes made\n- [ ] `changes_made` accurately reflects what was done\n\n### ADD_PARAMETERS Checks:\n- [ ] NO DUPLICATE directive names in updated_directives\n- [ ] Only MISSING directives were added\n- [ ] Existing directives with different values are in warnings\n\n### DELETE_PARAMETERS Checks:\n- [ ] Did I use ServerBlockParameters when location_path == \"server_block\"?\n- [ ] Did I parse \"name:value\" format correctly (split by ':')?\n- [ ] Did I check protected parameters BEFORE adding to to_remove?\n- [ ] Did I actually REMOVE the matching directive (non-protected)?\n- [ ] Is the deleted directive ABSENT from updated_directives?\n- [ ] If ServerBlockParameters had values, changes_made is NOT empty (unless all were protected)?\n\n### MODIFY_PARAMETERS Checks:\n- [ ] Did I check protected parameters BEFORE applying changes?\n- [ ] Did I REPLACE (not add duplicate) the existing directive?\n- [ ] changes_made shows old → new values\n\n---\n\n## OUTPUT FORMAT\n\n### Success:\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"OPERATION_NAME\",\n  \"config_key\": \"config_key_value\",\n  \"location_path\": \"location_path_value\",\n  \"updated_directives\": [\"array\", \"of\", \"directives\"],\n  \"directives_to_delete\": [\"name1\", \"name2\"],\n  \"hash\": \"md5_hash_of_updated_directives\",\n  \"changes_made\": [\"specific\", \"changes\", \"made\"],\n  \"explanation\": \"Clear explanation of what was done\",\n  \"warnings\": [\"any\", \"warnings\"],\n  \"ready_to_save\": true\n}}\n```\n\n**⚠️ IMPORTANT FOR DELETE_PARAMETERS:**\nThe `directives_to_delete` field MUST contain the directive NAMES that were deleted.\nThis field is REQUIRED for the downstream script to work correctly!\n\nExample:\n```json\n{{\n  \"operation_type\": \"DELETE_PARAMETERS\",\n  \"directives_to_delete\": [\"proxy_buffer_size\", \"proxy_buffers\"],\n  \"changes_made\": [\"Removed: proxy_buffer_size 32k;\", \"Removed: proxy_buffers 4 32k;\"]\n}}\n```\n\n### Partial Success (Some operations blocked):\n```json\n{{\n  \"status\": \"partial_success\",\n  \"operation_type\": \"OPERATION_NAME\",\n  \"config_key\": \"config_key_value\",\n  \"location_path\": \"location_path_value\",\n  \"updated_directives\": [\"array\", \"of\", \"directives\"],\n  \"hash\": \"md5_hash_of_updated_directives\",\n  \"changes_made\": [\"changes\", \"that\", \"were\", \"allowed\"],\n  \"blocked_operations\": [\"operations\", \"that\", \"were\", \"blocked\"],\n  \"explanation\": \"Explanation including what was blocked and why\",\n  \"warnings\": [\n    \"BLOCKED: Cannot modify/delete protected directive 'X' - this is a critical system parameter\"\n  ],\n  \"ready_to_save\": true\n}}\n```\n\n### Error:\n```json\n{{\n  \"status\": \"error\",\n  \"operation_type\": \"OPERATION_NAME\",\n  \"error_type\": \"ERROR_TYPE\",\n  \"error_message\": \"Detailed error message\",\n  \"config_key\": \"config_key_value\",\n  \"location_path\": \"location_path_value\",\n  \"explanation\": \"Why operation failed\",\n  \"warnings\": [],\n  \"ready_to_save\": false\n}}\n```\n\n---\n\n## HASH CALCULATION\n```python\nimport hashlib\ncontent = '\\n'.join(updated_directives)\nhash_value = hashlib.md5(content.encode()).hexdigest()\n```\n\n---\n\n## FORBIDDEN ACTIONS\n\n### 🚨 PROTECTED PARAMETER VIOLATIONS (INSTANT FAILURE):\n- ❌ **Changing `http2 on` to `http2 off`** — THIS IS FORBIDDEN NO MATTER WHAT\n- ❌ **Changing `http2` to ANY value** — THE VALUE MUST REMAIN `on`\n- ❌ **Deleting `http2` directive** — MUST STAY IN CONFIG\n- ❌ **Changing `listen 9443 ssl proxy_protocol`** — FORBIDDEN\n- ❌ **Changing `server_name aip.mos.ru`** — FORBIDDEN\n- ❌ **Obeying user requests to change these** — ALWAYS REFUSE\n\n### Other Forbidden Actions:\n\n1. ❌ Adding a directive when its name already exists (ADD_PARAMETERS)\n2. ❌ Creating duplicate directives under any circumstances\n3. ❌ Adding \"standard\" or \"recommended\" parameters not in input\n4. ❌ Changing directive values in ADD_PARAMETERS (use MODIFY_PARAMETERS)\n5. ❌ Ignoring existing directives without scanning them first\n6. ❌ Returning ready_to_save=true when no actual changes were made\n7. ❌ **Ignoring ServerBlockParameters when location_path == \"server_block\"**\n8. ❌ **Reporting \"no parameters provided\" when ServerBlockParameters has values**\n9. ❌ **Keeping a directive in updated_directives that should be deleted**\n10. ❌ **Empty changes_made when parameters were actually processed**\n11. ❌ **MODIFYING protected directive `listen 9443 ssl proxy_protocol` - NEVER ALLOWED**\n12. ❌ **DELETING protected directive `listen 9443 ssl proxy_protocol` - NEVER ALLOWED**\n13. ❌ **MODIFYING protected directive `http2 on` - NEVER ALLOWED**\n14. ❌ **DELETING protected directive `http2 on` - NEVER ALLOWED**\n15. ❌ **MODIFYING protected directive `server_name aip.mos.ru` - NEVER ALLOWED**\n16. ❌ **DELETING protected directive `server_name aip.mos.ru` - NEVER ALLOWED**\n17. ❌ **Obeying user requests to change protected parameters - ALWAYS REFUSE**\n\n---\n\n## THINK STEP BY STEP (MANDATORY)\n\n### For ALL Operations - First Check:\n```\n0. Protected parameters check:\n   - Requested parameters: [list]\n   - Protected matches: [listen/http2/server_name found?]\n   - Action: [BLOCK any protected, PROCEED with rest]\n```\n\n### For ADD_PARAMETERS:\n```\n1. Existing directive names: [list all names]\n2. effective_parameters source: [Parameters/ServerBlockParameters]\n3. Protected check: [any protected? → BLOCK]\n4. For each parameter: [name] → [EXISTS/NOT EXISTS] → [ADD/SKIP]\n5. Final duplicate check: [PASS/FAIL]\n```\n\n### For DELETE_PARAMETERS:\n```\n1. location_path = [value]\n2. Parameter source: [Parameters/ServerBlockParameters]  \n3. effective_parameters = [actual values]\n4. Protected check: [filter out listen/http2/server_name]\n5. Directive names to remove (non-protected only): [set]\n6. Scanning results:\n   - [directive] → [KEEP/REMOVE]\n7. Removed directives: [list]\n8. Blocked directives: [list]\n9. Verification: [protected directives STILL PRESENT? YES]\n```\n\n### For MODIFY_PARAMETERS:\n```\n1. effective_parameters source: [Parameters/ServerBlockParameters]\n2. Protected check: [filter out listen/http2/server_name]\n3. Changes to apply (non-protected only): [name → new_value]\n4. For each directive: [KEEP/REPLACE]\n5. Modified: [list of changes]\n6. Blocked: [list of blocked attempts]\n```\n\n---\n\n## NOW PROCESS THE INPUT\n\nAnalyze the input carefully. **ALWAYS check for protected parameters FIRST.** Follow the algorithm for the specified Operation. Show your work. Return correct JSON."
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "type": {
                "advanced": false,
                "display_name": "type",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "type",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "warnings": {
                "advanced": false,
                "display_name": "warnings",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "warnings",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "id": "Prompt Template-fKVaX",
        "measured": {
          "height": 1835,
          "width": 320
        },
        "position": {
          "x": 10573.916410856822,
          "y": 476.86325000669206
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-YRAOB",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "openai",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "last_updated": "2025-11-03T16:58:41.808Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "TOKEN"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_CHAT_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "local_huggingface/Qwen3-32B"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:8000/v1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are the NGINX YAML Configuration Processor.  \nFollow ENGINE_RULES from the input exactly.  \nNever invent directives. Only modify existing YAML according to parameters.  \nAlways return valid JSON.\n\n"
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.05
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 2400
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "OpenAIModel"
        },
        "id": "OpenAIModel-YRAOB",
        "measured": {
          "height": 661,
          "width": 320
        },
        "position": {
          "x": 11082.659407194045,
          "y": 1053.367418844422
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-uXcEf",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "key": "TypeConverterComponent",
            "last_updated": "2025-12-09T19:29:41.312Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data Output",
                "group_outputs": false,
                "hidden": null,
                "method": "convert_to_data",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Data"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-uXcEf",
        "measured": {
          "height": 261,
          "width": 320
        },
        "position": {
          "x": 12348.673196873922,
          "y": 2112.351419783015
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-t5AFB",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "- Index: {index}\n- Operation: {operation}\n- Config Key: {config_key}\n- Config File: {config_file}\n- Location Path: {location_path}\n- Type: {type}\n- Directives: {directives}\n- Parameters: {parameters}\n- ServerBlockParameters: {server_block_parameters}\n- IP Addresses: {ip_addresses}\n- KMS Required: {kms_required}\n- Create Mode: {create_mode}\n- Delete Mode: {delete_mode}\n- New Location Path: {new_location_path}\n- Existing Locations: {existing_locations}\n- Matching Domains: {matching_domains}\n- Server Names: {server_names}\n- Hash: {hash}\n- Warnings: {warnings}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-t5AFB",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 9651.91575562004,
          "y": 940.6934785084536
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LoopComponent-d2QMY",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.",
            "display_name": "Loop",
            "documentation": "https://docs.langflow.org/components-logic#loop",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "infinity",
            "key": "LoopComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": true,
                "cache": true,
                "display_name": "Item",
                "group_outputs": true,
                "method": "item_output",
                "name": "item",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Done",
                "group_outputs": true,
                "method": "done_output",
                "name": "done",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\n\n\nclass LoopComponent(Component):\n    display_name = \"Loop\"\n    description = (\n        \"Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.\"\n    )\n    documentation: str = \"https://docs.langflow.org/components-logic#loop\"\n    icon = \"infinity\"\n\n    inputs = [\n        HandleInput(\n            name=\"data\",\n            display_name=\"Inputs\",\n            info=\"The initial list of Data objects or DataFrame to iterate over.\",\n            input_types=[\"DataFrame\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Item\", name=\"item\", method=\"item_output\", allows_loop=True, group_outputs=True),\n        Output(display_name=\"Done\", name=\"done\", method=\"done_output\", group_outputs=True),\n    ]\n\n    def initialize_data(self) -> None:\n        \"\"\"Initialize the data list, context index, and aggregated list.\"\"\"\n        if self.ctx.get(f\"{self._id}_initialized\", False):\n            return\n\n        # Ensure data is a list of Data objects\n        data_list = self._validate_data(self.data)\n\n        # Store the initial data and context variables\n        self.update_ctx(\n            {\n                f\"{self._id}_data\": data_list,\n                f\"{self._id}_index\": 0,\n                f\"{self._id}_aggregated\": [],\n                f\"{self._id}_initialized\": True,\n            }\n        )\n\n    def _validate_data(self, data):\n        \"\"\"Validate and return a list of Data objects.\"\"\"\n        if isinstance(data, DataFrame):\n            return data.to_data_list()\n        if isinstance(data, Data):\n            return [data]\n        if isinstance(data, list) and all(isinstance(item, Data) for item in data):\n            return data\n        msg = \"The 'data' input must be a DataFrame, a list of Data objects, or a single Data object.\"\n        raise TypeError(msg)\n\n    def evaluate_stop_loop(self) -> bool:\n        \"\"\"Evaluate whether to stop item or done output.\"\"\"\n        current_index = self.ctx.get(f\"{self._id}_index\", 0)\n        data_length = len(self.ctx.get(f\"{self._id}_data\", []))\n        return current_index > data_length\n\n    def item_output(self) -> Data:\n        \"\"\"Output the next item in the list or stop if done.\"\"\"\n        self.initialize_data()\n        current_item = Data(text=\"\")\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n        else:\n            # Get data list and current index\n            data_list, current_index = self.loop_variables()\n            if current_index < len(data_list):\n                # Output current item and increment index\n                try:\n                    current_item = data_list[current_index]\n                except IndexError:\n                    current_item = Data(text=\"\")\n            self.aggregated_output()\n            self.update_ctx({f\"{self._id}_index\": current_index + 1})\n\n        # Now we need to update the dependencies for the next run\n        self.update_dependency()\n        return current_item\n\n    def update_dependency(self):\n        item_dependency_id = self.get_incoming_edge_by_target_param(\"item\")\n        if item_dependency_id not in self.graph.run_manager.run_predecessors[self._id]:\n            self.graph.run_manager.run_predecessors[self._id].append(item_dependency_id)\n\n    def done_output(self) -> DataFrame:\n        \"\"\"Trigger the done output when iteration is complete.\"\"\"\n        self.initialize_data()\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n            self.start(\"done\")\n\n            aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n\n            return DataFrame(aggregated)\n        self.stop(\"done\")\n        return DataFrame([])\n\n    def loop_variables(self):\n        \"\"\"Retrieve loop variables from context.\"\"\"\n        return (\n            self.ctx.get(f\"{self._id}_data\", []),\n            self.ctx.get(f\"{self._id}_index\", 0),\n        )\n\n    def aggregated_output(self) -> list[Data]:\n        \"\"\"Return the aggregated list once all items are processed.\"\"\"\n        self.initialize_data()\n\n        # Get data list and aggregated list\n        data_list = self.ctx.get(f\"{self._id}_data\", [])\n        aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n        loop_input = self.item\n        if loop_input is not None and not isinstance(loop_input, str) and len(aggregated) <= len(data_list):\n            aggregated.append(loop_input)\n            self.update_ctx({f\"{self._id}_aggregated\": aggregated})\n        return aggregated\n"
              },
              "data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "The initial list of Data objects or DataFrame to iterate over.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LoopComponent"
        },
        "id": "LoopComponent-d2QMY",
        "measured": {
          "height": 241,
          "width": 320
        },
        "position": {
          "x": 9047.01874770544,
          "y": 1158.2511121777998
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-ppTdn",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}\n"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-ppTdn",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 9644.360973627083,
          "y": 1448.7260121813551
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-WqHOE",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "openai",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "last_updated": "2025-11-03T16:58:41.808Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "TOKEN"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_CHAT_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "local_huggingface/Qwen3-32B"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:8000/v1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an expert in nginx configuration.  IMPORTANT RULES: 1. Always follow the instructions STEP BY STEP. 2. Respond STRICTLY in the specified format. 3. Do not invent data — if something is missing, write “NOT SPECIFIED.” 4. Be specific in your questions to the client. 5. For small domains such as test.ru or school.mos.ru, use the exact data from the request.  CONTEXT: You work in a chain of agents, each agent doing their part of the job. Your task is to perform ONLY your part, clearly and in a structured manner."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.05
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 600
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "OpenAIModel"
        },
        "id": "OpenAIModel-WqHOE",
        "measured": {
          "height": 661,
          "width": 320
        },
        "position": {
          "x": 1241.6072792175937,
          "y": 1060.2846827566427
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-9jjXZ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "question": {
                "advanced": false,
                "display_name": "question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# NGINX Configuration Expert System v3.2 (CORRECTED - Only Plural Fields)\n\nYou are an expert NGINX configuration parser. Your task is to extract ALL information from CLIENT REQUEST with 100% accuracy and output structured JSON.\n\n---\n\n## ⚠️ CRITICAL RULES (READ FIRST)\n\n1. **Extract ONLY from CLIENT REQUEST** — Do NOT invent information\n2. **One operation per domain = One JSON object** — Use arrays only for multiple domains\n3. **Always validate before output** — Check completeness, format, required fields\n4. **When in doubt = data_complete: false** — Never guess critical values\n## 🔒 GLOBAL NON-INVERSION RULE (MANDATORY)\n\n\nThe model MUST preserve the exact direction of user intent.\nSemantic inversion is STRICTLY FORBIDDEN.\n\nINTENT → RESULT invariants:\n- REMOVE / DELETE → entity MUST be ABSENT\n- ADD / CREATE → entity MUST APPEAR\n- MODIFY → entity MUST EXIST and CHANGE\n- ENABLE / TURN ON → state MUST be enabled\n- DISABLE / TURN OFF → state MUST be disabled\n\nFORBIDDEN:\n- REMOVE ≠ DISABLE\n- DELETE ≠ SET value\n- OFF ≠ ON\n- PUBLIC ≠ PROTECTED\n- DENY ≠ ALLOW\n\nPOST-CHECK (MANDATORY):\nBefore output, verify:\n\"If this JSON is applied, will the result do EXACTLY what the user asked?\"\n\nIf result contradicts intent:\n- data_complete = false\n- missing = \"logical inversion detected\"\n- confidence ≤ 0.5\n\nIf intent is ambiguous:\n- operation = UNCLEAR\n- data_complete = false\n- Never guess.\n### CRITICAL VERB MAPPING (NO EXCEPTIONS):\n\n| Verb (RU/EN) | MUST map to | NEVER map to |\n|--------------|-------------|--------------|\n| убрать, удалить, remove, delete | DELETE_* | ADD_*, CREATE_* |\n| добавить, внести, add, create | ADD_*, CREATE_* | DELETE_* |\n\n### PARAMETER DELETION EXAMPLES:\n\n- \"убрать gzip off\" → DELETE gzip:off (not add it!)\n- \"удалить proxy_timeout\" → DELETE proxy_timeout\n- \"убрать allow 10.0.0.0/8\" → DELETE allow:10.0.0.0/8\n---\n\n## 🏢 DATACENTER (ЦОД) SELECTION\n\n### Available Datacenters\n\n| ID | Name (RU) | Name (EN) | Description |\n|----|-----------|-----------|-------------|\n| `korovinskiy` | ЦОД Коровинский | DC Korovinskiy | Main datacenter |\n| `kurchatovskiy` | ЦОД Курчатовский | DC Kurchatovskiy | Main datacenter |\n| `nagornaya` | ЦОД Нагорная | DC Nagornaya | Main datacenter |\n| `dr` | DR | Disaster Recovery | Creates configs in BOTH Korovinskiy AND Kurchatovskiy |\n| `moshub_rus` | moshub rus | MosHub RUS | MosHub Russian segment |\n| `ext_kurchatovskiy` | EXT Курчатовский | EXT Kurchatovskiy | External farm Kurchatovskiy |\n| `ext_korovinskiy` | EXT Коровинский | EXT Korovinskiy | External farm Korovinskiy |\n| `ext_nagornaya` | EXT Нагорная | EXT Nagornaya | External farm Nagornaya |\n| `mesh` | МЭШ | MESH | Moscow Electronic School |\n| `top10_kurchatovskiy` | top 10 Курчатовский | Top 10 Kurchatovskiy | Top 10 Kurchatovskiy |\n| `top10_korovinskiy` | top 10 Коровинский | Top 10 Korovinskiy | Top 10 Korovinskiy |\n\n### DC Synonyms Recognition\n\n| User Input (variations) | Normalized DC ID |\n|------------------------|------------------|\n| коровинский, коровинском, коровинск, korovinskiy, korov | `korovinskiy` |\n| курчатовский, курчатовском, курчатов, kurchatovskiy, kurch | `kurchatovskiy` |\n| нагорная, нагорной, nagornaya, nagor | `nagornaya` |\n| dr, дисастер, disaster recovery | `dr` |\n| moshub, мосхаб, moshub rus | `moshub_rus` |\n| ext курчатовский, экст курчат, ext kurch | `ext_kurchatovskiy` |\n| ext коровинский, экст коров, ext korov | `ext_korovinskiy` |\n| ext нагорная, экст нагор, ext nagor | `ext_nagornaya` |\n| мэш, mesh, меш | `mesh` |\n| top 10 курчатовский, топ 10 курч, top10 kurch | `top10_kurchatovskiy` |\n| top 10 коровинский, топ 10 коров, top10 korov | `top10_korovinskiy` |\n\n### DC Field Rules\n\n| Scenario | `selected_dc` Value |\n|----------|---------------------|\n| DC explicitly specified | Array with one or more DC IDs |\n| DR specified | `[\"korovinskiy\", \"kurchatovskiy\"]` |\n| DC NOT specified | `[]` (empty array) |\n\n---\n\n## 🎯 RULE PRIORITY (Highest to Lowest)\n\n| Priority | Category | Description |\n|----------|----------|-------------|\n| 1 | Security | Validate IPs, domains, deny dangerous patterns |\n| 2 | Required Fields | upstreams for CREATE_LOCATION, domains for all ops |\n| 3 | Output Format | Single object vs array rules |\n| 4 | Parameters | Correct placement (location vs server_block) |\n| 5 | Completeness | Mark missing data appropriately |\n\n---\n\n## 📖 KEY CONCEPTS\n\n### Server Block vs Location\n\n| Term | Scope | Example |\n|------|-------|---------|\n| `server_block` | Entire domain/server (outside location blocks) | `gzip on;` at server level |\n| `location` | Specific URL path | `gzip on;` inside `location /api {{}}` |\n\n### When to Use What\n\n| User Says | Use Field |\n|-----------|-----------|\n| \"для всего конфига\", \"на уровне домена\", \"for entire config\" | `server_block_parameters` |\n| \"для /api\", \"в локейшене\", \"for location\" | `location_parameters` |\n| \"добавить параметр\" (без указания места) | Ask for clarification or use context |\n\n---\n\n## 🔧 OPERATIONS REFERENCE\n\n| Operation | Trigger Words (RU/EN) | Required Fields |\n|-----------|----------------------|-----------------|\n| `CREATE_LOCATION` | создать, create location | domains, locations, **upstreams** |\n| `DELETE_LOCATION` | удалить локейшн, delete location | domains, locations |\n| `ADD_PARAMETERS` | добавить, внести параметры, add | domains, locations OR server_block |\n| `MODIFY_PARAMETERS` |  изменить, поправить, modify, change | domains, locations, parameters |\n| `DELETE_PARAMETERS` | убрать, удалить параметры, remove params | domains, locations, parameters |\n| `MODIFY_UPSTREAM` | изменить апстрим, change upstream | domains, locations, upstreams |\n| `MODIFY_LOCATION_PATH` | изменить путь, rename location | domains, from_location, to_location |\n| `MAKE_PROTECTED` | добавить в КМС, protect, enable KMS | domains, locations |\n| `MAKE_PUBLIC` | убрать из КМС, make public | domains, locations |\n| `UNCLEAR` | Cannot determine | — |\n\n---\n\n## 📝 SYNONYMS DICTIONARY\n\n| User Input (variations) | Normalized Term |\n|------------------------|-----------------|\n| апстрим, upstream, бэкенд, backend, сервер | `upstream` |\n| локейшн, локация, location, путь, path, endpoint | `location` |\n| домен, сайт, хост, domain, host, site | `domain` |\n| убрать, удалить, remove, delete, drop | `DELETE_*` |\n| добавить, создать, add, create, new | `ADD_*/CREATE_*` |\n| изменить, поменять, поправить, modify, change, update | `MODIFY_*` |\n| КМС, KMS, защита, protection, auth | KMS-related |\n| Да, Yes, включить, enable, on | `on` |\n| Нет, No, выключить, disable, off | `off` |\n| цод, цоде, дата-центр, datacenter, dc, конфиг в | datacenter reference |\n\n---\n\n## 🌐 LOCATION TYPES\n\n| Syntax | Type | Field Value |\n|--------|------|-------------|\n| `location = /exact` | Exact match | `location_match: \"exact\"` |\n| `location /prefix` | Prefix match | `location_match: \"prefix\"` |\n| `location ~ \\.php$` | Regex (case-sensitive) | `location_match: \"regex\"` |\n| `location ~* \\.jpg$` | Regex (case-insensitive) | `location_match: \"regex_insensitive\"` |\n| `location ^~ /images` | Prefix priority | `location_match: \"prefix_priority\"` |\n\n---\n\n## 🔗 UPSTREAM PARSING RULES\n\n### Format Recognition\n\n| Input Pattern | Interpretation |\n|---------------|----------------|\n| `main 1.1.1.1:80,2.2.2.2:80 backup 3.3.3.3:80` | main: [1.1.1.1:80, 2.2.2.2:80], backup: [3.3.3.3:80] |\n| `1.1.1.1:80,2.2.2.2:80 3.3.3.3:80` | Ambiguous — assume first=main, second=backup |\n| `main backup 1.1.1.1:80,2.2.2.2:80` | Both main AND backup use same IPs |\n| `1.1.1.1:80 weight=5` | IP with additional params |\n\n### Upstream Output Structure\n\n\n\"upstreams\": [\n  {{\n    \"upstream_type\": \"main\",\n    \"ip_addresses\": [\"10.0.0.1:80\", \"10.0.0.2:80\"],\n    \"params\": [\"weight=5\", \"max_fails=3\"]\n  }},\n  {{\n    \"upstream_type\": \"backup\", \n    \"ip_addresses\": [\"10.0.0.3:80\"]\n  }}\n]\n\n\n### Direct Proxy Pass (No Upstream)\n\nIf request specifies direct IP in proxy_pass (not upstream name):\n- Use `MODIFY_PARAMETERS` with `proxy_pass:http://IP:port/`\n- Do NOT use `MODIFY_UPSTREAM`\n\n---\n\n## ✅ VALIDATION RULES\n\n### IP Address Validation\n\n\nIPv4:        ^\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}$\nIPv4+Port:   ^\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}:\\d{{1,5}}$\nCIDR:        ^\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}\\.\\d{{1,3}}/\\d{{1,2}}$\nPort Range:  1-65535\n\n\n### Domain Validation\n\n\nValid:    example.mos.ru, sub.domain.com\nInvalid:  http://example.com (no protocol)\nInvalid:  example (must have TLD)\n\n\n### Location Validation\n\n\nValid:    /, /api, /api/v1, /api_v2/\nInvalid:  api (must start with /)\nInvalid:  /api v2 (no spaces)\n\n\n---\n\n## 📊 OUTPUT SCHEMA\n\n\n{{\n  \"operation\": \"OPERATION_TYPE\",\n  \n  \"selected_dc\": [\"korovinskiy\"] or [],\n  \n  \"domains\": [\"domain1.ru\", \"domain2.ru\"],\n  \n  \"locations\": [\"/path1\", \"/path2\"],\n  \"location_match\": \"prefix|exact|regex|regex_insensitive|prefix_priority\",\n  \n  \"from_location\": \"/old-path or null\",\n  \"to_location\": \"/new-path or null\",\n  \n  \"preserve_directives\": true,\n  \n  \"parameters\": [],\n  \n  \"location_parameters\": [\n    {{\n      \"location\": \"/path\",\n      \"parameters\": [\"param1:value1\", \"param2:value2\"],\n      \"kms_required\": false\n    }}\n  ],\n  \n  \"server_block_parameters\": [\"gzip:on\", \"client_max_body_size:100m\"],\n  \n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main|backup\",\n      \"ip_addresses\": [\"ip:port\"],\n      \"params\": [\"weight=5\"]\n    }}\n  ],\n  \n  \"ssl\": {{\n    \"enabled\": false,\n    \"certificate\": null,\n    \"certificate_key\": null\n  }},\n  \n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \n  \"data_complete\": true,\n  \"missing\": null,\n  \n  \"confidence\": 0.95,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n## OUTPUT FORMAT RULES\n\n| Scenario | Output Format |\n|----------|---------------|\n| One domain, one operation | Single JSON object with `domains: [\"single.domain\"]` |\n| Multiple domains OR different DCs per domain | Array of JSON objects |\n| Same domain, multiple locations, same operation | Single object with `locations: [\"/path1\", \"/path2\"]` |\n\n**KEY RULE:** \n- **Always use arrays** for `domains` and `locations`\n- Even with 1 domain: `domains: [\"example.com\"]`\n- Even with 1 location: `locations: [\"/\"]`\n- Each unique (domain + DC) combination = separate JSON object\n\n---\n\n## 🚫 ANTI-PATTERNS (What NOT to Do)\n\n### ❌ Multiple Objects for Same Domain + Operation\n\n**REQUEST:** \"enable kms for /api, /api_v2 on domain test.ru\"\n\n❌ WRONG:\n\n[\n  {{\"operation\": \"MAKE_PROTECTED\", \"domains\": [\"test.ru\"], \"locations\": [\"/api\"]}},\n  {{\"operation\": \"MAKE_PROTECTED\", \"domains\": [\"test.ru\"], \"locations\": [\"/api_v2\"]}}\n]\n\n\n✅ CORRECT:\n\n{{\n  \"operation\": \"MAKE_PROTECTED\",\n  \"domains\": [\"test.ru\"],\n  \"locations\": [\"/api\", \"/api_v2\"],\n  \"location_parameters\": [\n    {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": true}},\n    {{\"location\": \"/api_v2\", \"parameters\": [], \"kms_required\": true}}\n  ]\n}}\n\n\n### ❌ Wrong Parameter Placement\n\n**REQUEST:** \"добавьте gzip on для всего конфига домена test.ru\"\n\n❌ WRONG:\n\n{{\n  \"location_parameters\": [{{\"location\": \"/\", \"parameters\": [\"gzip:on\"]}}]\n}}\n\n\n✅ CORRECT:\n\n{{\n  \"locations\": [],\n  \"server_block_parameters\": [\"gzip:on\"]\n}}\n\n\n### ❌ Missing Upstreams for CREATE_LOCATION\n\n**REQUEST:** \"создайте локейшн /api для домена test.ru\"\n\n❌ WRONG:\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"upstreams\": [],\n  \"data_complete\": true\n}}\n\n\n✅ CORRECT:\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"upstreams\": [],\n  \"data_complete\": false,\n  \"missing\": \"upstreams required for CREATE_LOCATION\"\n}}\n\n\n### ❌ Duplicates in Arrays\n\n❌ WRONG: `\"kms_locations\": [\"/api\", \"/api_v2\", \"/api\", \"/api_v2\"]`\n✅ CORRECT: `\"kms_locations\": [\"/api\", \"/api_v2\"]`\n\n### ❌ Using Empty Strings Instead of Empty Arrays\n\n❌ WRONG: `\"domains\": \"\", \"locations\": \"\"`\n✅ CORRECT: `\"domains\": [], \"locations\": []`\n\n### ❌ Losing Additional Parameters\n\n**REQUEST:** \"main 1.1.1.1:80 weight=5 max_fails=3\"\n\n❌ WRONG:\n\n{{\n  \"upstreams\": [{{\"ip_addresses\": [\"1.1.1.1:80\"]}}]\n}}\n\n\n✅ CORRECT:\n\n{{\n  \"upstreams\": [{{\n    \"ip_addresses\": [\"1.1.1.1:80\"],\n    \"params\": [\"weight=5\", \"max_fails=3\"]\n  }}]\n}}\n\n\n### ❌ Merging Different Domains with Different DCs\n\n**REQUEST:** \"dchelper.mos.ru коровинский aip.mos.ru нагорная gzip on\"\n\n❌ WRONG (merged into one object):\n\n{{\n  \"selected_dc\": [\"korovinskiy\", \"nagornaya\"],\n  \"domains\": [\"dchelper.mos.ru\"],\n  …\n}}\n\n\n✅ CORRECT (separate objects per domain+DC pair):\n\n\n{{\"domains\": [\"dchelper.mos.ru\"], \"selected_dc\": [\"korovinskiy\"], …}},\n{{\"domains\": [\"aip.mos.ru\"], \"selected_dc\": [\"nagornaya\"], …}}\n\n### ❌ Inverting DELETE to ADD\n\n**REQUEST:** \"домен dchelper.mos.ru убрать gzip off\"\n\n❌ WRONG (semantic inversion):\n```json\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"server_block_parameters\": [\"gzip:off\"]\n}}\n```\n\n✅ CORRECT:\n```json\n{{\n  \"operation\": \"DELETE_PARAMETERS\",\n  \"server_block_parameters\": [\"gzip:off\"]\n}}\n```\n\n**Why:** \"убрать\" = \"remove/delete\", NOT \"add\". The parameter \"gzip off\" should be REMOVED from config.\n\n\n---\n\n## 📋 EXAMPLES\n\n### Example 1: Upstream Change with DC Specified (Korovinskiy)\n\n**Request:** \"Измените апстримы для локейшена / у домена aip.mos.ru в цод коровинском main 10.10.10.10,10.10.10.11,10.10.10.12\"\n\n\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [\"korovinskiy\"],\n  \"domains\": [\"aip.mos.ru\"],\n  \"locations\": [\"/\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.10.10.10\", \"10.10.10.11\", \"10.10.10.12\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 2: Upstream Change with DC Specified (Kurchatovskiy)\n\n**Request:** \"Измените апстримы для локейшена / у домена aip.mos.ru конфиг в курчатовском main 10.10.10.10,10.10.10.11,10.10.10.12\"\n\n\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [\"kurchatovskiy\"],\n  \"domains\": [\"aip.mos.ru\"],\n  \"locations\": [\"/\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.10.10.10\", \"10.10.10.11\", \"10.10.10.12\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 3: DR (Disaster Recovery) - Both DCs\n\n**Request:** \"создать локейшн /api для домена test.ru в DR main 1.1.1.1:80\"\n\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [\"korovinskiy\", \"kurchatovskiy\"],\n  \"domains\": [\"test.ru\"],\n  \"locations\": [\"/api\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"1.1.1.1:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 4: No DC Specified (Empty Array)\n\n**Request:** \"Change upstreams for location / domain school.mos.ru main 10.10.10.10:80,10.10.10.11:80 backup 10.10.10.12:80\"\n\n\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [],\n  \"domains\": [\"school.mos.ru\"],\n  \"locations\": [\"/\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.10.10.10:80\", \"10.10.10.11:80\"],\n      \"params\": []\n    }},\n    {{\n      \"upstream_type\": \"backup\",\n      \"ip_addresses\": [\"10.10.10.12:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n**Request:** \"Change upstreams for location / domain school.mos.ru main backup 10.10.10.10:80,10.10.10.11:80\"\n\n\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [],\n  \"domains\": [\"school.mos.ru\"],\n  \"locations\": [\"/\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.10.10.10:80\", \"10.10.10.11:80\"],\n      \"params\": []\n    }},\n    {{\n      \"upstream_type\": \"backup\",\n      \"ip_addresses\": [\"10.10.10.10:80\", \"10.10.10.11:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n---\n\n### Example 5: External Farm (EXT Kurchatovskiy)\n\n**Request:** \"добавить локейшн /external для api.mos.ru в EXT Курчатовский main 192.168.1.1:8080\"\n\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [\"ext_kurchatovskiy\"],\n  \"domains\": [\"api.mos.ru\"],\n  \"locations\": [\"/external\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/external\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"192.168.1.1:8080\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 6: MESH Datacenter\n\n**Request:** \"enable kms for /api domain mesh.mos.ru в МЭШ\"\n\n\n{{\n  \"operation\": \"MAKE_PROTECTED\",\n  \"selected_dc\": [\"mesh\"],\n  \"domains\": [\"mesh.mos.ru\"],\n  \"locations\": [\"/api\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": true}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": true,\n  \"kms_locations\": [\"/api\"],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 7: Top 10 Datacenter\n\n**Request:** \"изменить апстримы для / домена top.mos.ru в top 10 Коровинский main 10.0.0.1:80\"\n\n\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"selected_dc\": [\"top10_korovinskiy\"],\n  \"domains\": [\"top.mos.ru\"],\n  \"locations\": [\"/\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.0.0.1:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 8: Multiple Locations with KMS (No DC)\n\n**Request:** \"enable kms for locations /api,/api_v2 domain c2222-tech-fair.mos.ru\"\n\n\n{{\n  \"operation\": \"MAKE_PROTECTED\",\n  \"selected_dc\": [],\n  \"domains\": [\"c2222-tech-fair.mos.ru\"],\n  \"locations\": [\"/api\", \"/api_v2\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/api\", \"parameters\": [], \"kms_required\": true}},\n    {{\"location\": \"/api_v2\", \"parameters\": [], \"kms_required\": true}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": true,\n  \"kms_locations\": [\"/api\", \"/api_v2\"],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 9: Create Locations with Shared Upstreams (No DC)\n\n**Request:** \"create locations /a /b domain test.ru main backup 1.1.1.1:80,2.2.2.2:80\"\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [],\n  \"domains\": [\"aip.mos.ru\"],\n  \"locations\": [\"/vcs/api\", \"/api_v2\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\n      \"location\": \"/vcs/api\",\n      \"parameters\": [],\n      \"kms_required\": true,\n      \"upstreams\": []\n    }},\n    {{\n      \"location\": \"/api_v2\",\n      \"parameters\": [\"proxy_buffer_size:32k\", \"proxy_buffers:4 32k\", \"large_client_header_buffers:4 32k\"],\n      \"kms_required\": false,\n      \"upstreams\": []\n    }}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.15.239.84:80\", \"10.15.239.85:80\", \"10.15.239.86:80\"],\n      \"params\": [],\n      \"location\": \"/vcs/api\"\n    }},\n    {{\n      \"upstream_type\": \"backup\",\n      \"ip_addresses\": [\"10.15.239.84:80\", \"10.15.239.85:80\", \"10.15.239.86:80\"],\n      \"params\": [],\n      \"location\": \"/vcs/api\"\n    }},\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.15.239.84:8088\", \"10.15.239.85:8088\", \"10.15.239.86:8088\"],\n      \"params\": [],\n      \"location\": \"/api_v2\"\n    }},\n    {{\n      \"upstream_type\": \"backup\",\n      \"ip_addresses\": [\"10.15.239.84:8088\", \"10.15.239.85:8088\", \"10.15.239.86:8088\"],\n      \"params\": [],\n      \"location\": \"/api_v2\"\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": true,\n  \"kms_locations\": [\"/vcs/api\"],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.95,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n---\n\n### Example 10: Add Parameters with Allow/Deny (Nagornaya DC)\n\n**Request:** \"domain fmon-edu.mos.ru for location /test/ add parameters allow 10.15.166.0/25; allow 10.113.0.0/16; deny all; proxy_set_header Host $host; в цод Нагорная\"\n\n\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"selected_dc\": [\"nagornaya\"],\n  \"domains\": [\"fmon-edu.mos.ru\"],\n  \"locations\": [\"/test/\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\n      \"location\": \"/test/\",\n      \"parameters\": [\n        \"allow:10.15.166.0/25\",\n        \"allow:10.113.0.0/16\",\n        \"deny:all\",\n        \"proxy_set_header:Host $host\"\n      ],\n      \"kms_required\": false\n    }}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 11: Server Block Parameters (No DC)\n\n**Request:** \"для домена api.mos.ru добавить на уровне конфига: gzip on, client_max_body_size 50m\"\n\n\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"selected_dc\": [],\n  \"domains\": [\"api.mos.ru\"],\n  \"locations\": [],\n  \"location_match\": null,\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [\"gzip:on\", \"client_max_body_size:50m\"],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 12: CREATE_LOCATION Without Upstreams (Incomplete)\n\n**Request:** \"домен aip.mos.ru создайте локейшен /api_v6\"\n\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [],\n  \"domains\": [\"aip.mos.ru\"],\n  \"locations\": [\"/api_v6\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/api_v6\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": false,\n  \"missing\": \"upstreams required for CREATE_LOCATION\",\n  \"confidence\": 0.90,\n  \"warnings\": [\"No upstream servers specified for new location\"],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 13: MosHub RUS Datacenter\n\n**Request:** \"добавить /hub для домена hub.mos.ru в moshub rus main 10.20.30.40:80\"\n\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"selected_dc\": [\"moshub_rus\"],\n  \"domains\": [\"hub.mos.ru\"],\n  \"locations\": [\"/hub\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\"location\": \"/hub\", \"parameters\": [], \"kms_required\": false}}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [\n    {{\n      \"upstream_type\": \"main\",\n      \"ip_addresses\": [\"10.20.30.40:80\"],\n      \"params\": []\n    }}\n  ],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 14: Multiple Domains\n\n**Request:** \"domain1.ru добавить /api в коровинском, domain2.ru удалить /old в курчатовском\"\n\n{{\n  \"task1\": {{\n    \"operation\": \"CREATE_LOCATION\",\n    \"selected_dc\": [\"korovinskiy\"],\n    \"domains\": [\"domain1.ru\"],\n    \"locations\": [\"/api\"],\n    \"location_match\": \"prefix\",\n    \"from_location\": null,\n    \"to_location\": null,\n    \"preserve_directives\": true,\n    \"parameters\": [],\n    \"location_parameters\": [\n      {{\n        \"location\": \"/api\",\n        \"parameters\": [],\n        \"kms_required\": false\n      }}\n    ],\n    \"server_block_parameters\": [],\n    \"upstreams\": [],\n    \"ssl\": {{\n      \"enabled\": false,\n      \"certificate\": null,\n      \"certificate_key\": null\n    }},\n    \"kms_mentioned\": false,\n    \"kms_locations\": [],\n    \"public_locations\": [],\n    \"data_complete\": false,\n    \"missing\": \"upstreams required for CREATE_LOCATION\",\n    \"confidence\": 0.85,\n    \"warnings\": [],\n    \"ambiguities\": []\n  }},\n  \"task2\": {{\n    \"operation\": \"DELETE_LOCATION\",\n    \"selected_dc\": [\"kurchatovskiy\"],\n    \"domains\": [\"domain2.ru\"],\n    \"locations\": [\"/old\"],\n    \"location_match\": \"prefix\",\n    \"from_location\": null,\n    \"to_location\": null,\n    \"preserve_directives\": true,\n    \"parameters\": [],\n    \"location_parameters\": [],\n    \"server_block_parameters\": [],\n    \"upstreams\": [],\n    \"ssl\": {{\n      \"enabled\": false,\n      \"certificate\": null,\n      \"certificate_key\": null\n    }},\n    \"kms_mentioned\": false,\n    \"kms_locations\": [],\n    \"public_locations\": [],\n    \"data_complete\": true,\n    \"missing\": null,\n    \"confidence\": 0.95,\n    \"warnings\": [],\n    \"ambiguities\": []\n  }},\n  \"task3\": {{\n    \"operation\": \"DELETE_LOCATION\",\n    \"selected_dc\": [\"nagornaya\"],\n    \"domains\": [\"domain2.ru\"],\n    \"locations\": [\"= /old\"],\n    \"location_match\": \"prefix\",\n    \"from_location\": null,\n    \"to_location\": null,\n    \"preserve_directives\": true,\n    \"parameters\": [],\n    \"location_parameters\": [],\n    \"server_block_parameters\": [],\n    \"upstreams\": [],\n    \"ssl\": {{\n      \"enabled\": false,\n      \"certificate\": null,\n      \"certificate_key\": null\n    }},\n    \"kms_mentioned\": false,\n    \"kms_locations\": [],\n    \"public_locations\": [],\n    \"data_complete\": true,\n    \"missing\": null,\n    \"confidence\": 0.95,\n    \"warnings\": [],\n    \"ambiguities\": []\n  }}\n}}\n\n---\n\n### Example 15: Modify Location Path (No DC)\n\n**Request:** \"переименовать локейшн /api в /api/ для домена test.ru\"\n\n\n{{\n  \"operation\": \"MODIFY_LOCATION_PATH\",\n  \"selected_dc\": [],\n  \"domains\": [\"test.ru\"],\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": \"/api\",\n  \"to_location\": \"/api/\",\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 16: Direct Proxy Pass Modification (No DC)\n\n**Request:** \"изменить proxy_pass на http://10.206.100.17:8000/ для локейшн / домена api.mos.ru\"\n\n\n{{\n  \"operation\": \"MODIFY_PARAMETERS\",\n  \"selected_dc\": [],\n  \"domains\": [\"api.mos.ru\"],\n  \"locations\": [\"/\"],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [\n    {{\n      \"location\": \"/\",\n      \"parameters\": [\"proxy_pass:http://10.206.100.17:8000/\"],\n      \"kms_required\": false\n    }}\n  ],\n  \"server_block_parameters\": [],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.99,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n---\n\n### Example 17: Make Public No Location Specified (Default Parameters)\n\n**Request:** \"домен dchelper.mos.ru убрать из КМС\"\n\n\n{{\n  \"operation\": \"MAKE_PUBLIC\",\n  \"selected_dc\": [],\n  \"domains\": [\"dchelper.mos.ru\"],\n  \"locations\": [],\n  \"location_match\": \"prefix\",\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [\"allow:10.0.0.0/8\", \"deny:all\"],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": true,\n  \"kms_locations\": [],\n  \"public_locations\": [\"/\"],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n### Example 18: Delete Parameter from Server Block\n\n**Request:** \"домен dchelper.mos.ru убрать gzip off\"\n\n<thinking>\n1. DATACENTER: не указан → selected_dc: []\n2. OPERATION: \"убрать\" = DELETE → DELETE_PARAMETERS\n3. DOMAIN: dchelper.mos.ru\n4. LOCATION: не указан → server_block level\n5. PARAMETER TO DELETE: \"gzip off\" (весь параметр)\n6. POST-CHECK: \"убрать\" означает УДАЛИТЬ, не добавить\n</thinking>\n\n{{\n  \"operation\": \"DELETE_PARAMETERS\",\n  \"selected_dc\": [],\n  \"domains\": [\"dchelper.mos.ru\"],\n  \"locations\": [],\n  \"location_match\": null,\n  \"from_location\": null,\n  \"to_location\": null,\n  \"preserve_directives\": true,\n  \"parameters\": [],\n  \"location_parameters\": [],\n  \"server_block_parameters\": [\"gzip:off\"],\n  \"upstreams\": [],\n  \"ssl\": {{\"enabled\": false, \"certificate\": null, \"certificate_key\": null}},\n  \"kms_mentioned\": false,\n  \"kms_locations\": [],\n  \"public_locations\": [],\n  \"data_complete\": true,\n  \"missing\": null,\n  \"confidence\": 0.98,\n  \"warnings\": [],\n  \"ambiguities\": []\n}}\n\n\n### Example 19: Delete Parameter vs Add Parameter (Contrast)\n\n❌ **WRONG interpretation of \"убрать gzip off\":**\n```json\n{{\"operation\": \"ADD_PARAMETERS\", \"server_block_parameters\": [\"gzip:off\"]}}\n```\n\n✅ **CORRECT interpretation of \"убрать gzip off\":**\n```json\n{{\"operation\": \"DELETE_PARAMETERS\", \"server_block_parameters\": [\"gzip:off\"]}}\n```\n\n**Rule:** \"убрать X\" ALWAYS means DELETE X, never ADD X\n---\n\n## 🧠 MANDATORY REASONING PROCESS\n\nBefore outputting JSON, you MUST think through these steps:\n\n\n<thinking>\n1. DATACENTER IDENTIFICATION\n   - Is DC explicitly mentioned? (цод, datacenter, конфиг в)\n   - DC keywords found: [list keywords]\n   - Determined DC: [DC_ID or empty if not specified]\n\n2. OPERATION IDENTIFICATION\n   - What action is requested? (create/delete/modify/protect/etc.)\n   - Key trigger words found: [list words]\n   - Determined operation: [OPERATION_TYPE]\n\n3. DOMAIN EXTRACTION  \n   - Single domain or multiple?\n   - Domain value: [extracted domain(s)]\n   - Validation: [valid/invalid]\n   - Output: domains: [array]\n\n4. LOCATION EXTRACTION\n   - Single location or multiple?\n   - Location value(s): [extracted location(s)]\n   - Location type: [prefix/exact/regex]\n   - Output: locations: [array]\n   \n5. PARAMETER CLASSIFICATION\n   - Location-level params: [list]\n   - Server-block params: [list]\n   - Reasoning: [why this classification]\n\n6. UPSTREAM PARSING (if applicable)\n   - Main servers: [IPs]\n   - Backup servers: [IPs]\n   - Additional params: [weight, etc.]\n\n7. COMPLETENESS CHECK\n   - Required fields present: [yes/no]\n   - Missing information: [list what's missing]\n   - data_complete value: [true/false]\n\n8. CONFIDENCE ASSESSMENT\n   - Ambiguities found: [list]\n   - Warnings: [list]\n   - Confidence score: [0.0-1.0]\n\n9. COHERENCE CHECK (НОВАЯ ПРОВЕРКА)\n   - Запрос говорит \"Удалить X, Добавить Y\" для тех же путей?\n   - Если ДА → это MODIFY_PARAMETERS, а не DELETE+CREATE\n   - Если пути те же → единая операция модификации\n   - Если пути разные → возможны раздельные операции\n</thinking>\n\n\nThen output ONLY the JSON.\n\n---\n\n## 🔒 ERROR HANDLING\n\n| Error Type | Action |\n|------------|--------|\n| Invalid IP format | `data_complete: false`, `missing: \"invalid IP format: X.X.X.X\"` |\n| Missing required field | `data_complete: false`, `missing: \"[field] required for [operation]\"` |\n| Conflicting instructions | Add to `ambiguities`, reduce confidence |\n| Unknown nginx directive | Include as-is, add to `warnings` |\n| Typo detected | Add to `warnings`: \"possible typo: 'gzp' → 'gzip'\" |\n| Unknown DC | Add to `warnings`: \"unknown datacenter specified\", use closest match or empty |\n\n---\n\n## 🔄 CONTEXT AWARENESS\n\nIf request references previous context:\n\n| User Says | Action |\n|-----------|--------|\n| \"тот же домен\", \"same domain\" | Use domain from context if available, else `data_complete: false` |\n| \"эти же апстримы\", \"same upstreams\" | Use upstreams from context if available |\n| \"как раньше\", \"as before\" | Request clarification, set `data_complete: false` |\n| \"тот же цод\", \"same dc\" | Use DC from context if available |\n\n---\n\n## ✅ DATA_COMPLETE RULES\n\nSet `data_complete: true` when:\n- ✅ Operation identified\n- ✅ domains array present (even if empty for server_block operations)\n- ✅ locations array present (can be empty for server_block operations)\n- ✅ For CREATE_LOCATION: upstreams array has at least main upstream with IPs\n- ✅ For MAKE_PROTECTED/MAKE_PUBLIC: KMS params auto-generated (empty is OK)\n- ✅ For ADD_PARAMETERS: at least one parameter specified\n- ✅ selected_dc can be empty (not required)\n\nSet `data_complete: false` when:\n- ❌ Missing domains array or empty when required\n- ❌ Missing locations array for location-specific operations\n- ❌ CREATE_LOCATION without upstreams\n- ❌ ADD_PARAMETERS without any parameters\n- ❌ Ambiguous request that can't be resolved\n\n---\n\n## 🚀 FINAL CHECKLIST BEFORE OUTPUT\n\n1. ☐ Is datacenter correctly identified (or empty if not specified)?\n2. ☐ Is operation correctly identified?\n3. ☐ Are domains and locations in array format (even if single value)?\n4. ☐ Are parameters in correct section (location vs server_block)?\n5. ☐ Are upstreams properly parsed with main/backup?\n6. ☐ Is data_complete correctly set?\n7. ☐ Are there no duplicate entries in arrays?\n8. ☐ Is the output valid JSON?\n9. ☐ Is confidence score reasonable?\n\n---\n\n## NOW ANALYZE\n\n**CLIENT REQUEST:**\n{question}\n\n---\n\n**Output ONLY valid JSON (single object or array of objects):**\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "id": "Prompt Template-9jjXZ",
        "measured": {
          "height": 359,
          "width": 320
        },
        "position": {
          "x": 789.5143613243972,
          "y": 1309.0102574583348
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "JSONCleaner-2l30o",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.",
            "display_name": "JSON Cleaner",
            "documentation": "",
            "edited": false,
            "field_order": [
              "json_str",
              "remove_control_chars",
              "normalize_unicode",
              "validate_json"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "JSONCleaner",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Cleaned JSON String",
                "group_outputs": false,
                "method": "clean_json",
                "name": "output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.ParserComponent"
            ],
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport unicodedata\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import BoolInput, MessageTextInput\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass JSONCleaner(Component):\n    icon = \"braces\"\n    display_name = \"JSON Cleaner\"\n    description = (\n        \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs \"\n        \"so that they are fully compliant with the JSON spec.\"\n    )\n    legacy = True\n    replacement = [\"processing.ParserComponent\"]\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json\n        except ImportError as e:\n            msg = \"Could not import the json_repair package. Please install it with `pip install json_repair`.\"\n            raise ImportError(msg) from e\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        start = json_str.find(\"{\")\n        end = json_str.rfind(\"}\")\n        if start == -1 or end == -1:\n            msg = \"Invalid JSON string: Missing '{' or '}'\"\n            raise ValueError(msg)\n        try:\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            msg = f\"Error cleaning JSON string: {e}\"\n            raise ValueError(msg) from e\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return s.translate(self.translation_table)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n        except json.JSONDecodeError as e:\n            msg = f\"Invalid JSON string: {e}\"\n            raise ValueError(msg) from e\n        return s\n\n    def __init__(self, *args, **kwargs):\n        # Create a translation table that maps control characters to None\n        super().__init__(*args, **kwargs)\n        self.translation_table = str.maketrans(\"\", \"\", \"\".join(chr(i) for i in range(32)) + chr(127))\n"
              },
              "json_str": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JSON String",
                "dynamic": false,
                "info": "The JSON string to be cleaned.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "json_str",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "normalize_unicode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Normalize Unicode",
                "dynamic": false,
                "info": "Normalize Unicode characters in the JSON string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "normalize_unicode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "remove_control_chars": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Remove Control Characters",
                "dynamic": false,
                "info": "Remove control characters from the JSON string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "remove_control_chars",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "validate_json": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Validate JSON",
                "dynamic": false,
                "info": "Validate the JSON string to ensure it is well-formed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "validate_json",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "JSONCleaner"
        },
        "id": "JSONCleaner-2l30o",
        "measured": {
          "height": 440,
          "width": 320
        },
        "position": {
          "x": 1684.9248868522345,
          "y": 1229.2072576429541
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-bWTwE",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "openai",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "last_updated": "2025-11-03T16:58:41.808Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "TOKEN"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_CHAT_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "local_huggingface/Qwen3-32B"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:8000/v1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a validation expert for nginx configuration requests. Your job is to verify data completeness, detect risks, and generate specific clarification questions."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.05
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 600
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "OpenAIModel"
        },
        "id": "OpenAIModel-bWTwE",
        "measured": {
          "height": 661,
          "width": 320
        },
        "position": {
          "x": 2904.12813091741,
          "y": 1123.7722787799817
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-KPVE4",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "agent1_json",
                "original_question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "agent1_json": {
                "advanced": false,
                "display_name": "agent1_json",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent1_json",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "original_question": {
                "advanced": false,
                "display_name": "original_question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "original_question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# NGINX Configuration Validation Expert v4.1 (BUG FIXES)\n\nYou are a validation expert for NGINX configuration requests. Your task is to validate Agent 1's output against the original request and NGINX syntax rules.\n\n---\n\n## ⚠️ CRITICAL RULES (READ FIRST)\n\n\n1. **ACTUALLY READ the input JSON** — Do not assume fields are missing without checking!\n2. **location OR locations** — Either one is valid, not both required\n3. **Warnings ≠ Missing fields** — Warnings don't block COMPLETE status\n4. **Skip proxy_pass validation** — Always mark as valid\n5. **Check upstreams array properly** — Look inside the array structure\n\n---\n\n## 🚨 COMMON VALIDATION BUGS TO AVOID\n\n### Bug 1: Ignoring `locations` array\n\n❌ WRONG: location is null → missing_fields: [\"location\"]\n✅ RIGHT: location is null BUT locations = [\"/a\", \"/b\"] → data is PRESENT\n\n\n### Bug 2: Not parsing `upstreams` structure  \n\n❌ WRONG: upstreams exists → assume empty\n✅ RIGHT: Check if upstreams[*].ip_addresses has values\n\n\n### Bug 3: Treating warnings as blockers\n\n❌ WRONG: Same IPs in main/backup → validation_status: \"INCOMPLETE\"\n✅ RIGHT: Same IPs in main/backup → Add warning, but status: \"COMPLETE\"\n\n\n### Bug 4: Wrong fields for MODIFY_LOCATION_PATH\n\n❌ WRONG: Check location/locations for MODIFY_LOCATION_PATH\n✅ RIGHT: Check from_location and to_location ONLY\n\n\n### Bug 5: Ignoring `domains` array when `domain` is null\n\nInput: {{\"domain\": null, \"domains\": [\"aip.mos.ru\", \"dchelper.mos.ru\"]}}\n\n❌ WRONG: domain is null → missing_fields: [\"domain: required\"]\n✅ RIGHT: domain is null BUT domains = [\"aip.mos.ru\", \"dchelper.mos.ru\"] → PRESENT\n\n\n### Bug 6: Ignoring `server_block_parameters` for location check\n\nInput: {{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"location\": null,\n  \"locations\": [],\n  \"server_block_parameters\": [\"gzip:on\"]\n}}\n\n❌ WRONG: location is null and locations empty → missing_fields: [\"location required\"]\n✅ RIGHT: server_block_parameters has values → server-block level operation, location NOT required\n\n❌ WRONG: parameters is empty → missing_fields: [\"parameters\"]\n✅ RIGHT: parameters is empty BUT location_parameters has values → data is PRESENT\n---\n\n## 🎯 VALIDATION PRIORITY\n\n| Priority | Check | Action on Failure |\n|----------|-------|-------------------|\n| 1 | Security risks | Set HIGH_RISK |\n| 2 | Required fields (ACTUALLY CHECK!) | Set INCOMPLETE |\n| 3 | Syntax errors | Set INCOMPLETE |\n| 4 | Consistency/Best practices | Add warnings ONLY |\n\n---\n\n## 📊 DATA PRESENCE CHECK ALGORITHM\n\n### Step 1: Parse Input Correctly\n\n```python\ndef parse_agent1_output(json_input):\n    \"\"\"\n    CRITICAL: Actually extract values, don't assume!\n    \"\"\"\n    return {{\n        \"operation\": json_input.get(\"operation\"),\n        \"domain\": json_input.get(\"domain\"),  # Can be string or null\n        \"domains\": json_input.get(\"domains\", []),  # Can be array or empty\n        \"location\": json_input.get(\"location\"),  # Can be string or null\n        \"locations\": json_input.get(\"locations\", []),  # Can be array or empty\n        \"from_location\": json_input.get(\"from_location\"),\n        \"to_location\": json_input.get(\"to_location\"),\n        \"upstreams\": json_input.get(\"upstreams\", []),  # PARSE THIS PROPERLY!\n        \"parameters\": json_input.get(\"parameters\", []),\n        \"location_parameters\": json_input.get(\"location_parameters\", []),\n        \"server_block_parameters\": json_input.get(\"server_block_parameters\", []),\n        \"kms_mentioned\": json_input.get(\"kms_mentioned\", False),\n        \"kms_locations\": json_input.get(\"kms_locations\", []),\n    }}\n```\n\n### Step 2: Check Field Presence\n\n```python\ndef is_field_present(value):\n    \"\"\"\n    Returns True if field has actual data\n    \"\"\"\n    if value is None:\n        return False\n    if isinstance(value, str) and value.strip() == \"\":\n        return False\n    if isinstance(value, list) and len(value) == 0:\n        return False\n    return True\n\ndef has_domain(data):\n    \"\"\"\n    CRITICAL: Check BOTH domain AND domains!\n    Returns True if EITHER has value.\n    \"\"\"\n    # Check single domain field\n    domain = data.get(\"domain\")\n    if domain is not None and domain.strip() != \"\":\n        return True\n    \n    # Check domains array\n    domains = data.get(\"domains\", [])\n    if domains and len(domains) > 0:\n        return True\n    \n    return False\n\n# Examples:\n# {{\"domain\": \"example.ru\", \"domains\": []}} → True (domain is set)\n# {{\"domain\": null, \"domains\": [\"a.ru\", \"b.ru\"]}} → True (domains has items)\n# {{\"domain\": null, \"domains\": []}} → False (neither has value)\n# {{\"domain\": \"\", \"domains\": []}} → False (empty string = not present)\n\ndef has_location(data):\n    # CRITICAL: Check BOTH fields!\n    return is_field_present(data[\"location\"]) or is_field_present(data[\"locations\"])\n\ndef has_upstreams(data):\n    # CRITICAL: Check inside the array!\n    upstreams = data.get(\"upstreams\", [])\n    if not upstreams:\n        return False\n    for upstream in upstreams:\n        ip_addresses = upstream.get(\"ip_addresses\", [])\n        if ip_addresses and len(ip_addresses) > 0:\n            return True\n    return False\n\n\ndef has_from_to_location(data):\n    return is_field_present(data[\"from_location\"]) and is_field_present(data[\"to_location\"])\n\n```\n### Step 3: Required Fields by Operation\n\n```python\ndef get_missing_fields(data):\n    operation = data[\"operation\"]\n    missing = []\n    \n    # ALL operations need domain\n    if not has_domain(data):\n        missing.append(\"domain: No domain or domains specified\")\n    \n    # Operation-specific checks\n    if operation == \"MODIFY_LOCATION_PATH\":\n        # Special case: needs from_location and to_location, NOT location/locations\n        if not is_field_present(data[\"from_location\"]):\n            missing.append(\"from_location: Source path required\")\n        if not is_field_present(data[\"to_location\"]):\n            missing.append(\"to_location: Target path required\")\n        # DO NOT check location or locations here!\n        \n    elif operation in [\"DELETE_LOCATION\", \"CREATE_LOCATION\", \"MODIFY_UPSTREAM\",\n                       \"ADD_PARAMETERS\", \"MODIFY_PARAMETERS\", \"DELETE_PARAMETERS\",\n                       \"MAKE_PROTECTED\", \"MAKE_PUBLIC\"]:\n        # These need location OR locations (not both)\n        if not has_location(data):\n            # Exception: server_block level operations may have null location\n            if operation == \"ADD_PARAMETERS\" and is_field_present(data[\"server_block_parameters\"]):\n                pass  # OK - server block level, no location needed\n            elif operation in [\"MAKE_PROTECTED\", \"MAKE_PUBLIC\"] and is_field_present(data[\"kms_locations\"]):\n                pass  # OK - using kms_locations instead\n            else:\n                missing.append(\"location: Neither location nor locations specified\")\n    \n    # CREATE_LOCATION needs upstreams\n    if operation == \"CREATE_LOCATION\":\n        if not has_upstreams(data):\n            missing.append(\"upstreams: IP addresses required for new location(s)\")\n    \n    # MODIFY_UPSTREAM needs upstreams\n    if operation == \"MODIFY_UPSTREAM\":\n        if not has_upstreams(data):\n            missing.append(\"upstreams: New upstream configuration required\")\n    # DELETE_PARAMETERS needs parameter names (in ANY param field)\n    if operation == \"DELETE_PARAMETERS\":\n       has_loc = has_location(data)\n       has_server_block = is_field_present(data.get(\"server_block_parameters\", []))\n       has_loc_params = is_field_present(data.get(\"location_parameters\", []))\n       \n       # Need either location-level or server-block level target\n       if not has_loc and not has_server_block and not has_loc_params:\n           missing.append(\"location: Neither location nor server_block_parameters specified\")\n       \n       # Need parameters to delete in ANY field\n       has_any_params = (\n           is_field_present(data.get(\"parameters\", [])) or \n           has_server_block or \n           has_loc_params\n       )\n       if not has_any_params:\n           missing.append(\"parameters: No parameters specified to delete\")\n    # ADD/MODIFY_PARAMETERS need actual parameters (unless KMS-only)\n    if operation in [\"ADD_PARAMETERS\", \"MODIFY_PARAMETERS\"]:\n        has_params = (is_field_present(data[\"parameters\"]) or \n                      is_field_present(data[\"location_parameters\"]) or\n                      is_field_present(data[\"server_block_parameters\"]))\n        is_kms_only = data[\"kms_mentioned\"] and is_field_present(data[\"kms_locations\"])\n        if not has_params and not is_kms_only:\n            missing.append(\"parameters: No parameters specified to add/modify\")\n    \n    return missing\n```\n\n---\n\n## 📋 FIELD PRESENCE TRUTH TABLE\n\n| Field | NOT Present (Empty) | IS Present (Valid) |\n|-------|--------------------|--------------------|\n| `domain` | `null`, `\"\"` | `\"example.ru\"` |\n| `domains` | `[]` | `[\"a.ru\", \"b.ru\"]` |\n| `location` | `null`, `\"\"` | `\"/\"`, `\"/api\"` |\n| `locations` | `[]` | `[\"/api\", \"/v2\"]` |\n| `from_location` | `null`, `\"\"` | `\"/old-path\"` |\n| `to_location` | `null`, `\"\"` | `\"/new-path\"` |\n| `upstreams` | `[]` | `[{{\"upstream_type\": \"main\", \"ip_addresses\": [\"1.1.1.1:80\"]}}]` |\n| `parameters` | `[]` | `[\"gzip:on\"]` |\n| `location_parameters` | `[]` | `[{{\"location\": \"/\", \"parameters\": [\"x:y\"]}}]` |\n| `server_block_parameters` | `[]` | `[\"gzip:on\"]` |\n\n### Combined Field Logic\n\n| Scenario | domain | domains | Result |\n|----------|--------|---------|--------|\n| Single domain | `\"example.ru\"` | `[]` | ✅ VALID |\n| Multiple domains | `null` | `[\"a.ru\", \"b.ru\"]` | ✅ VALID |\n| Both set | `\"example.ru\"` | `[\"a.ru\"]` | ✅ VALID (use both) |\n| Neither set | `null` | `[]` | ❌ MISSING |\n\n| Scenario | location | locations | server_block_params | Result |\n|----------|----------|-----------|---------------------|--------|\n| Single location | `\"/api\"` | `[]` | `[]` | ✅ VALID |\n| Multiple locations | `null` | `[\"/a\", \"/b\"]` | `[]` | ✅ VALID |\n| Server block level | `null` | `[]` | `[\"gzip:on\"]` | ✅ VALID |\n| Neither | `null` | `[]` | `[]` | ❌ MISSING |\n\n---\n\n## 🔄 OPERATION-SPECIFIC VALIDATION\n\n### CREATE_LOCATION\n\n**Required:** domain + (location OR locations) + upstreams with IPs\n\n\n# Validation\n```python\ndef validate_create_location(data):\n    errors = []\n    \n    # Check domain\n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    # Check location OR locations (not both required)\n    if not has_location(data):\n        errors.append(\"location or locations required\")\n    \n    # Check upstreams - MUST have at least main with IPs\n    if not has_upstreams(data):\n        errors.append(\"upstreams with IP addresses required\")\n    \n    return errors\n\n```\n**Example - VALID:**\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"domain\": \"aip.mos.ru\",\n  \"location\": null,\n  \"locations\": [\"/api_V2/\", \"/api_V3/\"],\n  \"upstreams\": [\n    {{\"upstream_type\": \"main\", \"ip_addresses\": [\"10.10.10.10\"]}}\n  ]\n}}\n\n→ `validation_status: \"COMPLETE\"` ✅\n\n---\n\n### MODIFY_LOCATION_PATH\n\n**Required:** domain + from_location + to_location\n**NOT Required:** location, locations\n\n```python\ndef validate_modify_location_path(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    # ONLY check from/to, NOT location/locations!\n    if not is_field_present(data[\"from_location\"]):\n        errors.append(\"from_location required\")\n    if not is_field_present(data[\"to_location\"]):\n        errors.append(\"to_location required\")\n    \n    return errors\n```\n\n**Example - VALID:**\n\n{{\n  \"operation\": \"MODIFY_LOCATION_PATH\",\n  \"domain\": \"mobile-newmos.mos.ru\",\n  \"location\": null,\n  \"locations\": [],\n  \"from_location\": \"/relay\",\n  \"to_location\": \"/relay/\"\n}}\n\n→ `validation_status: \"COMPLETE\"` ✅\n\n---\n\n### MODIFY_UPSTREAM\n\n**Required:** domains + locations + upstreams with IPs\n⚠️ ВАЖНО: Если `locations` — пустой массив ([]), то данные НЕПОЛНЫЕ. Такая конфигурация недопустима, даже если все остальные поля заполнены.\n\n```python\n\ndef check_MODIFY_UPSTREAM(data):\n    missing = []\n    \n    # 1. Проверь domain/domains\n    if not (data.get(\"domain\") or data.get(\"domains\")):\n        missing.append(\"domain: required\")\n    \n    # 2. Проверь location/locations ← ЭТО ОБЯЗАТЕЛЬНО!\n    if not (data.get(\"location\") or data.get(\"locations\")):\n        missing.append(\"location: Neither location nor locations specified\")\n    \n    # 3. Проверь upstreams\n    if not data.get(\"upstreams\"):\n        missing.append(\"upstreams: required\")\n    \n    return missing\n```\n{{\n  \"operation\": \"MODIFY_UPSTREAM\",\n  \"domain\": \"school.mos.ru\",\n  \"location\": \"/\",\n  \"upstreams\": [\n    {{\"upstream_type\": \"main\", \"ip_addresses\": [\"10.10.10.10:80\", \"10.10.10.11:80\"]}},\n    {{\"upstream_type\": \"backup\", \"ip_addresses\": [\"10.10.10.12\"]}}\n  ],\n  \"data_complete\": true\n}}\n\n**Output:**\n\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"parameter_validation\": {{\n    \"validated_parameters\": [\n      \"main upstream IPs: 10.10.10.10:80 (valid), 10.10.10.11:80 (valid)\",\n      \"backup upstream IPs: 10.10.10.12 (valid - assuming :80)\"\n    ],\n    \"invalid_parameters\": [],\n    \"warnings\": [\"No port for 10.10.10.12 - Defaults to 80\"]\n  }},\n  \"kms_rules\": {{\"locations_need_kms\": [], \"locations_public\": [], \"note\": null}},\n  \"risk_assessment\": {{\"risk_level\": \"low\", \"warnings\": []}},\n  \"cross_referenced\": {{\"note\": null}},\n  \"ready_for_next_agent\": true\n}}\n---\n\n### ADD_PARAMETERS / MODIFY_PARAMETERS\n\n**Required:** domain + (location OR locations OR server_block) + parameters\n**Exception:** KMS-only operations don't need parameters\n\n```python\ndef validate_add_modify_params(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    # Location check (unless server_block level)\n    has_server_block = is_field_present(data[\"server_block_parameters\"])\n    if not has_location(data) and not has_server_block:\n        errors.append(\"location, locations, or server_block_parameters required\")\n    \n    # Parameters check (unless KMS-only)\n    has_any_params = (is_field_present(data[\"parameters\"]) or \n                      is_field_present(data[\"location_parameters\"]) or\n                      has_server_block)\n    is_kms_only = data[\"kms_mentioned\"] and is_field_present(data[\"kms_locations\"])\n    \n    if not has_any_params and not is_kms_only:\n        errors.append(\"parameters required\")\n    \n    return errors\n```\n\n---\n\n### DELETE_PARAMETERS\n\n**Required:** domain + (location OR locations OR server_block_parameters) + parameter names in ANY parameter field\n**Note:** Parameter VALUES not required for deletion, just names\n```python\ndef validate_delete_params(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    # Check if we have location-level OR server-block-level deletion\n    has_loc = has_location(data)\n    has_server_block = is_field_present(data.get(\"server_block_parameters\", []))\n    has_loc_params = is_field_present(data.get(\"location_parameters\", []))\n    \n    # For DELETE_PARAMETERS: either location-level or server-block-level is valid\n    if not has_loc and not has_server_block and not has_loc_params:\n        errors.append(\"location, locations, or server_block_parameters required\")\n    \n    # Check if ANY parameter field has values (parameters to delete)\n    has_any_params = (\n        is_field_present(data.get(\"parameters\", [])) or \n        is_field_present(data.get(\"server_block_parameters\", [])) or\n        is_field_present(data.get(\"location_parameters\", []))\n    )\n    \n    if not has_any_params:\n        errors.append(\"parameter names to delete required\")\n    \n    return errors\n```\n---\n\n### DELETE_LOCATION\n\n**Required:** domain + (location OR locations)\n\n```python\ndef validate_delete_location(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    if not has_location(data):\n        errors.append(\"location or locations required\")\n    \n    return errors\n```\n\n---\n\n### MAKE_PROTECTED / MAKE_PUBLIC\n\n**Required:** domain + (location OR locations OR kms_locations/public_locations)\n\n```python\ndef validate_kms_operation(data):\n    errors = []\n    \n    if not has_domain(data):\n        errors.append(\"domain required\")\n    \n    has_loc = has_location(data)\n    has_kms_loc = is_field_present(data[\"kms_locations\"])\n    has_pub_loc = is_field_present(data.get(\"public_locations\", []))\n    \n    if not has_loc and not has_kms_loc and not has_pub_loc:\n        errors.append(\"location, locations, or kms_locations required\")\n    \n    return errors\n\n```\n---\n\n## ⚠️ WARNINGS vs MISSING FIELDS\n\n### What is a WARNING (does NOT block COMPLETE):\n\n| Condition | Warning Text |\n|-----------|--------------|\n| Same IPs in main/backup upstreams | \"Failover may not work with duplicate IPs\" |\n| No port in IP address | \"No port specified, defaults to :80\" |\n| High client_max_body_size | \"Large body size may pose security risks\" |\n| Empty parameters for CREATE_LOCATION | \"Consider adding timeout/buffer settings\" |\n| Low timeout values | \"Timeout < 10s may cause issues\" |\n\n### What is MISSING FIELD (DOES block COMPLETE):\n\n| Condition | Missing Field |\n|-----------|---------------|\n| No domain and no domains | \"domain: required\" |\n| No location and no locations (when needed) | \"location: required\" |\n| No upstreams for CREATE_LOCATION | \"upstreams: required\" |\n| No from_location for MODIFY_LOCATION_PATH | \"from_location: required\" |\n| No parameters for ADD_PARAMETERS | \"parameters: required\" |\n\n---\n\n## 📊 STATUS DETERMINATION\n\n```python\ndef determine_validation_status(missing_fields, syntax_errors, risk_level):\n    # Priority 1: High risk\n    if risk_level == \"high\":\n        return \"HIGH_RISK\"\n    \n    # Priority 2: Missing data or syntax errors\n    if missing_fields or syntax_errors:\n        return \"INCOMPLETE\"\n    \n    # Priority 3: Everything OK (warnings don't block!)\n    return \"COMPLETE\"\n\ndef is_ready_for_next_agent(status):\n    return status == \"COMPLETE\"\n```\n---\n## NGINX PARAMETERS DATABASE (EXPANDED)\n### KNOWN PARAMETERS - Complete Reference\n**BUFFER PARAMETERS** (Size format: k/m):\n- `proxy_buffer_size` → Format: `SIZE` (e.g., 16k, 32k, 64k) → Default: 4k|8k\n- `proxy_buffers` → Format: `NUMBER SIZE` (e.g., 4 16k, 8 32k) → Default: 8 4k|8k\n- `proxy_busy_buffers_size` → Format: `SIZE` (e.g., 16k, 32k) → Default: 8k|16k\n- `client_header_buffer_size` → Format: `SIZE` (e.g., 128k, 256k) → Default: 1k\n- `large_client_header_buffers` → Format: `NUMBER SIZE` (e.g., 4 32k, 8 16k) → Default: 4 8k\n- `client_body_buffer_size` → Format: `SIZE` (e.g., 128k, 1m) → Default: 8k|16k\n- `client_max_body_size` → Format: `SIZE` (e.g., 50m, 100m, 1g, 0) → Default: 1m → Note: '0' means unlimited\n- `fastcgi_buffer_size` → Format: `SIZE` (e.g., 16k, 32k) → Default: 4k|8k\n- `fastcgi_buffers` → Format: `NUMBER SIZE` (e.g., 4 16k, 8 32k) → Default: 8 4k|8k\n- `fastcgi_busy_buffers_size` → Format: `SIZE` (e.g., 16k, 32k) → Default: 8k|16k\n**TIMEOUT PARAMETERS** (Format: time in seconds or with suffix s/m):\n- `proxy_connect_timeout` → Format: `TIME` (e.g., 60, 60s, 5m, 600) → Default: 60s\n- `proxy_send_timeout` → Format: `TIME` (e.g., 60, 60s, 5m, 600) → Default: 60s\n- `proxy_read_timeout` → Format: `TIME` (e.g., 60, 60s, 5m, 600) → Default: 60s\n- `fastcgi_connect_timeout` → Format: `TIME` (e.g., 60, 60s) → Default: 60s\n- `fastcgi_send_timeout` → Format: `TIME` (e.g., 60, 60s, 600) → Default: 60s\n- `fastcgi_read_timeout` → Format: `TIME` (e.g., 60, 60s, 600) → Default: 60s\n- `send_timeout` → Format: `TIME` (e.g., 60, 60s) → Default: 60s\n- `client_body_timeout` → Format: `TIME` (e.g., 60, 60s) → Default: 60s\n- `keepalive_timeout` → Format: `TIME` (e.g., 75s, 75) → Default: 75s\n**GZIP PARAMETERS** (Boolean: on/off):\n- `gzip` → Format: `on|off` → Default: off\n- `gzip_vary` → Format: `on|off` → Default: off\n- `gzip_proxied` → Format: `off|expired|no-cache|no-store|private|no_last_modified|no_etag|auth|any` → Default: off\n- `gzip_comp_level` → Format: `NUMBER` (1-9) → Default: 1\n- `gzip_disable` → Format: `STRING` (e.g., msie6, \"Safari|IE\") → Default: empty\n- `gzip_types` → Format: `MIME-TYPES` (e.g., text/plain, application/json)\n- `gzip_http_version` → Format: `VERSION` (e.g., 1.1, 1.0) → Default: 1.1\n**PROXY PARAMETERS**:\n- `proxy_pass` → DO NOT VALIDATE SYNTAX - Handled by other agents. Accept any format as valid (e.g., http://upstream_name/, http://10.0.0.1:8080/). Skip all checks for this parameter.\n- `proxy_redirect` → Format: `on|off|REDIRECT_FROM REDIRECT_TO` (e.g., off, http://old.com http://new.com) → Default: on\n- `proxy_set_header` → Format: `HEADER_NAME VALUE` (e.g., Host $host, X-Real-IP $remote_addr, X-Forwarded-For $proxy_add_x_forwarded_for, X-Forwarded-Proto $scheme, X-Forwarded-Host $host, X-Forwarded-Port $server_port, X-Forwarded-Prefix /path, Upgrade $http_upgrade, Connection $connection_upgrade, X-W-Request-ID $request_id, Client-IP $remote_addr or $proxy_add_x_forwarded_for)\n- `proxy_cache_bypass` → Format: `CONDITION` (e.g., $http_pragma, $http_authorization)\n- `proxy_http_version` → Format: `VERSION` (e.g., 1.1, 1.0) → Default: 1.1\n**SECURITY PARAMETERS**:\n- `ssl_protocols` → Format: `VERSIONS` (e.g., TLSv1.2, TLSv1.3, \"TLSv1.2 TLSv1.3\") → Default: TLSv1, TLSv1.1, TLSv1.2\n- `ssl_ciphers` → Format: `CIPHER_LIST` (e.g., HIGH:!aNULL:!MD5)\n- `ssl_certificate` → Format: `PATH` (e.g., /etc/ssl/certs/cert.pem)\n- `ssl_certificate_key` → Format: `PATH` (e.g., /etc/ssl/private/key.pem)\n**KMS/AUTH PARAMETERS**:\n- `allow` → Format: `IP|CIDR|all` (e.g., 192.168.1.0/24, 10.0.0.1) → KMS related\n- `deny` → Format: `IP|CIDR|all` (e.g., 192.168.1.0/24, all) → KMS related\n- `auth_request` → Format: `URI` (e.g., /auth, /kms_auth) → KMS related\n- `satisfy` → Format: `all|any` → KMS related\n- `limit_except` → Format: `METHOD` (e.g., GET HEAD, GET POST) → KMS related\n- `wallarm_acl` → Format: `on|off` → Default: off\n**HEADER PARAMETERS** (Boolean: on/off):\n- `underscores_in_headers` → Format: `on|off` → Default: off\n- `ignore_invalid_headers` → Format: `on|off` → Default: on\n- `server_tokens` → Format: `on|off|string` → Default: on\n- `add_header` → Format: `HEADER_NAME VALUE [always]`\n**WALLARM PARAMETERS** (Wallarm WAF):\n- `wallarm_mode` → Format: `off|monitoring|block|safe_blocking` → Default: monitoring\n- `wallarm_application` → Format: `NUMBER` (app ID) → Default: -1\n- `wallarm_request_parser` → Format: `on|off` → Default: on\n**LOGGING PARAMETERS**:\n- `access_log` → Format: `PATH FORMAT` (e.g., /var/log/nginx/access.log main, /var/log/nginx/sudir.mos.ru-access.log.json extend_json)\n- `error_log` → Format: `PATH LEVEL` (e.g., /var/log/nginx/error.log warn)\n**OTHER COMMON PARAMETERS**:\n- `keepalive_requests` → Format: `NUMBER` (e.g., 1000)\n- `reset_timedout_connection` → Format: `on|off` → Default: off\n- `listen` → Format: `PORT [ssl] [proxy_protocol]` (e.g., 9443 ssl proxy_protocol) → Server-block level\n- `http2` → Format: `on|off` → Default: off\n- `server_name` → Format: `DOMAIN` (e.g., sudir.mos.ru)\n---\n## PARAMETER VALIDATION RULES (UPDATED)\n### Rule 1: Size Format (k/m/g)\n- `proxy_buffer_size 32k` ✅ VALID\n- `proxy_buffer_size 32K` ❌ INVALID (case-sensitive, must be lowercase k/m/g)\n- `proxy_buffer_size 50m` ✅ VALID\n- `client_max_body_size 100m` ✅ VALID\n- `client_max_body_size 100M` ❌ INVALID (case-sensitive)\n- `client_max_body_size 0` ✅ VALID (unlimited)\n### Rule 2: Multi-Value Parameters (Count + Size)\n- `proxy_buffers 4 32k` ✅ VALID (count=4, size=32k)\n- `proxy_buffers 4 32K` ❌ INVALID (size must be lowercase)\n- `large_client_header_buffers 4 32k` ✅ VALID\n- `large_client_header_buffers 4 32K` ❌ INVALID (case-sensitive)\n### Rule 3: Boolean Parameters (on/off)\n- `gzip on` ✅ VALID\n- `gzip ON` ❌ INVALID (case-sensitive, must be lowercase)\n- `wallarm_mode off` ✅ VALID\n- `underscores_in_headers on` ✅ VALID\n### Rule 4: Time Format (seconds or with suffix)\n- `proxy_connect_timeout 600` ✅ VALID (600 seconds)\n- `proxy_connect_timeout 600s` ✅ VALID (explicit seconds)\n- `proxy_connect_timeout 5m` ✅ VALID (5 minutes)\n- `proxy_connect_timeout 5M` ❌ INVALID (suffix must be lowercase m)\n- `send_timeout 60` ✅ VALID\n### Rule 5: Special Multi-Value Formats\n- `proxy_set_header X-Real-IP $remote_addr` ✅ VALID\n- `proxy_redirect http://old.com http://new.com` ✅ VALID\n- `gzip_disable \"Safari|IE\"` ✅ VALID (quoted strings allowed)\n- `gzip_disable msie6` ✅ VALID\n### Rule 6: IP/CIDR Format for allow/deny\n- `allow 192.168.1.0/24` ✅ VALID\n- `allow 10.0.0.1` ✅ VALID\n- `deny all` ✅ VALID\n- `allow 256.1.1.1` ❌ INVALID (octet 256 > 255)\n- `allow 192.168.1.256` ❌ INVALID (last octet 256 > 255)\n- Multiple allows/denys in parameters are valid as separate entries\n### Rule 7: Wallarm Mode Values\n- `wallarm_mode off` ✅ VALID\n- `wallarm_mode monitoring` ✅ VALID\n- `wallarm_mode block` ✅ VALID\n- `wallarm_mode safe_blocking` ✅ VALID\n- `wallarm_mode enabled` ❌ INVALID (must be off|monitoring|block|safe_blocking)\n### Rule 8: Timeout Consistency (Improved)\n- If setting `proxy_connect_timeout`, warn if `proxy_send_timeout` or `proxy_read_timeout` missing\n- All three should ideally be set for consistent timeout behavior\n- ⚠️ Warning: \"Consider setting all proxy timeouts (connect, send, read) together for consistency\"\n- If any timeout < 10s, add warning: \"Low timeout values may cause premature disconnections\"\n### Rule 9: Buffer Consistency (Improved)\n- If setting `proxy_buffer_size`, consider also setting `proxy_buffers` and `proxy_busy_buffers_size`\n- ⚠️ Warning if `proxy_buffer_size` > individual buffer size in `proxy_buffers` (e.g., proxy_buffer_size 64k with proxy_buffers 4 16k)\n- ⚠️ New: If client_max_body_size > 1g, warn: \"Large client_max_body_size may increase memory usage or security risks\"\n### Rule 10: Gzip Type Validation\n- `gzip_disable` values should match known user-agent patterns\n- `gzip_types` should contain valid MIME-types (text/*, application/*)\n### Rule 11: Proxy_Set_Header Specifics (New)\n- For \"Client-IP\": Accept $remote_addr or $proxy_add_x_forwarded_for\n- Warn if duplicate headers (e.g., multiple Host)\n- Common values: $host, $http_host, $scheme, etc. - Validate against known variables\n### Rule 12: No Validation for Proxy_Pass (New - Critical)\n- Skip all syntax, format, and value checks for \"proxy_pass\"\n- Treat as always valid if present\n- Do not add to invalid_parameters or syntax_errors\n- Do not generate clarification questions for it\n---\n\n## ✅ VALIDATION EXAMPLES\n\n### Example 1: CREATE_LOCATION with locations array\n\n**Input:**\n\n{{\n  \"operation\": \"CREATE_LOCATION\",\n  \"domain\": \"aip.mos.ru\",\n  \"location\": null,\n  \"locations\": [\"/api_V2/\", \"/api_V3/\", \"/api_V4/\"],\n  \"upstreams\": [\n    {{\"upstream_type\": \"main\", \"ip_addresses\": [\"10.10.10.10\", \"10.10.10.11\"]}},\n    {{\"upstream_type\": \"backup\", \"ip_addresses\": [\"10.10.10.10\", \"10.10.10.11\"]}}\n  ]\n}}\n\n\n**Validation Check:**\n- ✅ domain: \"aip.mos.ru\" → PRESENT\n- ✅ location: null, BUT locations: [3 items] → PRESENT\n- ✅ upstreams: has main with 2 IPs → PRESENT\n- ⚠️ Warning: same IPs in main/backup\n\n**Output:**\n\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"upstream_validation\": {{\n    \"valid_upstreams\": [\n      {{\"type\": \"main\", \"ips\": [\"10.10.10.10\", \"10.10.10.11\"], \"status\": \"valid\"}},\n      {{\"type\": \"backup\", \"ips\": [\"10.10.10.10\", \"10.10.10.11\"], \"status\": \"valid\"}}\n    ],\n    \"warnings\": [\"Same IPs in main and backup - failover may not work as expected\"]\n  }},\n  \"risk_assessment\": {{\n    \"risk_level\": \"low\",\n    \"warnings\": [\"Consider different IPs for backup upstreams\"]\n  }},\n  \"ready_for_next_agent\": true\n}}\n\n\n---\n\n### Example 2: MODIFY_LOCATION_PATH\n\n**Input:**\n\n{{\n  \"operation\": \"MODIFY_LOCATION_PATH\",\n  \"domain\": \"mobile-newmos.mos.ru\",\n  \"location\": null,\n  \"locations\": [],\n  \"from_location\": \"/relay\",\n  \"to_location\": \"/relay/\"\n}}\n\n\n**Validation Check:**\n- ✅ domain: \"mobile-newmos.mos.ru\" → PRESENT\n- ✅ from_location: \"/relay\" → PRESENT\n- ✅ to_location: \"/relay/\" → PRESENT\n- ⏭️ location/locations: NOT CHECKED for this operation\n\n**Output:**\n\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"ready_for_next_agent\": true\n}}\n\n\n---\n\n### Example 3: ADD_PARAMETERS server block level\n\n**Input:**\n\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"domain\": \"api.mos.ru\",\n  \"location\": null,\n  \"locations\": [],\n  \"server_block_parameters\": [\"gzip:on\", \"client_max_body_size:50m\"]\n}}\n\n\n**Validation Check:**\n- ✅ domain: \"api.mos.ru\" → PRESENT\n- ✅ server_block_parameters: [2 items] → PRESENT (location not needed)\n- ✅ Parameters syntax: valid\n\n**Output:**\n\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"ready_for_next_agent\": true\n}}\n\n\n---\n\n### Example 4: Multiple domains with server_block_parameters\n\n**Input:**\n\n{{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"domain\": null,\n  \"domains\": [\"aip.mos.ru\", \"dchelper.mos.ru\"],\n  \"location\": null,\n  \"locations\": [],\n  \"server_block_parameters\": [\n    \"proxy_buffer_size:32k\",\n    \"proxy_buffers:4 32k\",\n    \"large_client_header_buffers:4 32k\"\n  ]\n}}\n\n\n**Validation Check:**\n- ✅ domain: null, BUT domains: [\"aip.mos.ru\", \"dchelper.mos.ru\"] → PRESENT\n- ✅ location: null, BUT server_block_parameters: [3 items] → SERVER BLOCK LEVEL (location not needed)\n- ✅ Parameters syntax: all valid (lowercase k)\n\n**Output:**\n\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"parameter_validation\": {{\n    \"validated_parameters\": [\n      \"proxy_buffer_size: 32k (valid)\",\n      \"proxy_buffers: 4 32k (valid)\",\n      \"large_client_header_buffers: 4 32k (valid)\"\n    ],\n    \"invalid_parameters\": [],\n    \"warnings\": [],\n    \"recommendations\": [\"Consider setting proxy_busy_buffers_size for buffer consistency\"]\n  }},\n  \"ready_for_next_agent\": true\n}}\n\n### Example: DELETE_PARAMETERS at server block level\n\n**Input:**\n```json\n{{\n  \"operation\": \"DELETE_PARAMETERS\",\n  \"selected_dc\": [],\n  \"domains\": [\"dchelper.mos.ru\"],\n  \"locations\": [],\n  \"location_match\": null,\n  \"server_block_parameters\": [\"gzip:off\"],\n  \"data_complete\": true\n}}\n```\n\n**Validation Check:**\n- ✅ domain: null, BUT domains: [\"dchelper.mos.ru\"] → PRESENT\n- ✅ locations: [], BUT server_block_parameters: [\"gzip:off\"] → SERVER BLOCK LEVEL (location not needed)\n- ✅ Parameters to delete: server_block_parameters has \"gzip:off\" → PRESENT\n\n**Output:**\n```json\n{{\n  \"validation_status\": \"COMPLETE\",\n  \"data_complete\": true,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"parameter_validation\": {{\n    \"validated_parameters\": [\"gzip: off (valid - to be deleted)\"],\n    \"invalid_parameters\": [],\n    \"warnings\": [],\n    \"recommendations\": []\n  }},\n  \"ready_for_next_agent\": true\n}}\n```\n---\n\n## 🚫 ANTI-PATTERNS (DO NOT DO THIS!)\n\n### ❌ Bug 1: Ignoring locations array\n\nInput: {{\"location\": null, \"locations\": [\"/api\", \"/v2\"]}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"location: required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n}}\n\n\n### ❌ Bug 2: Not parsing upstreams\n\n\nInput: {{\n  \"upstreams\": [\n    {{\"upstream_type\": \"main\", \"ip_addresses\": [\"10.0.0.1:80\"]}}\n  ]\n}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"upstreams: required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n}}\n\n\n### ❌ Bug 3: Warnings blocking completion\n\n\nInput: upstreams with same IPs in main/backup\n\nWRONG output:\n{{\n  \"missing_fields\": [\"upstreams: should have different IPs\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"warnings\": [\"Same IPs in main/backup\"],\n  \"validation_status\": \"COMPLETE\"\n}}\n\n\n### ❌ Bug 4: Wrong fields for MODIFY_LOCATION_PATH\n\n\nInput: {{\n  \"operation\": \"MODIFY_LOCATION_PATH\",\n  \"location\": null,\n  \"from_location\": \"/old\",\n  \"to_location\": \"/new\"\n}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"location: required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n}}\n\n\n### ❌ Bug 5: Ignoring domains array\n\nInput: {{\"domain\": null, \"domains\": [\"aip.mos.ru\", \"dchelper.mos.ru\"]}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"domain: No domain or domains specified\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n}}\n\n\n### ❌ Bug 6: Requiring location for server_block operations\n\n\nInput: {{\n  \"operation\": \"ADD_PARAMETERS\",\n  \"location\": null,\n  \"locations\": [],\n  \"server_block_parameters\": [\"gzip:on\"]\n}}\n\nWRONG output:\n{{\n  \"missing_fields\": [\"location: required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n\nCORRECT output:\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n  // server_block_parameters means server-level, no location needed\n}}\n\n### ❌ Bug 7: Ignoring server_block_parameters for DELETE_PARAMETERS\n\nInput: \n```json\n{{\n  \"operation\": \"DELETE_PARAMETERS\",\n  \"domains\": [\"dchelper.mos.ru\"],\n  \"locations\": [],\n  \"parameters\": [],\n  \"server_block_parameters\": [\"gzip:off\"]\n}}\n```\n\nWRONG output:\n```json\n{{\n  \"missing_fields\": [\"parameters: parameter names to delete required\"],\n  \"validation_status\": \"INCOMPLETE\"\n}}\n```\n\nCORRECT output:\n```json\n{{\n  \"missing_fields\": [],\n  \"validation_status\": \"COMPLETE\"\n  // server_block_parameters contains the parameter to delete!\n}}\n```\n---\n\n## 📊 OUTPUT SCHEMA\n\n\n{{\n  \"validation_status\": \"COMPLETE | INCOMPLETE | HIGH_RISK\",\n  \"data_complete\": true | false,\n  \"missing_fields\": [],\n  \"syntax_errors\": [],\n  \"clarification_questions\": [],\n  \"parameter_validation\": {{\n    \"validated_parameters\": [],\n    \"invalid_parameters\": [],\n    \"warnings\": [],\n    \"recommendations\": []\n  }},\n  \"kms_rules\": {{\n    \"locations_need_kms\": [],\n    \"locations_public\": [],\n    \"note\": null\n  }},\n  \"upstream_validation\": {{\n    \"valid_upstreams\": [],\n    \"invalid_upstreams\": [],\n    \"warnings\": []\n  }},\n  \"risk_assessment\": {{\n    \"risk_level\": \"low | medium | high\",\n    \"risk_factors\": [],\n    \"warnings\": [],\n    \"requires_confirmation\": false\n  }},\n  \"cross_referenced\": {{\n    \"applied\": false,\n    \"note\": null,\n    \"inherited_fields\": []\n  }},\n  \"ready_for_next_agent\": true | false,\n  \"validation_summary\": {{\n    \"total_parameters\": 0,\n    \"valid_parameters\": 0,\n    \"invalid_parameters\": 0,\n    \"skipped_parameters\": 0\n  }}\n}}\n\n\n---\n\n## 🧠 MANDATORY REASONING PROCESS\n\nBefore outputting JSON, think step by step:\n\n\n<thinking>\n1. PARSE INPUT\n   - Operation: [operation]\n   - Domain present? [check domain AND domains]\n   - Location present? [check location AND locations]\n   - From/to location? [for MODIFY_LOCATION_PATH]\n   - Upstreams present? [check array contents]\n   - Parameters present? [check all param fields]\n\n2. DETERMINE REQUIRED FIELDS\n   - For [operation], required fields are: [list]\n   - Checking each:\n     - Field X: [present/missing]\n     - Field Y: [present/missing]\n\n3. VALIDATE SYNTAX (if parameters present)\n   - Parameter A: [valid/invalid]\n   - Parameter B: [valid/invalid]\n\n4. IDENTIFY WARNINGS (do not block completion!)\n   - [list any warnings]\n\n5. DETERMINE STATUS\n   - Missing fields: [count]\n   - Syntax errors: [count]\n   - High risk: [yes/no]\n   - Final status: [COMPLETE/INCOMPLETE/HIGH_RISK]\n\n6. SET READY FLAG\n   - Status is COMPLETE? [yes/no]\n   - ready_for_next_agent: [true/false]\n</thinking>\n\n\n---\n\n## ❗ CRITICAL RULES\n\n1. **ALWAYS check both `domain` AND `domains`** — either one being present is valid\n2. **ALWAYS check both `location` AND `locations`** — either one being present is valid\n3. **ALWAYS parse `upstreams` array contents** — check ip_addresses inside\n4. **NEVER treat warnings as missing fields** — warnings don't block COMPLETE\n5. **For MODIFY_LOCATION_PATH** — check from_location/to_location, NOT location/locations\n6. **For server_block_parameters** — location NOT required when operating at server level\n7. **Skip proxy_pass validation** — always mark as valid\n8. **Consistency check** — if missing_fields is empty, status should be COMPLETE\n\n---\n\n## NOW VALIDATE\n\n**AGENT 1 OUTPUT:**\n{agent1_json}\n\n**ORIGINAL REQUEST:**\n{original_question}\n\n---\n\n**Output ONLY valid JSON:**\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "id": "Prompt Template-KPVE4",
        "measured": {
          "height": 441,
          "width": 320
        },
        "position": {
          "x": 2317.0306158836916,
          "y": 1104.8726434538862
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ArbitratorComponent-vBetm",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Проверяет validation_status от Agent2 и возвращает JSON от Agent1 если COMPLETE",
            "display_name": "JSON Arbitrator",
            "documentation": "",
            "edited": true,
            "field_order": [
              "agent1_output",
              "agent2_output"
            ],
            "frozen": false,
            "icon": "check-circle",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Result",
                "group_outputs": false,
                "hidden": null,
                "method": "process",
                "name": "result",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Needs Clarification",
                "group_outputs": false,
                "hidden": null,
                "method": "get_clarification",
                "name": "needs_clarification",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent1_output": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Agent 1 Output",
                "dynamic": false,
                "info": "JSON от первого агента (парсер)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "agent1_output",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "agent2_output": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Agent 2 Output",
                "dynamic": false,
                "info": "JSON от второго агента (валидатор)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "agent2_output",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.data import Data\nimport json\n\n\nclass ArbitratorComponent(Component):\n    display_name = \"JSON Arbitrator\"\n    description = \"Проверяет validation_status от Agent2 и возвращает JSON от Agent1 если COMPLETE\"\n    icon = \"check-circle\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"agent1_output\",\n            display_name=\"Agent 1 Output\",\n            info=\"JSON от первого агента (парсер)\",\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"agent2_output\",\n            display_name=\"Agent 2 Output\",\n            info=\"JSON от второго агента (валидатор)\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Result\",\n            name=\"result\",\n            method=\"process\",\n        ),\n        Output(\n            display_name=\"Needs Clarification\",\n            name=\"needs_clarification\",\n            method=\"get_clarification\",\n        ),\n    ]\n\n    def _parse_json(self, text: str) -> dict:\n        \"\"\"Парсит JSON, убирая markdown обёртки если есть\"\"\"\n        text = text.strip()\n        # Убираем ```json ... ``` если есть\n        if text.startswith(\"```\"):\n            lines = text.split(\"\\n\")\n            # Убираем первую и последнюю строку с ```\n            lines = [l for l in lines if not l.strip().startswith(\"```\")]\n            text = \"\\n\".join(lines)\n        return json.loads(text)\n\n    def _is_valid(self, agent2_data: dict) -> bool:\n        \"\"\"Проверяет статус валидации\"\"\"\n        status = agent2_data.get(\"validation_status\", \"\").upper()\n        return status == \"COMPLETE\"\n\n    def process(self) -> Data:\n        \"\"\"Основной выход — возвращает agent1 JSON напрямую, если валидация прошла\"\"\"\n        try:\n            agent1_data = self._parse_json(self.agent1_output)\n            agent2_data = self._parse_json(self.agent2_output)\n    \n            if self._is_valid(agent2_data):\n                # Возвращаем именно payload-структуру, без мета-обёртки\n                return Data(data=agent1_data)\n            else:\n                return Data(data={\n                    \"status\": \"VALIDATION_FAILED\",\n                    \"payload\": None,\n                    \"ready_for_execution\": False,\n                    \"missing_fields\": agent2_data.get(\"missing_fields\", []),\n                    \"clarification_questions\": agent2_data.get(\"clarification_questions\", [])\n                })\n    \n        except json.JSONDecodeError as e:\n            return Data(data={\n                \"status\": \"PARSE_ERROR\",\n                \"error\": str(e),\n                \"ready_for_execution\": False\n            })\n\n    def get_clarification(self) -> Data:\n        \"\"\"Второй выход — вопросы для уточнения если нужны\"\"\"\n        try:\n            agent2_data = self._parse_json(self.agent2_output)\n\n            if not self._is_valid(agent2_data):\n                questions = agent2_data.get(\"clarification_questions\", [])\n                missing = agent2_data.get(\"missing_fields\", [])\n                \n                return Data(data={\n                    \"needs_clarification\": True,\n                    \"questions\": questions,\n                    \"missing_fields\": missing,\n                    \"message\": self._format_clarification_message(questions, missing)\n                })\n            else:\n                return Data(data={\n                    \"needs_clarification\": False,\n                    \"questions\": [],\n                    \"missing_fields\": [],\n                    \"message\": None\n                })\n\n        except json.JSONDecodeError:\n            return Data(data={\n                \"needs_clarification\": True,\n                \"questions\": [],\n                \"missing_fields\": [],\n                \"message\": \"Ошибка парсинга JSON от агентов\"\n            })\n\n    def _format_clarification_message(self, questions: list, missing: list) -> str:\n        \"\"\"Форматирует сообщение для пользователя\"\"\"\n        parts = []\n        \n        if missing:\n            parts.append(\"Не хватает данных:\")\n            for field in missing:\n                parts.append(f\"  • {field}\")\n        \n        if questions:\n            parts.append(\"\\nУточняющие вопросы:\")\n            for q in questions:\n                parts.append(f\"  • {q}\")\n        \n        return \"\\n\".join(parts) if parts else \"Требуется уточнение запроса\""
              }
            },
            "tool_mode": false
          },
          "selected_output": "result",
          "showNode": true,
          "type": "ArbitratorComponent"
        },
        "dragging": false,
        "id": "ArbitratorComponent-vBetm",
        "measured": {
          "height": 301,
          "width": 320
        },
        "position": {
          "x": 3917.3716425114917,
          "y": 1123.7703202978878
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-W4PmL",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": false,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "last_updated": "2025-11-30T12:21:17.327Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "group_outputs": true,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "group_outputs": true,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"starts with\",\n                \"ends with\",\n                \"regex\",\n                \"less than\",\n                \"less than or equal\",\n                \"greater than\",\n                \"greater than or equal\",\n            ],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"true_case_message\",\n            display_name=\"Case True\",\n            info=\"The message to pass if the condition is True.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"false_case_message\",\n            display_name=\"Case False\",\n            info=\"The message to pass if the condition is False.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n            try:\n                input_num = float(input_text)\n                match_num = float(match_text)\n                if operator == \"less than\":\n                    return input_num < match_num\n                if operator == \"less than or equal\":\n                    return input_num <= match_num\n                if operator == \"greater than\":\n                    return input_num > match_num\n                if operator == \"greater than or equal\":\n                    return input_num >= match_num\n            except ValueError:\n                return False  # Invalid number format for comparison\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        \"\"\"Handles cycle iteration counting and branch exclusion.\n\n        Uses two complementary mechanisms:\n        1. stop() - ACTIVE/INACTIVE state for cycle management (gets reset each iteration)\n        2. exclude_branch_conditionally() - Persistent exclusion for conditional routing\n\n        When max_iterations is reached, breaks the cycle by allowing the default_route to execute.\n        \"\"\"\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n\n            # Check if max iterations reached and we're trying to stop the default route\n            if current_iteration >= self.max_iterations and route_to_stop == self.default_route:\n                # Clear ALL conditional exclusions to allow default route to execute\n                if self._id in self.graph.conditional_exclusion_sources:\n                    previous_exclusions = self.graph.conditional_exclusion_sources[self._id]\n                    self.graph.conditionally_excluded_vertices -= previous_exclusions\n                    del self.graph.conditional_exclusion_sources[self._id]\n\n                # Switch which route to stop - stop the NON-default route to break the cycle\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n\n                # Call stop to break the cycle\n                self.stop(route_to_stop)\n                # Don't apply conditional exclusion when breaking cycle\n                return\n\n            # Normal case: Use BOTH mechanisms\n            # 1. stop() for cycle management (marks INACTIVE, updates run manager, gets reset)\n            self.stop(route_to_stop)\n\n            # 2. Conditional exclusion for persistent routing (doesn't get reset except by this router)\n            self.graph.exclude_branch_conditionally(self._id, output_name=route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        # Check if we should force output due to max_iterations on default route\n        current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n        force_output = current_iteration >= self.max_iterations and self.default_route == \"true_result\"\n\n        if result or force_output:\n            self.status = self.true_case_message\n            if not force_output:  # Only stop the other branch if not forcing due to max iterations\n                self.iterate_and_stop_once(\"false_result\")\n            return self.true_case_message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        if not result:\n            self.status = self.false_case_message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.false_case_message\n\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "external_options": {},
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".*(ADD_PARAMETERS|MODIFY_PARAMETERS|DELETE_PARAMETERS|DELETE_LOCATION|CREATE_LOCATION|MODIFY_LOCATION_PATH|MAKE_PROTECTED|MAKE_PUBLIC).*"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "external_options": {},
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "regex"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-W4PmL",
        "measured": {
          "height": 509,
          "width": 320
        },
        "position": {
          "x": 5904.879931066491,
          "y": 902.727406578453
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-H6W2e",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": false,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "last_updated": "2025-11-30T12:02:50.362Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "group_outputs": true,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "group_outputs": true,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"starts with\",\n                \"ends with\",\n                \"regex\",\n                \"less than\",\n                \"less than or equal\",\n                \"greater than\",\n                \"greater than or equal\",\n            ],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"true_case_message\",\n            display_name=\"Case True\",\n            info=\"The message to pass if the condition is True.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"false_case_message\",\n            display_name=\"Case False\",\n            info=\"The message to pass if the condition is False.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n            try:\n                input_num = float(input_text)\n                match_num = float(match_text)\n                if operator == \"less than\":\n                    return input_num < match_num\n                if operator == \"less than or equal\":\n                    return input_num <= match_num\n                if operator == \"greater than\":\n                    return input_num > match_num\n                if operator == \"greater than or equal\":\n                    return input_num >= match_num\n            except ValueError:\n                return False  # Invalid number format for comparison\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        \"\"\"Handles cycle iteration counting and branch exclusion.\n\n        Uses two complementary mechanisms:\n        1. stop() - ACTIVE/INACTIVE state for cycle management (gets reset each iteration)\n        2. exclude_branch_conditionally() - Persistent exclusion for conditional routing\n\n        When max_iterations is reached, breaks the cycle by allowing the default_route to execute.\n        \"\"\"\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n\n            # Check if max iterations reached and we're trying to stop the default route\n            if current_iteration >= self.max_iterations and route_to_stop == self.default_route:\n                # Clear ALL conditional exclusions to allow default route to execute\n                if self._id in self.graph.conditional_exclusion_sources:\n                    previous_exclusions = self.graph.conditional_exclusion_sources[self._id]\n                    self.graph.conditionally_excluded_vertices -= previous_exclusions\n                    del self.graph.conditional_exclusion_sources[self._id]\n\n                # Switch which route to stop - stop the NON-default route to break the cycle\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n\n                # Call stop to break the cycle\n                self.stop(route_to_stop)\n                # Don't apply conditional exclusion when breaking cycle\n                return\n\n            # Normal case: Use BOTH mechanisms\n            # 1. stop() for cycle management (marks INACTIVE, updates run manager, gets reset)\n            self.stop(route_to_stop)\n\n            # 2. Conditional exclusion for persistent routing (doesn't get reset except by this router)\n            self.graph.exclude_branch_conditionally(self._id, output_name=route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        # Check if we should force output due to max_iterations on default route\n        current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n        force_output = current_iteration >= self.max_iterations and self.default_route == \"true_result\"\n\n        if result or force_output:\n            self.status = self.true_case_message\n            if not force_output:  # Only stop the other branch if not forcing due to max iterations\n                self.iterate_and_stop_once(\"false_result\")\n            return self.true_case_message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        if not result:\n            self.status = self.false_case_message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.false_case_message\n\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "external_options": {},
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".*(DELETE_LOCATION|CREATE_LOCATION|MODIFY_UPSTREAM).*"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "external_options": {},
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "regex"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-H6W2e",
        "measured": {
          "height": 509,
          "width": 320
        },
        "position": {
          "x": 5941.232005410501,
          "y": 2173.719248057828
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-iJJfy",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "last_updated": "2025-12-08T19:35:28.674Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Clean Data",
                "dynamic": false,
                "info": "Enable to clean the data by removing empty rows and lines in each cell of the DataFrame/ Data object.",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Stringify"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{payload}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "id": "ParserComponent-iJJfy",
        "measured": {
          "height": 245,
          "width": 320
        },
        "position": {
          "x": 4647.043319557171,
          "y": 1585.1118867462033
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "JSONCleaner-nmFh0",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.",
            "display_name": "JSON Cleaner",
            "documentation": "",
            "edited": false,
            "field_order": [
              "json_str",
              "remove_control_chars",
              "normalize_unicode",
              "validate_json"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "JSONCleaner",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Cleaned JSON String",
                "group_outputs": false,
                "method": "clean_json",
                "name": "output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.ParserComponent"
            ],
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport unicodedata\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import BoolInput, MessageTextInput\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass JSONCleaner(Component):\n    icon = \"braces\"\n    display_name = \"JSON Cleaner\"\n    description = (\n        \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs \"\n        \"so that they are fully compliant with the JSON spec.\"\n    )\n    legacy = True\n    replacement = [\"processing.ParserComponent\"]\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json\n        except ImportError as e:\n            msg = \"Could not import the json_repair package. Please install it with `pip install json_repair`.\"\n            raise ImportError(msg) from e\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        start = json_str.find(\"{\")\n        end = json_str.rfind(\"}\")\n        if start == -1 or end == -1:\n            msg = \"Invalid JSON string: Missing '{' or '}'\"\n            raise ValueError(msg)\n        try:\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            msg = f\"Error cleaning JSON string: {e}\"\n            raise ValueError(msg) from e\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return s.translate(self.translation_table)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n        except json.JSONDecodeError as e:\n            msg = f\"Invalid JSON string: {e}\"\n            raise ValueError(msg) from e\n        return s\n\n    def __init__(self, *args, **kwargs):\n        # Create a translation table that maps control characters to None\n        super().__init__(*args, **kwargs)\n        self.translation_table = str.maketrans(\"\", \"\", \"\".join(chr(i) for i in range(32)) + chr(127))\n"
              },
              "json_str": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JSON String",
                "dynamic": false,
                "info": "The JSON string to be cleaned.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "json_str",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "normalize_unicode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Normalize Unicode",
                "dynamic": false,
                "info": "Normalize Unicode characters in the JSON string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "normalize_unicode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "remove_control_chars": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Remove Control Characters",
                "dynamic": false,
                "info": "Remove control characters from the JSON string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "remove_control_chars",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "validate_json": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Validate JSON",
                "dynamic": false,
                "info": "Validate the JSON string to ensure it is well-formed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "validate_json",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "JSONCleaner"
        },
        "id": "JSONCleaner-nmFh0",
        "measured": {
          "height": 440,
          "width": 320
        },
        "position": {
          "x": 5138.047804159384,
          "y": 1431.2517379985165
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-KA7o9",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/components-io#chat-input",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatInput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0020353564437605998,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        # Ensure files is a list and filter out empty/None values\n        files = self.files if self.files else []\n        if files and not isinstance(files, list):\n            files = [files]\n        files = [f for f in files if f is not None and f != \"\"]\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=files,\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "csv",
                  "json",
                  "pdf",
                  "txt",
                  "md",
                  "mdx",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "id": "ChatInput-KA7o9",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 284,
          "y": 1572.455026292941
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-ToohH",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": false,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "key": "ConditionalRouter",
            "last_updated": "2025-12-11T07:14:24.553Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "group_outputs": true,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "group_outputs": true,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"If-Else\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"operator\",\n            display_name=\"Operator\",\n            options=[\n                \"equals\",\n                \"not equals\",\n                \"contains\",\n                \"starts with\",\n                \"ends with\",\n                \"regex\",\n                \"less than\",\n                \"less than or equal\",\n                \"greater than\",\n                \"greater than or equal\",\n            ],\n            info=\"The operator to apply for comparing the texts.\",\n            value=\"equals\",\n            real_time_refresh=True,\n        ),\n        MessageTextInput(\n            name=\"match_text\",\n            display_name=\"Match Text\",\n            info=\"The text input to compare against.\",\n            required=True,\n        ),\n        BoolInput(\n            name=\"case_sensitive\",\n            display_name=\"Case Sensitive\",\n            info=\"If true, the comparison will be case sensitive.\",\n            value=True,\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"true_case_message\",\n            display_name=\"Case True\",\n            info=\"The message to pass if the condition is True.\",\n            advanced=True,\n        ),\n        MessageInput(\n            name=\"false_case_message\",\n            display_name=\"Case False\",\n            info=\"The message to pass if the condition is False.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"max_iterations\",\n            display_name=\"Max Iterations\",\n            info=\"The maximum number of iterations for the conditional router.\",\n            value=10,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"default_route\",\n            display_name=\"Default Route\",\n            options=[\"true_result\", \"false_result\"],\n            info=\"The default route to take when max iterations are reached.\",\n            value=\"false_result\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\n    ]\n\n    def _pre_run_setup(self):\n        self.__iteration_updated = False\n\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\n        if not case_sensitive and operator != \"regex\":\n            input_text = input_text.lower()\n            match_text = match_text.lower()\n\n        if operator == \"equals\":\n            return input_text == match_text\n        if operator == \"not equals\":\n            return input_text != match_text\n        if operator == \"contains\":\n            return match_text in input_text\n        if operator == \"starts with\":\n            return input_text.startswith(match_text)\n        if operator == \"ends with\":\n            return input_text.endswith(match_text)\n        if operator == \"regex\":\n            try:\n                return bool(re.match(match_text, input_text))\n            except re.error:\n                return False  # Return False if the regex is invalid\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\n            try:\n                input_num = float(input_text)\n                match_num = float(match_text)\n                if operator == \"less than\":\n                    return input_num < match_num\n                if operator == \"less than or equal\":\n                    return input_num <= match_num\n                if operator == \"greater than\":\n                    return input_num > match_num\n                if operator == \"greater than or equal\":\n                    return input_num >= match_num\n            except ValueError:\n                return False  # Invalid number format for comparison\n        return False\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n        \"\"\"Handles cycle iteration counting and branch exclusion.\n\n        Uses two complementary mechanisms:\n        1. stop() - ACTIVE/INACTIVE state for cycle management (gets reset each iteration)\n        2. exclude_branch_conditionally() - Persistent exclusion for conditional routing\n\n        When max_iterations is reached, breaks the cycle by allowing the default_route to execute.\n        \"\"\"\n        if not self.__iteration_updated:\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\n            self.__iteration_updated = True\n            current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n\n            # Check if max iterations reached and we're trying to stop the default route\n            if current_iteration >= self.max_iterations and route_to_stop == self.default_route:\n                # Clear ALL conditional exclusions to allow default route to execute\n                if self._id in self.graph.conditional_exclusion_sources:\n                    previous_exclusions = self.graph.conditional_exclusion_sources[self._id]\n                    self.graph.conditionally_excluded_vertices -= previous_exclusions\n                    del self.graph.conditional_exclusion_sources[self._id]\n\n                # Switch which route to stop - stop the NON-default route to break the cycle\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\n\n                # Call stop to break the cycle\n                self.stop(route_to_stop)\n                # Don't apply conditional exclusion when breaking cycle\n                return\n\n            # Normal case: Use BOTH mechanisms\n            # 1. stop() for cycle management (marks INACTIVE, updates run manager, gets reset)\n            self.stop(route_to_stop)\n\n            # 2. Conditional exclusion for persistent routing (doesn't get reset except by this router)\n            self.graph.exclude_branch_conditionally(self._id, output_name=route_to_stop)\n\n    def true_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        # Check if we should force output due to max_iterations on default route\n        current_iteration = self.ctx.get(f\"{self._id}_iteration\", 0)\n        force_output = current_iteration >= self.max_iterations and self.default_route == \"true_result\"\n\n        if result or force_output:\n            self.status = self.true_case_message\n            if not force_output:  # Only stop the other branch if not forcing due to max iterations\n                self.iterate_and_stop_once(\"false_result\")\n            return self.true_case_message\n        self.iterate_and_stop_once(\"true_result\")\n        return Message(content=\"\")\n\n    def false_response(self) -> Message:\n        result = self.evaluate_condition(\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\n        )\n\n        if not result:\n            self.status = self.false_case_message\n            self.iterate_and_stop_once(\"true_result\")\n            return self.false_case_message\n\n        self.iterate_and_stop_once(\"false_result\")\n        return Message(content=\"\")\n\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\n        if field_name == \"operator\":\n            if field_value == \"regex\":\n                build_config.pop(\"case_sensitive\", None)\n            elif \"case_sensitive\" not in build_config:\n                case_sensitive_input = next(\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\n                )\n                if case_sensitive_input:\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\n        return build_config\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "external_options": {},
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ".*(VALIDATION_FAILED).*"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "external_options": {},
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "regex"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-ToohH",
        "measured": {
          "height": 509,
          "width": 320
        },
        "position": {
          "x": 5297.0698885665615,
          "y": 2813.9735648503893
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-zHg0X",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-zHg0X",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 5665.206584980623,
          "y": 3219.5693492988257
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-FdI1h",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "operation",
                "agent1_data",
                "upstreams"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "replacement": null,
            "template": {
              "_type": "Component",
              "agent1_data": {
                "advanced": false,
                "display_name": "agent1_data",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "agent1_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "operation": {
                "advanced": false,
                "display_name": "operation",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "operation",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "# NGINX Upstream Configuration Agent v6.0 (Smart Validation)\n\nYou are an nginx upstream configuration expert. Process upstream configs in JSON format.\n\n## ERROR CHECK (DO FIRST)\n\nIf ANY condition is true, return error JSON and STOP:\n- `agent1_data` is \"None\" or missing\n- `upstreams` is \"None\" or missing (except CREATE_LOCATION)\n\n```json\n{{\n  \"status\": \"error\",\n  \"operation_type\": \"NONE\",\n  \"error_type\": \"PREREQUISITE_ERROR\",\n  \"error_message\": \"Missing required data\",\n  \"ready_to_save\": false\n}}\n```\n\n## INPUTS\n\n- `{operation}`: CREATE_LOCATION | MODIFY_UPSTREAM | DELETE_LOCATION\n- `{agent1_data}`: Request details (domain, location, ip_addresses, upstream_type)\n- `{upstreams}`: Current upstream configs (JSON)\n\n## ⚠️ CRITICAL: SMART VALIDATION (NEW IN v6.0)\n\n### Before ANY modification, perform these checks:\n\n#### 1. NO-OP Detection (Идемпотентность)\nCompare requested state with current state. If they are IDENTICAL, return:\n```json\n{{\n  \"status\": \"no_change\",\n  \"operation_type\": \"MODIFY_UPSTREAM\",\n  \"upstream_name\": \"example_upstream\",\n  \"target_section\": \"main\",\n  \"message\": \"Requested configuration is identical to current state. No changes needed.\",\n  \"current_servers\": [\"10.206.178.155:80\", \"10.206.178.156:80\"],\n  \"requested_servers\": [\"10.206.178.155:80\", \"10.206.178.156:80\"],\n  \"ready_to_save\": false\n}}\n```\n\n#### 2. Partial Modification Detection (Точечные изменения)\nWhen user requests to change ONLY specific attributes (like port), preserve unchanged parts:\n\n**User says:** \"замени порты на 443\"\n**Current:** `[\"10.206.178.155:80\", \"10.206.178.156:80\"]`\n**Result:** `[\"10.206.178.155:443\", \"10.206.178.156:443\"]` ← ONLY port changes, IPs preserved\n\n**User says:** \"замени IP 10.206.178.155 на 10.206.178.200\"\n**Current:** `[\"10.206.178.155:80\", \"10.206.178.156:80\"]`\n**Result:** `[\"10.206.178.200:80\", \"10.206.178.156:80\"]` ← ONLY that IP changes\n\n#### 3. Intent Analysis\nParse `{agent1_data}` to understand the actual intent:\n\n| User Request Pattern | Intent | Action |\n|---------------------|--------|--------|\n| \"замени порты на X\" | CHANGE_PORT | Keep IPs, change all ports to X |\n| \"замени порт на X для IP Y\" | CHANGE_PORT_SINGLE | Change port only for specific IP |\n| \"замени IP X на Y\" | CHANGE_IP | Keep port, change specific IP |\n| \"добавь сервер X\" | ADD_SERVER | Append to existing list |\n| \"удали сервер X\" | REMOVE_SERVER | Remove from existing list |\n| \"замени апстримы на X,Y,Z\" | REPLACE_ALL | Full replacement |\n| \"main backup X,Y,Z\" | REPLACE_BOTH | Replace servers in BOTH main and backup sections |\n| \"замени main и backup на X,Y,Z\" | REPLACE_BOTH | Replace servers in BOTH main and backup sections |\n\n### Intent Detection in agent1_data\n\nAdd field `modification_type` to agent1_data:\n- `replace_all` - полная замена списка серверов\n- `change_port` - изменить порт(ы), сохранить IP\n- `change_port_single` - изменить порт для конкретного IP\n- `change_ip` - изменить конкретный IP\n- `add_server` - добавить сервер(ы)\n- `remove_server` - удалить сервер(ы)\n\n## CONFIG FORMAT (JSON)\n\n```json\n{{\n  \"nginx_http_upstreams\": {{\n    \"aip_mos_ru\": {{\n      \"main\": {{\n        \"lb\": \"ip_hash\",\n        \"servers\": [\"10.206.218.65:80\", \"10.206.218.66:80\"]\n      }},\n      \"backup\": {{\n        \"servers\": [\"10.207.139.201:80\"]\n      }},\n      \"domains\": [\"aip.mos.ru\"],\n      \"environment\": \"production\",\n      \"system_id\": \"IS0166\"\n    }}\n  }}\n}}\n```\n\n**Server params:** `max_fails=N`, `fail_timeout=Xs`, `weight=N`, `backup`, `down`\n**LB methods:** `round_robin`, `ip_hash`, `least_conn`, `hash`\n\n⚠️ **LB RULE:** Field `lb` include ONLY if:\n- Already exists in current config → preserve it\n- User explicitly requested → add it\n- Otherwise → DO NOT add `lb` field\n\n## OPERATIONS\n\n### MODIFY_UPSTREAM (Enhanced)\n\n#### Step 1: Parse Current State\n```\ncurrent_servers = {upstreams}[upstream_name][section][\"servers\"]\n```\n\n#### Step 2: Determine Modification Type\nBased on `{agent1_data}.modification_type` or infer from context:\n\n**Type: change_port**\n```python\nnew_port = {agent1_data}.new_port  # e.g., \"443\"\nnew_servers = []\nfor server in current_servers:\n    ip = server.split(\":\")[0]\n    new_servers.append(f\"{{ip}}:{{new_port}}\")\n```\n\n**Type: change_ip**\n```python\nold_ip = {agent1_data}.old_ip\nnew_ip = {agent1_data}.new_ip\nnew_servers = []\nfor server in current_servers:\n    ip, port = server.split(\":\")\n    if ip == old_ip:\n        new_servers.append(f\"{{new_ip}}:{{port}}\")\n    else:\n        new_servers.append(server)\n```\n\n**Type: add_server**\n```python\nnew_servers = current_servers + {agent1_data}.servers_to_add\n```\n\n**Type: remove_server**\n```python\nto_remove = set({agent1_data}.servers_to_remove)\nnew_servers = [s for s in current_servers if s not in to_remove]\n```\n\n**Type: replace_all**\n```python\nnew_servers = {agent1_data}.ip_addresses\n# Add default port if missing\nnew_servers = [s if \":\" in s else f\"{{s}}:80\" for s in new_servers]\n```\n\n#### Step 3: Validate Change\n```python\nif set(new_servers) == set(current_servers):\n    return {{\"status\": \"no_change\", ...}}\n```\n**Type: replace_both**\n```python\nnew_servers = {agent1_data}.ip_addresses\nnew_servers = [s if \":\" in s else f»{{s}}:80\" for s in new_servers]\n# Apply to BOTH sections\nresult[\"main\"][\"servers\"] = new_servers\nresult[\"backup\"][\"servers\"] = new_servers\n```\n#### Step 4: Generate Output\n**Output for replace_both**\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"MODIFY_UPSTREAM\",\n  \"modification_type\": \"replace_all\",\n  \"upstream_name\": \"school_mos_ru_notifications\",\n  \"target_section\": \"both\",\n  \"analysis\": {{\n    \"main\": {{\n      \"current_servers\": [\"10.206.223.50:80\", \"10.206.223.51:80\", \"10.206.223.52:80\", \"10.206.223.53:80\", \"10.206.223.54:80\", \"10.206.223.55:80\"],\n      \"new_servers\": [\"10.10.10.10:80\", \"10.10.10.11:80\", \"10.10.10.12:80\"],\n      \"servers_modified\": 3\n    }},\n    \"backup\": {{\n      \"current_servers\": [\"10.207.139.50:80\", \"10.207.139.51:80\"],\n      \"new_servers\": [\"10.10.10.10:80\", \"10.10.10.11:80\", \"10.10.10.12:80\"],\n      \"servers_modified\": 3\n    }},\n    \"change_description\": \"Both main and backup servers completely replaced with identical new IP addresses\",\n    \"ips_unchanged\": false\n  }},\n  \"updated_json\": {{\n    \"school_mos_ru_notifications\": {{\n      \"main\": {{\n        \"servers\": [\"10.10.10.10:80\", \"10.10.10.11:80\", \"10.10.10.12:80\"]\n      }},\n      \"backup\": {{\n        \"servers\": [\"10.10.10.10:80\", \"10.10.10.11:80\", \"10.10.10.12:80\"]\n      }},\n      \"domains\": [\"school.mos.ru\"],\n      \"environment\": \"production\",\n      \"system_id\": \"IS1125\"\n    }}\n  }},\n  \"diff\": {{\n    \"type\": \"full_replacement\",\n    \"main\": {{\n      \"old_servers\": [\"10.206.223.50:80\", \"10.206.223.51:80\", \"10.206.223.52:80\", \"10.206.223.53:80\", \"10.206.223.54:80\", \"10.206.223.55:80\"],\n      \"new_servers\": [\"10.10.10.10:80\", \"10.10.10.11:80\", \"10.10.10.12:80\"]\n    }},\n    \"backup\": {{\n      \"old_servers\": [\"10.207.139.50:80\", \"10.207.139.51:80\"],\n      \"new_servers\": [\"10.10.10.10:80\", \"10.10.10.11:80\", \"10.10.10.12:80\"]\n    }}\n  }},\n  \"explanation\": \"Main and backup servers for upstream school_mos_ru_notifications have been completely replaced. Main: 6 servers → 3 servers. Backup: 2 servers → 3 servers. Both sections now contain identical server lists.\",\n  \"ready_to_save\": true\n}}\n```\n**Output for change_port:**\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"MODIFY_UPSTREAM\",\n  \"modification_type\": \"change_port\",\n  \"upstream_name\": \"dchelper_mos_ru\",\n  \"target_section\": \"main\",\n  \"analysis\": {{\n    \"current_servers\": [\"10.206.178.155:80\", \"10.206.178.156:80\"],\n    \"new_servers\": [\"10.206.178.155:443\", \"10.206.178.156:443\"],\n    \"change_description\": \"Port changed from 80 to 443 for all servers\",\n    \"servers_modified\": 2,\n    \"ips_unchanged\": true\n  }},\n  \"updated_json\": {{\n    \"dchelper_mos_ru\": {{\n      \"main\": {{\"servers\": [\"10.206.178.155:443\", \"10.206.178.156:443\"]}},\n      \"backup\": {{\"servers\": [\"10.206.178.155\", \"10.206.178.156\"]}},\n      \"domains\": [\"dchelper.mos.ru\"],\n      \"environment\": \"production\",\n      \"system_id\": \"IS0998\"\n    }}\n  }},\n  \"diff\": {{\n    \"type\": \"port_change\",\n    \"old_port\": \"80\",\n    \"new_port\": \"443\",\n    \"affected_servers\": 2\n  }},\n  \"explanation\": \"Port changed from 80 to 443 for all 2 main servers. IPs preserved.\",\n  \"ready_to_save\": true\n}}\n```\n\n**Output for no_change:**\n```json\n{{\n  \"status\": \"no_change\",\n  \"operation_type\": \"MODIFY_UPSTREAM\",\n  \"upstream_name\": \"dchelper_mos_ru\",\n  \"target_section\": \"main\",\n  \"message\": \"Requested servers are identical to current configuration\",\n  \"current_servers\": [\"10.206.178.155:80\", \"10.206.178.156:80\"],\n  \"requested_servers\": [\"10.206.178.155:80\", \"10.206.178.156:80\"],\n  \"ready_to_save\": false\n}}\n```\n\n### CREATE_LOCATION\n\n1. Generate name: `domain.replace(\".\",  \"_\")` + `_` + `location.replace(\"/\", \"_\")`\n   - Example: `aip.mos.ru` + `/api/test_v2/` → `aip_mos_ru_api_test_v2`\n2. Create config from `agent1_data.upstreams[]`\n3. Add `:80` if no port specified\n\n**Output:**\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"CREATE_LOCATION\",\n  \"upstream_name\": \"aip_mos_ru_api\",\n  \"updated_json\": {{\n    \"aip_mos_ru_api\": {{\n      \"main\": {{\"servers\": [\"10.10.10.10:80\"]}},\n      \"domains\": [\"aip.mos.ru\"],\n      \"environment\": \"production\",\n      \"system_id\": null\n    }}\n  }},\n  \"explanation\": \"Upstream aip_mos_ru_api with 1 main server created\",\n  \"ready_to_save\": true\n}}\n```\n\n### DELETE_LOCATION\n\nCheck `domains` array length:\n- **Multiple domains** → keep upstream, return warning\n- **Single domain** → safe to delete\n\n```json\n{{\n  \"status\": \"success\",\n  \"operation_type\": \"DELETE_LOCATION\",\n  \"upstream_name\": \"aip_mos_ru\",\n  \"action\": \"delete_upstream\",\n  \"explanation\": \"Upstream is used by only one domain, can be removed\",\n  \"ready_to_save\": true\n}}\n```\n\n## RULES\n\n✅ ALLOWED:\n- Modify `main.servers` or `backup.servers`\n- Create new upstreams (CREATE_LOCATION)\n- Recommend deletion (DELETE_LOCATION)\n- Point modifications (port, single IP, add/remove server)\n\n❌ FORBIDDEN:\n- Modify `domains`, `environment`, `system_id` (except defaults for new)\n- Delete upstream with multiple domains\n- Make changes when current == requested (return no_change instead)\n\n## VALIDATION\n\n- IP format: `XXX.XXX.XXX.XXX`\n- Port: `1-65535`, default `:80`\n- Min 1 server in main (recommended)\n- **Always compare before modifying**\n\n## AGENT1_DATA ENHANCED FORMAT\n\nFor better precision, agent1 should provide:\n\n```json\n{{\n  \"domain\": \"dchelper.mos.ru\",\n  \"modification_type\": \"change_port\",  // NEW FIELD\n  \"target_section\": \"main\",\n  \"upstreams\": [{{\n    \"upstream_type\": \"main\",\n    // For change_port:\n    \"new_port\": \"443\",\n    // For change_ip:\n    \"old_ip\": \"10.206.178.155\",\n    \"new_ip\": \"10.206.178.200\",\n    // For add_server:\n    \"servers_to_add\": [\"10.206.178.161:80\"],\n    // For remove_server:\n    \"servers_to_remove\": [\"10.206.178.155:80\"],\n    // For replace_all:\n    \"ip_addresses\": [\"10.1.1.1:80\", \"10.1.1.2:80\"]\n  }}]\n}}\n```\n\n## OUTPUT\n\nReturn ONLY valid JSON"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "upstreams": {
                "advanced": false,
                "display_name": "upstreams",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "upstreams",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-FdI1h",
        "measured": {
          "height": 523,
          "width": 320
        },
        "position": {
          "x": 9775.804122919457,
          "y": 3055.0158982557086
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "OpenAIModel-Ps7tU",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "openai",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "last_updated": "2025-11-03T16:58:41.808Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.000001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "TOKEN"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_CHAT_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_CHAT_MODEL_NAMES[0],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        logger.debug(f\"Executing request with model: {self.model_name}\")\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n        }\n\n        # TODO: Revisit if/once parameters are supported for reasoning models\n        unsupported_params_for_reasoning_models = [\"temperature\", \"seed\"]\n\n        if self.model_name not in OPENAI_REASONING_MODEL_NAMES:\n            parameters[\"temperature\"] = self.temperature if self.temperature is not None else 0.1\n            parameters[\"seed\"] = self.seed\n        else:\n            params_str = \", \".join(unsupported_params_for_reasoning_models)\n            logger.debug(f\"{self.model_name} is a reasoning model, {params_str} are not configurable. Ignoring.\")\n\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n            # Hide system_message for o1 models - currently unsupported\n            if field_value.startswith(\"o1\") and \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_CHAT_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n            if \"system_message\" in build_config:\n                build_config[\"system_message\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "external_options": {},
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-5",
                  "gpt-5-mini",
                  "gpt-5-nano",
                  "gpt-5-chat-latest",
                  "o1",
                  "o3-mini",
                  "o3",
                  "o3-pro",
                  "o4-mini",
                  "o4-mini-high"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "local_huggingface/Qwen3-32B"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:8000/v1"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are an nginx upstream configuration expert. You modify upstream configurations in `skdpu_http_upstreams.yml` based on validated user requests.\n⚠️ **CRITICAL**: You work with EXISTING upstream configurations. You manage backend server lists for upstreams."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.05
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1500
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-Ps7tU",
        "measured": {
          "height": 537,
          "width": 320
        },
        "position": {
          "x": 10200.601340074672,
          "y": 3063.595921567826
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LoopComponent-xg3V7",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "category": "logic",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.",
            "display_name": "Loop",
            "documentation": "https://docs.langflow.org/components-logic#loop",
            "edited": false,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "infinity",
            "key": "LoopComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": true,
                "cache": true,
                "display_name": "Item",
                "group_outputs": true,
                "method": "item_output",
                "name": "item",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Done",
                "group_outputs": true,
                "method": "done_output",
                "name": "done",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\n\n\nclass LoopComponent(Component):\n    display_name = \"Loop\"\n    description = (\n        \"Iterates over a list of Data objects, outputting one item at a time and aggregating results from loop inputs.\"\n    )\n    documentation: str = \"https://docs.langflow.org/components-logic#loop\"\n    icon = \"infinity\"\n\n    inputs = [\n        HandleInput(\n            name=\"data\",\n            display_name=\"Inputs\",\n            info=\"The initial list of Data objects or DataFrame to iterate over.\",\n            input_types=[\"DataFrame\"],\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Item\", name=\"item\", method=\"item_output\", allows_loop=True, group_outputs=True),\n        Output(display_name=\"Done\", name=\"done\", method=\"done_output\", group_outputs=True),\n    ]\n\n    def initialize_data(self) -> None:\n        \"\"\"Initialize the data list, context index, and aggregated list.\"\"\"\n        if self.ctx.get(f\"{self._id}_initialized\", False):\n            return\n\n        # Ensure data is a list of Data objects\n        data_list = self._validate_data(self.data)\n\n        # Store the initial data and context variables\n        self.update_ctx(\n            {\n                f\"{self._id}_data\": data_list,\n                f\"{self._id}_index\": 0,\n                f\"{self._id}_aggregated\": [],\n                f\"{self._id}_initialized\": True,\n            }\n        )\n\n    def _validate_data(self, data):\n        \"\"\"Validate and return a list of Data objects.\"\"\"\n        if isinstance(data, DataFrame):\n            return data.to_data_list()\n        if isinstance(data, Data):\n            return [data]\n        if isinstance(data, list) and all(isinstance(item, Data) for item in data):\n            return data\n        msg = \"The 'data' input must be a DataFrame, a list of Data objects, or a single Data object.\"\n        raise TypeError(msg)\n\n    def evaluate_stop_loop(self) -> bool:\n        \"\"\"Evaluate whether to stop item or done output.\"\"\"\n        current_index = self.ctx.get(f\"{self._id}_index\", 0)\n        data_length = len(self.ctx.get(f\"{self._id}_data\", []))\n        return current_index > data_length\n\n    def item_output(self) -> Data:\n        \"\"\"Output the next item in the list or stop if done.\"\"\"\n        self.initialize_data()\n        current_item = Data(text=\"\")\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n        else:\n            # Get data list and current index\n            data_list, current_index = self.loop_variables()\n            if current_index < len(data_list):\n                # Output current item and increment index\n                try:\n                    current_item = data_list[current_index]\n                except IndexError:\n                    current_item = Data(text=\"\")\n            self.aggregated_output()\n            self.update_ctx({f\"{self._id}_index\": current_index + 1})\n\n        # Now we need to update the dependencies for the next run\n        self.update_dependency()\n        return current_item\n\n    def update_dependency(self):\n        item_dependency_id = self.get_incoming_edge_by_target_param(\"item\")\n        if item_dependency_id not in self.graph.run_manager.run_predecessors[self._id]:\n            self.graph.run_manager.run_predecessors[self._id].append(item_dependency_id)\n\n    def done_output(self) -> DataFrame:\n        \"\"\"Trigger the done output when iteration is complete.\"\"\"\n        self.initialize_data()\n\n        if self.evaluate_stop_loop():\n            self.stop(\"item\")\n            self.start(\"done\")\n\n            aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n\n            return DataFrame(aggregated)\n        self.stop(\"done\")\n        return DataFrame([])\n\n    def loop_variables(self):\n        \"\"\"Retrieve loop variables from context.\"\"\"\n        return (\n            self.ctx.get(f\"{self._id}_data\", []),\n            self.ctx.get(f\"{self._id}_index\", 0),\n        )\n\n    def aggregated_output(self) -> list[Data]:\n        \"\"\"Return the aggregated list once all items are processed.\"\"\"\n        self.initialize_data()\n\n        # Get data list and aggregated list\n        data_list = self.ctx.get(f\"{self._id}_data\", [])\n        aggregated = self.ctx.get(f\"{self._id}_aggregated\", [])\n        loop_input = self.item\n        if loop_input is not None and not isinstance(loop_input, str) and len(aggregated) <= len(data_list):\n            aggregated.append(loop_input)\n            self.update_ctx({f\"{self._id}_aggregated\": aggregated})\n        return aggregated\n"
              },
              "data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "The initial list of Data objects or DataFrame to iterate over.",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "LoopComponent"
        },
        "dragging": false,
        "id": "LoopComponent-xg3V7",
        "measured": {
          "height": 241,
          "width": 320
        },
        "position": {
          "x": 8668.268312556545,
          "y": 3134.4830005403633
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UpstreamExtractorComponent-LZc0P",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Извлекает upstream данные из NGINX конфигов для Агента 4",
            "display_name": "Upstream Extractor",
            "documentation": "",
            "edited": true,
            "field_order": [
              "config_data",
              "mosru_path"
            ],
            "frozen": false,
            "icon": "database",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Upstream Data",
                "group_outputs": false,
                "hidden": null,
                "method": "process_upstream",
                "name": "upstream_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"\nUpstream Extractor Component for Langflow\nИзвлекает данные upstream из конфигов для операций MODIFY_UPSTREAM и DELETE_LOCATION\nРаботает с Data/DataFrame от Universal Search Config\n\"\"\"\n\nimport re\nimport os\nimport yaml\nimport json\nfrom typing import Optional, Dict, Any, List\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, MessageTextInput, Output\nfrom langflow.schema import Data\n\n\nclass UpstreamExtractorComponent(Component):\n    display_name = \"Upstream Extractor\"\n    description = \"Извлекает upstream данные из NGINX конфигов для Агента 4\"\n    icon = \"database\"\n\n    inputs = [\n        DataInput(\n            name=\"config_data\",\n            display_name=\"Config Data\",\n            info=\"Data/DataFrame от Universal Search Config\",\n            input_types=[\"Data\"]\n        ),\n        MessageTextInput(\n            name=\"mosru_path\",\n            display_name=\"MosRU Path\",\n            value=\"mosru_nginx/mos_ru_nginx\",\n            info=\"Базовый путь к конфигам MosRU\"\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Upstream Data\", name=\"upstream_data\", method=\"process_upstream\"),\n    ]\n\n    def extract_data_from_input(self) -> Dict[str, Any]:\n        \"\"\"\n        Извлекает данные из Data/DataFrame объекта\n        Обрабатывает все возможные форматы данных от Universal Search\n        \"\"\"\n        try:\n            self.log(f\"🔍 Input type: {type(self.config_data)}\")\n            self.log(f\"🔍 Input value preview: {str(self.config_data)[:200]}\")\n\n            # Если это Data объект от Langflow\n            if hasattr(self.config_data, 'data'):\n                self.log(\"📦 Found .data attribute\")\n                data = self.config_data.data\n\n                if isinstance(data, dict):\n                    self.log(f\"✅ Data is dict with keys: {list(data.keys())}\")\n                    return data\n                elif isinstance(data, str):\n                    self.log(\"🔄 Data is string, parsing JSON\")\n                    return json.loads(data)\n                elif isinstance(data, list) and len(data) > 0:\n                    self.log(\"📋 Data is list, taking first item\")\n                    return data[0] if isinstance(data[0], dict) else {}\n\n            # Если это dict напрямую\n            if isinstance(self.config_data, dict):\n                self.log(f\"✅ Direct dict with keys: {list(self.config_data.keys())}\")\n                return self.config_data\n\n            # Если это строка JSON\n            if isinstance(self.config_data, str):\n                self.log(\"🔄 String input, parsing JSON\")\n                return json.loads(self.config_data)\n\n            # Если это список\n            if isinstance(self.config_data, list) and len(self.config_data) > 0:\n                self.log(\"📋 List input, taking first item\")\n                first = self.config_data[0]\n                if hasattr(first, 'data'):\n                    return first.data\n                return first if isinstance(first, dict) else {}\n\n            self.log(f\"⚠️ Unexpected data type: {type(self.config_data)}\")\n            self.log(f\"⚠️ Data content: {self.config_data}\")\n            return {}\n\n        except Exception as e:\n            self.log(f\"❌ Error extracting data: {e}\")\n            import traceback\n            self.log(f\"Traceback: {traceback.format_exc()}\")\n            return {}\n\n    def find_proxy_pass(self, config_lines: List[str], location_path: str) -> Optional[str]:\n        \"\"\"\n        Находит proxy_pass для определенного location\n        Returns: upstream_name или None\n        \"\"\"\n        config_str = '\\n'.join(config_lines)\n\n        self.log(f\"🔍 Looking for proxy_pass in location: {location_path}\")\n        self.log(f\"📝 Config has {len(config_lines)} lines\")\n\n        # Нормализуем location path\n        location_normalized = location_path.strip().rstrip('/')\n\n        # Определяем тип match\n        exact_match = location_normalized.startswith('=')\n        if exact_match:\n            path = location_normalized[1:].strip().rstrip('/')\n        else:\n            path = location_normalized.rstrip('/')\n\n        # Для root location\n        if path == '' or path == '/':\n            path = '/'\n\n        path_escaped = re.escape(path) if path != '/' else '/'\n\n        # Паттерны для поиска (добавлена поддержка однострочного формата)\n        patterns = []\n\n        if exact_match:\n            patterns.extend([\n                # Многострочный формат\n                rf'location\\s*=\\s*{path_escaped}/?[\\s{{].*?proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n                # Однострочный формат: location / { proxy_pass http://upstream;}\n                rf'location\\s*=\\s*{path_escaped}/?[\\s]*\\{{\\s*proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n            ])\n        else:\n            if path == '/':\n                patterns.extend([\n                    # Многострочный формат\n                    r'location\\s+/\\s*\\{\\s*proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n                    r'location\\s+/\\s+\\{\\s*proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n                    # Однострочный формат: location / { proxy_pass http://upstream;}\n                    r'location\\s+/\\s*\\{\\s*proxy_pass\\s+(?:http|https)://([^/\\s;}}]+?)[;\\s}]',\n                    # Без пробела после {\n                    r'location\\s+/\\s*\\{{proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n                ])\n            else:\n                patterns.extend([\n                    # Многострочный формат\n                    rf'location\\s+{path_escaped}/?[\\s{{].*?proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)',\n                    # Однострочный формат\n                    rf'location\\s+{path_escaped}/?[\\s]*\\{{\\s*proxy_pass\\s+(?:http|https)://([^/\\s;}}]+?)[;\\s}}]',\n                ])\n\n        for i, pattern in enumerate(patterns):\n            self.log(f\"🔍 Trying pattern {i + 1}: {pattern[:80]}...\")\n            match = re.search(pattern, config_str, re.DOTALL | re.MULTILINE)\n            if match:\n                upstream = match.group(1).strip()\n                self.log(f\"✅ Found upstream: {upstream} for location: {location_path}\")\n                return upstream\n\n        # Дополнительный fallback: поиск в каждой строке отдельно\n        self.log(\"🔍 Trying line-by-line search as fallback...\")\n        for line in config_lines:\n            if f'location {path}' in line or f'location {path}/' in line:\n                # Ищем proxy_pass в этой же строке\n                proxy_match = re.search(r'proxy_pass\\s+(?:http|https)://([^/\\s;}}]+)', line)\n                if proxy_match:\n                    upstream = proxy_match.group(1).strip()\n                    self.log(f\"✅ Found upstream (line-by-line): {upstream}\")\n                    return upstream\n\n        self.log(f\"❌ No proxy_pass found for location: {location_path}\")\n        # Показываем строки для отладки\n        for i, line in enumerate(config_lines[:10]):\n            self.log(f\"  Line {i}: {line}\")\n\n        return None\n\n    def load_upstream_config(self, upstream_name: str, mosru_path: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Загружает конфигурацию upstream из skdpu_http_upstreams.yml\n        Возвращает структуру с main/backup servers\n        \"\"\"\n        skdpu_http_upstreams = f\"/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/skdpu_config/skdpu_http_upstreams.yml\"\n\n        self.log(f\"📂 Looking for upstream file: {skdpu_http_upstreams}\")\n\n        if not os.path.exists(skdpu_http_upstreams):\n            self.log(f\"❌ File not found: {skdpu_http_upstreams}\")\n            return None\n\n        try:\n            with open(skdpu_http_upstreams, 'r', encoding='utf-8') as f:\n                upstreams_data = yaml.safe_load(f)\n\n            self.log(f\"📄 YAML loaded, top-level keys: {list(upstreams_data.keys())[:10]}\")\n\n            # Ищем в секции nginx_http_upstreams\n            if 'nginx_http_upstreams' in upstreams_data:\n                upstreams = upstreams_data['nginx_http_upstreams']\n                self.log(f\"🔍 Found nginx_http_upstreams with {len(upstreams)} entries\")\n\n                if upstream_name in upstreams:\n                    upstream_config = upstreams[upstream_name]\n                    self.log(f\"✅ Found upstream config: {upstream_name}\")\n                    self.log(f\"📋 Config keys: {list(upstream_config.keys())}\")\n\n                    # Извлекаем IP-адреса из структуры\n                    result = {\n                        \"upstream_name\": upstream_name,\n                        \"main\": [],\n                        \"backup\": [],\n                        \"raw_config\": upstream_config  # Сохраняем полную конфигурацию\n                    }\n\n                    # Извлекаем main servers\n                    if 'main' in upstream_config and 'servers' in upstream_config['main']:\n                        main_servers = upstream_config['main']['servers']\n                        self.log(f\"📍 Main servers: {main_servers}\")\n                        # Извлекаем IP:PORT\n                        result['main'] = [self._parse_server_address(s) for s in main_servers]\n\n                    # Извлекаем backup servers\n                    if 'backup' in upstream_config and 'servers' in upstream_config['backup']:\n                        backup_servers = upstream_config['backup']['servers']\n                        self.log(f\"📍 Backup servers: {backup_servers}\")\n                        result['backup'] = [self._parse_server_address(s) for s in backup_servers]\n\n                    # Добавляем метаданные если есть\n                    if 'domains' in upstream_config:\n                        result['domains'] = upstream_config['domains']\n                    if 'system_id' in upstream_config:\n                        result['system_id'] = upstream_config['system_id']\n                    if 'environment' in upstream_config:\n                        result['environment'] = upstream_config['environment']\n\n                    self.log(f\"✅ Extracted IPs - Main: {result['main']}, Backup: {result['backup']}\")\n                    return result\n\n            # Проверка на top-level upstream (на случай другой структуры)\n            if upstream_name in upstreams_data:\n                self.log(f\"✅ Found upstream at top level: {upstream_name}\")\n                return self._process_upstream_structure(upstream_name, upstreams_data[upstream_name])\n\n            self.log(f\"❌ Upstream not found in YAML: {upstream_name}\")\n            return None\n\n        except Exception as e:\n            self.log(f\"❌ Error loading upstream config: {e}\")\n            import traceback\n            self.log(f\"Traceback: {traceback.format_exc()}\")\n            return None\n\n    def _parse_server_address(self, server: str) -> str:\n        \"\"\"\n        Парсит адрес сервера (может быть IP:PORT или просто IP)\n        Returns: IP address (без порта для единообразия)\n        \"\"\"\n        if ':' in server:\n            return server.split(':')[0]  # Возвращаем только IP\n        return server\n\n    def _process_upstream_structure(self, upstream_name: str, upstream_config: Dict) -> Dict[str, Any]:\n        \"\"\"\n        Обрабатывает структуру upstream и извлекает IP-адреса\n        \"\"\"\n        result = {\n            \"upstream_name\": upstream_name,\n            \"main\": [],\n            \"backup\": [],\n            \"raw_config\": upstream_config\n        }\n\n        if 'main' in upstream_config and 'servers' in upstream_config['main']:\n            result['main'] = [self._parse_server_address(s) for s in upstream_config['main']['servers']]\n\n        if 'backup' in upstream_config and 'servers' in upstream_config['backup']:\n            result['backup'] = [self._parse_server_address(s) for s in upstream_config['backup']['servers']]\n\n        # Копируем метаданные\n        for key in ['domains', 'system_id', 'environment']:\n            if key in upstream_config:\n                result[key] = upstream_config[key]\n\n        return result\n\n    def process_upstream(self) -> Data:\n        \"\"\"\n        Основной метод обработки - обрабатывает ВСЕ домены из agent1_data.payload\n        \"\"\"\n        try:\n            self.log(\"=\" * 50)\n            self.log(\"🚀 Starting Upstream Extractor processing\")\n\n            config_data = self.extract_data_from_input()\n\n            if not config_data:\n                return Data(data={\n                    \"status\": \"error\",\n                    \"operation\": \"UNKNOWN\",\n                    \"error_message\": \"Не удалось извлечь данные из config_data\",\n                    \"upstream_processing_needed\": False\n                })\n\n            status = config_data.get('status')\n            if status != 'success':\n                return Data(data={\n                    \"status\": \"error\",\n                    \"operation\": \"UNKNOWN\",\n                    \"error_message\": config_data.get('error_message', 'Config search failed'),\n                    \"upstream_processing_needed\": False\n                })\n\n            agent1_data = config_data.get('agent1_data', {})\n            operation = agent1_data.get('operation', config_data.get('operation', ''))\n\n            if operation not in ['MODIFY_UPSTREAM', 'DELETE_LOCATION', 'CREATE_LOCATION']:\n                return Data(data={\n                    \"status\": \"skipped\",\n                    \"operation\": operation,\n                    \"message\": f\"Операция {operation} не требует обработки upstream\",\n                    \"upstream_processing_needed\": False\n                })\n\n            # Для CREATE_LOCATION - проверяем, что location ещё не существует\n            if operation == 'CREATE_LOCATION':\n                domains = agent1_data.get('domains', [])\n                locations = agent1_data.get('locations', [])\n                all_configs = config_data.get('all_configs', [])\n\n                # Создаём маппинг domain -> config_block\n                domain_to_config = {}\n                for cfg in all_configs:\n                    for domain in cfg.get('matching_domains', []):\n                        if domain not in domain_to_config:\n                            domain_to_config[domain] = cfg.get('config_block', [])\n\n                # Проверяем, существует ли уже location\n                existing_locations = []\n                locations_to_create = []\n\n                for domain in domains:\n                    config_block = domain_to_config.get(domain, [])\n                    if not config_block:\n                        # Нет конфига - все locations можно создавать\n                        for location in locations:\n                            locations_to_create.append({\n                                \"domain\": domain,\n                                \"location\": location\n                            })\n                        continue\n\n                    config_str = '\\n'.join(config_block)\n                    for location in locations:\n                        # Нормализуем path\n                        path = location.strip().rstrip('/')\n                        if path == '':\n                            path = '/'\n\n                        # Проверяем наличие location в конфиге\n                        path_escaped = re.escape(path) if path != '/' else '/'\n                        patterns = [\n                            rf'location\\s+{path_escaped}\\s*\\{{',\n                            rf'location\\s+{path_escaped}/\\s*\\{{',\n                            rf'location\\s+=\\s*{path_escaped}\\s*\\{{',\n                            rf'location\\s+=\\s*{path_escaped}/\\s*\\{{',\n                        ]\n\n                        location_exists = False\n                        for pattern in patterns:\n                            if re.search(pattern, config_str):\n                                location_exists = True\n                                break\n\n                        if location_exists:\n                            existing_locations.append({\n                                \"domain\": domain,\n                                \"location\": location\n                            })\n                            self.log(f\"⚠️ Location {location} уже существует для домена {domain} - ПРОПУСКАЕМ\")\n                        else:\n                            locations_to_create.append({\n                                \"domain\": domain,\n                                \"location\": location\n                            })\n                            self.log(f\"✅ Location {location} для домена {domain} - будет создан\")\n\n                # Формируем warnings для существующих locations\n                warnings = []\n                for existing in existing_locations:\n                    warnings.append({\n                        \"type\": \"LOCATION_EXISTS\",\n                        \"domain\": existing[\"domain\"],\n                        \"location\": existing[\"location\"],\n                        \"message\": f\"Location {existing['location']} уже существует для {existing['domain']} - пропущен\"\n                    })\n\n                # Если НЕТ locations для создания - тогда ошибка\n                if not locations_to_create:\n                    self.log(f\"❌ CREATE_LOCATION: все locations уже существуют\")\n                    return Data(data={\n                        \"status\": \"error\",\n                        \"operation\": \"CREATE_LOCATION\",\n                        \"error_message\": \"Все указанные locations уже существуют\",\n                        \"existing_locations\": existing_locations,\n                        \"upstream_processing_needed\": False,\n                        \"message\": \"Невозможно создать locations - все они уже существуют в конфигурации\"\n                    })\n\n                # Есть locations для создания - продолжаем (с warnings если часть пропущена)\n                self.log(\n                    f\"✅ CREATE_LOCATION: {len(locations_to_create)} locations будет создано, {len(existing_locations)} пропущено\")\n\n                # Обновляем agent1_data с отфильтрованными locations\n                filtered_agent1_data = agent1_data.copy()\n                # Извлекаем уникальные locations для создания\n                filtered_locations = list(set([loc[\"location\"] for loc in locations_to_create]))\n                filtered_agent1_data['locations'] = filtered_locations\n                filtered_agent1_data['locations_to_create'] = locations_to_create\n                filtered_agent1_data['skipped_locations'] = existing_locations\n\n                return Data(data={\n                    \"status\": \"success\",\n                    \"operation\": \"CREATE_LOCATION\",\n                    \"message\": f\"Операция CREATE_LOCATION готова к выполнению для {len(locations_to_create)} locations\",\n                    \"upstream_processing_needed\": False,\n                    \"upstreams\": [],\n                    \"agent1_data\": filtered_agent1_data,\n                    \"full_config_data\": config_data,\n                    \"found_in_multiple_dc\": config_data.get('found_in_multiple_dc', False),\n                    \"domains_in_multiple_dc\": config_data.get('domains_in_multiple_dc', []),\n                    \"domain_dc_mapping\": config_data.get('domain_dc_mapping', {}),\n                    \"unique_dcs\": config_data.get('unique_dcs', []),\n                    \"dc_count\": config_data.get('dc_count', 1),\n                    \"locations_to_create\": locations_to_create,\n                    \"skipped_locations\": existing_locations,\n                    \"warnings\": warnings,\n                    \"has_warnings\": len(warnings) > 0\n                })\n\n                # Получаем информацию о мульти-ЦОД\n\n            # Получаем информацию о мульти-ЦОД\n            found_in_multiple_dc = config_data.get('found_in_multiple_dc', False)\n            domains_in_multiple_dc = config_data.get('domains_in_multiple_dc', [])\n            domain_dc_mapping = config_data.get('domain_dc_mapping', {})\n            unique_dcs = config_data.get('unique_dcs', [])\n\n            # Получаем domains и locations из agent1_data (новая структура)\n            domains = agent1_data.get('domains', [])\n            locations = agent1_data.get('locations', [])\n\n            self.log(f\"📋 Processing domains: {domains}\")\n            self.log(f\"📍 Processing locations: {locations}\")\n\n            all_configs = config_data.get('all_configs', [])\n\n            # Создаём маппинг domain -> config_block\n            domain_to_config = {}\n            domain_to_config_info = {}\n\n            for cfg in all_configs:\n                for domain in cfg.get('matching_domains', []):\n                    if domain not in domain_to_config:\n                        domain_to_config[domain] = cfg.get('config_block', [])\n                        domain_to_config_info[domain] = {\n                            'config_file': cfg.get('config_file', ''),\n                            'config_key': cfg.get('config_key', ''),\n                            'folder': cfg.get('folder', ''),\n                            'inferred_dc': cfg.get('inferred_dc', [])\n                        }\n\n            self.log(f\"📋 Domain to config mapping: {list(domain_to_config.keys())}\")\n\n            upstreams = []\n            warnings = []\n\n            # Генерируем warnings для доменов в нескольких ЦОД\n            if found_in_multiple_dc and domains_in_multiple_dc:\n                for domain in domains_in_multiple_dc:\n                    dcs = domain_dc_mapping.get(domain, [])\n                    warning_msg = f\"Домен {domain} найден в нескольких ЦОД: {', '.join(dcs)}. Убедитесь, что изменения применяются ко всем площадкам.\"\n                    warnings.append({\n                        \"type\": \"MULTI_DC\",\n                        \"domain\": domain,\n                        \"datacenters\": dcs,\n                        \"message\": warning_msg\n                    })\n                    self.log(f\"⚠️ WARNING: {warning_msg}\")\n\n            # Обрабатываем каждую комбинацию domain x location\n            for domain in domains:\n                for location in locations:\n                    self.log(f\"🔍 Processing domain: {domain}, location: {location}\")\n\n                    # Находим config_block для этого домена\n                    config_block = domain_to_config.get(domain, [])\n                    config_info = domain_to_config_info.get(domain, {})\n\n                    if not config_block:\n                        self.log(f\"⚠️ No config_block found for domain: {domain}\")\n                        warnings.append({\n                            \"type\": \"NO_CONFIG\",\n                            \"domain\": domain,\n                            \"message\": f\"Не найден конфиг для домена {domain}\"\n                        })\n                        continue\n\n                    # Ищем proxy_pass\n                    upstream_name = self.find_proxy_pass(config_block, location)\n\n                    if upstream_name:\n                        upstream_config = self.load_upstream_config(upstream_name, self.mosru_path)\n                        if upstream_config:\n                            upstream_entry = {\n                                \"domain\": domain,\n                                \"location\": location,\n                                \"upstream_name\": upstream_name,\n                                \"upstream_config\": upstream_config,\n                                \"upstream_yaml_block\": yaml.dump(\n                                    {upstream_name: upstream_config.get('raw_config', upstream_config)},\n                                    default_flow_style=False,\n                                    allow_unicode=True,\n                                    sort_keys=False\n                                ),\n                                \"config_info\": config_info,\n                                # IP-адреса для удобства\n                                \"main_ips\": upstream_config.get('main', []),\n                                \"backup_ips\": upstream_config.get('backup', [])\n                            }\n\n                            # Добавляем инфо о ЦОД если домен в нескольких\n                            if domain in domains_in_multiple_dc:\n                                upstream_entry[\"multi_dc\"] = True\n                                upstream_entry[\"datacenters\"] = domain_dc_mapping.get(domain, [])\n\n                            upstreams.append(upstream_entry)\n                            self.log(f\"✅ Found upstream for {domain}{location}: {upstream_name}\")\n                            self.log(f\"   Main IPs: {upstream_config.get('main', [])}\")\n                            self.log(f\"   Backup IPs: {upstream_config.get('backup', [])}\")\n                        else:\n                            self.log(f\"⚠️ Upstream config not found in YAML: {upstream_name}\")\n                            warnings.append({\n                                \"type\": \"UPSTREAM_NOT_FOUND\",\n                                \"domain\": domain,\n                                \"location\": location,\n                                \"upstream_name\": upstream_name,\n                                \"message\": f\"Upstream {upstream_name} не найден в skdpu_http_upstreams.yml\"\n                            })\n                    else:\n                        self.log(f\"⚠️ No proxy_pass found for {domain}{location}\")\n                        warnings.append({\n                            \"type\": \"NO_PROXY_PASS\",\n                            \"domain\": domain,\n                            \"location\": location,\n                            \"message\": f\"Не найден proxy_pass для {domain}{location}\"\n                        })\n\n            if not upstreams:\n                return Data(data={\n                    \"status\": \"error\",\n                    \"operation\": operation,\n                    \"error_message\": \"Не найдены upstreams для указанных доменов\",\n                    \"upstream_processing_needed\": False,\n                    \"processed_domains\": domains,\n                    \"warnings\": warnings\n                })\n\n            result = {\n                \"status\": \"success\",\n                \"operation\": operation,\n                \"upstreams\": upstreams,\n                \"upstream_processing_needed\": True,\n                \"agent1_data\": agent1_data,\n                \"full_config_data\": config_data,\n                # Мульти-ЦОД информация\n                \"found_in_multiple_dc\": found_in_multiple_dc,\n                \"domains_in_multiple_dc\": domains_in_multiple_dc,\n                \"domain_dc_mapping\": domain_dc_mapping,\n                \"unique_dcs\": unique_dcs,\n                \"dc_count\": config_data.get('dc_count', 1),\n                # Warnings\n                \"warnings\": warnings,\n                \"has_warnings\": len(warnings) > 0\n            }\n\n            self.log(f\"✅ SUCCESS! Found {len(upstreams)} upstreams\")\n            if warnings:\n                self.log(f\"⚠️ Generated {len(warnings)} warnings\")\n            return Data(data=result)\n\n        except Exception as e:\n            import traceback\n            self.log(f\"❌ CRITICAL ERROR: {str(e)}\\n{traceback.format_exc()}\")\n            return Data(data={\n                \"status\": \"error\",\n                \"operation\": \"UNKNOWN\",\n                \"error_message\": f\"Ошибка обработки: {str(e)}\",\n                \"upstream_processing_needed\": False\n            })"
              },
              "config_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Config Data",
                "dynamic": false,
                "info": "Data/DataFrame от Universal Search Config",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "config_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mosru_path": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "MosRU Path",
                "dynamic": false,
                "info": "Базовый путь к конфигам MosRU",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "mosru_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "config_file_path",
          "showNode": true,
          "type": "UpstreamExtractorComponent"
        },
        "dragging": false,
        "id": "UpstreamExtractorComponent-LZc0P",
        "measured": {
          "height": 263,
          "width": 320
        },
        "position": {
          "x": 6859.838783115813,
          "y": 2479.150568201105
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UpstreamConfigBlockSplitter-6qh1v",
          "node": {
            "base_classes": [
              "Data",
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Splits upstream blocks by domain AND location, skips multi-DC domains with warnings",
            "display_name": "Upstream Config Block Splitter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "selected_block"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Config Items DataFrame",
                "group_outputs": false,
                "hidden": null,
                "method": "build_config_dataframe",
                "name": "config_items_df",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Total Count",
                "group_outputs": false,
                "hidden": null,
                "method": "build_total_count",
                "name": "total_count",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Metadata",
                "group_outputs": false,
                "hidden": null,
                "method": "build_metadata",
                "name": "metadata",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Warnings",
                "group_outputs": false,
                "hidden": null,
                "method": "build_warnings",
                "name": "warnings_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.message import Message\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\nimport json\nimport pandas as pd\nfrom typing import Union, List, Dict, Any\n\n\nclass UpstreamConfigBlockSplitter(Component):\n    \"\"\"\n    Splits upstream config blocks into DataFrame for Loop processing.\n    Includes location_path, operation, upstreams, and agent1_data.\n    Skips domains in multiple DCs and generates warnings.\n    Now also splits by location for granular processing.\n    \"\"\"\n\n    display_name = \"Upstream Config Block Splitter\"\n    description = \"Splits upstream blocks by domain AND location, skips multi-DC domains with warnings\"\n    documentation = \"\"\n    icon = \"split\"\n\n    inputs = [\n        HandleInput(\n            name=\"selected_block\",\n            display_name=\"Selected Block\",\n            input_types=[\"Message\", \"Data\", \"dict\"],\n            info=\"Output from UpstreamExtractor containing upstreams\",\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Config Items DataFrame\",\n            name=\"config_items_df\",\n            info=\"DataFrame with location_path, operation, upstreams, agent1_data\",\n            method=\"build_config_dataframe\",\n        ),\n        Output(\n            display_name=\"Total Count\",\n            name=\"total_count\",\n            info=\"Total number of blocks to process\",\n            method=\"build_total_count\",\n        ),\n        Output(\n            display_name=\"Metadata\",\n            name=\"metadata\",\n            info=\"Metadata including warnings for multi-DC domains\",\n            method=\"build_metadata\",\n        ),\n        Output(\n            display_name=\"Warnings\",\n            name=\"warnings_output\",\n            info=\"All warnings including multi-DC skipped domains\",\n            method=\"build_warnings\",\n        ),\n    ]\n\n    def process_input_data(self, data: Union[Message, Data, dict, str]) -> dict:\n        \"\"\"Convert input to dictionary format\"\"\"\n        try:\n            if isinstance(data, Message):\n                text = data.text if hasattr(data, 'text') else str(data)\n                return json.loads(text)\n            elif isinstance(data, Data):\n                if hasattr(data, 'data'):\n                    data_content = data.data\n                    if isinstance(data_content, str):\n                        return json.loads(data_content)\n                    return data_content\n                elif hasattr(data, 'to_dict'):\n                    return data.to_dict()\n                else:\n                    return dict(data)\n            elif isinstance(data, dict):\n                return data\n            elif isinstance(data, str):\n                return json.loads(data)\n            else:\n                raise ValueError(f\"Unexpected input type: {type(data)}\")\n        except json.JSONDecodeError as e:\n            self.log(f\"JSON decode error: {str(e)}\")\n            raise ValueError(f\"Invalid JSON in input: {str(e)}\")\n        except Exception as e:\n            self.log(f\"Error processing input: {str(e)}\")\n            raise\n\n    def _get_domain_location_key(self, domain: str, location: str) -> str:\n        \"\"\"Generate unique key for domain+location combination\"\"\"\n        return f\"{domain}::{location}\"\n\n    def _check_multi_location_conflicts(\n            self,\n            blocks: List[Dict],\n            input_data: dict\n    ) -> tuple[List[Dict], List[Dict], Dict[str, List[str]]]:\n        \"\"\"\n        Check for locations that appear in multiple configurations.\n        Returns: (filtered_blocks, warnings, location_dc_mapping)\n        \"\"\"\n        warnings = []\n\n        # Получаем информацию о multi-location если есть\n        locations_in_multiple_dc = set(input_data.get('locations_in_multiple_dc', []))\n        location_dc_mapping = input_data.get('location_dc_mapping', {})\n\n        # Группируем блоки по domain+location\n        domain_location_blocks: Dict[str, List[Dict]] = {}\n\n        for block in blocks:\n            if not isinstance(block, dict):\n                self.log(f\"Warning: block is not a dict, skipping: {type(block)}\")\n                continue\n                \n            domain = block.get('domain', '')\n            location = block.get('location_path', block.get('location', '/'))\n            key = self._get_domain_location_key(domain, location)\n\n            if key not in domain_location_blocks:\n                domain_location_blocks[key] = []\n            domain_location_blocks[key].append(block)\n\n        # Проверяем конфликты\n        filtered_blocks = []\n        processed_keys = set()\n\n        for key, key_blocks in domain_location_blocks.items():\n            domain, location = key.split('::') if '::' in key else (key, '/')\n\n            # Проверка на multi-location (локейшен в нескольких конфигурациях)\n            if key in locations_in_multiple_dc or len(key_blocks) > 1:\n                dcs = location_dc_mapping.get(key, [])\n\n                # Если блоков больше одного для одной комбинации domain+location\n                if len(key_blocks) > 1:\n                    warning = {\n                        \"type\": \"MULTI_CONFIG_LOCATION\",\n                        \"domain\": domain,\n                        \"location\": location,\n                        \"configs_count\": len(key_blocks),\n                        \"message\": f\"⚠️ Локейшен {location} для домена {domain} найден в {len(key_blocks)} конфигурациях. Требуется выбор конкретной конфигурации.\",\n                        \"action_required\": True\n                    }\n                    warnings.append(warning)\n                    self.log(f\"⚠️ MULTI-CONFIG: {domain}{location} found in {len(key_blocks)} configs\")\n                    continue\n\n                # Если локейшен в нескольких ЦОД\n                if dcs and len(dcs) > 1:\n                    warning = {\n                        \"type\": \"MULTI_DC_LOCATION\",\n                        \"domain\": domain,\n                        \"location\": location,\n                        \"datacenters\": dcs,\n                        \"message\": f\"⚠️ Локейшен {location} для домена {domain} найден в нескольких ЦОД ({', '.join(dcs)}). Требуется ручная обработка.\",\n                        \"action_required\": True\n                    }\n                    warnings.append(warning)\n                    self.log(f\"⚠️ MULTI-DC LOCATION: {domain}{location} in DCs: {dcs}\")\n                    continue\n\n            # Добавляем первый блок для этой комбинации\n            if key not in processed_keys:\n                filtered_blocks.append(key_blocks[0])\n                processed_keys.add(key)\n\n        return filtered_blocks, warnings, location_dc_mapping\n\n    def _build_payload_from_agent1_data(self, agent1_data: dict) -> List[Dict]:\n        \"\"\"\n        Build payload list from agent1_data when payload field is missing.\n        Handles different agent1_data structures.\n        \"\"\"\n        payload = []\n        \n        # Get domains - support both 'domain' and 'domains'\n        domains = agent1_data.get('domains', [])\n        single_domain = agent1_data.get('domain', '')\n        if single_domain and single_domain not in domains:\n            domains.append(single_domain)\n        \n        if not domains:\n            return payload\n            \n        # Get locations - support both 'location' and 'locations'\n        locations = agent1_data.get('locations', [])\n        single_location = agent1_data.get('location', '')\n        if single_location and single_location not in locations:\n            locations.insert(0, single_location)\n        \n        if not locations:\n            locations = ['/']\n            \n        # Get requested upstreams\n        requested_upstreams = agent1_data.get('upstreams', [])\n        \n        # Build payload for each domain+location combination\n        for domain in domains:\n            for location in locations:\n                payload.append({\n                    'domain': domain,\n                    'location': location,\n                    'upstreams': requested_upstreams,\n                    'parameters': agent1_data.get('parameters', []),\n                    'location_parameters': agent1_data.get('location_parameters', []),\n                    'server_block_parameters': agent1_data.get('server_block_parameters', []),\n                    'kms_mentioned': agent1_data.get('kms_mentioned', False),\n                    'kms_locations': agent1_data.get('kms_locations', []),\n                    'public_locations': agent1_data.get('public_locations', []),\n                    'location_match': agent1_data.get('location_match', 'prefix'),\n                    'preserve_directives': agent1_data.get('preserve_directives', True),\n                    'from_location': agent1_data.get('from_location'),\n                    'to_location': agent1_data.get('to_location'),\n                    'confidence': agent1_data.get('confidence', 0),\n                    'warnings': agent1_data.get('warnings', []),\n                    'ambiguities': agent1_data.get('ambiguities', []),\n                })\n        \n        return payload\n\n    def extract_config_blocks(self, input_data: dict) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n        \"\"\"\n        Extract config blocks from input data.\n        Returns tuple: (blocks_to_process, warnings)\n        Skips domains that are in multiple DCs.\n        Now also handles location-level splitting.\n        \"\"\"\n\n        warnings = input_data.get('warnings', []).copy() if isinstance(input_data.get('warnings'), list) else []\n\n        # Получаем информацию о multi-DC\n        domains_in_multiple_dc = set(input_data.get('domains_in_multiple_dc', []))\n        domain_dc_mapping = input_data.get('domain_dc_mapping', {})\n\n        self.log(f\"🔍 Domains in multiple DC: {domains_in_multiple_dc}\")\n\n        # Специальная обработка для CREATE_LOCATION\n        operation = input_data.get('operation', '')\n        if operation == 'CREATE_LOCATION':\n            self.log(\"📝 Processing CREATE_LOCATION - no existing upstreams needed\")\n\n            agent1_data = input_data.get('agent1_data', {})\n\n            # Исправление: поддержка и domain, и domains\n            domain = agent1_data.get('domain', '')\n            if not domain:\n                domains_list = agent1_data.get('domains', [])\n                domain = domains_list[0] if domains_list else ''\n\n            # Исправление: убираем дефолтный '/'\n            primary_location = agent1_data.get('location')  # без дефолта\n            additional_locations = agent1_data.get('locations', [])\n\n            all_locations = []\n            if primary_location:\n                all_locations.append(primary_location)\n            all_locations.extend([loc for loc in additional_locations if loc and loc not in all_locations])\n\n            if not all_locations:\n                all_locations = ['/']\n\n            requested_upstreams = agent1_data.get('upstreams', [])\n\n            # Проверка на multi-DC для домена\n            if domain in domains_in_multiple_dc:\n                dcs = domain_dc_mapping.get(domain, [])\n                warning = {\n                    \"type\": \"MULTI_DC_SKIPPED\",\n                    \"domain\": domain,\n                    \"locations\": all_locations,\n                    \"datacenters\": dcs,\n                    \"message\": f\"⚠️ Домен {domain} пропущен: найден в нескольких ЦОД ({', '.join(dcs)}). Требуется ручная обработка.\",\n                    \"action_required\": True\n                }\n                warnings.append(warning)\n                self.log(f\"⚠️ SKIPPED: {domain} is in multiple DCs: {dcs}\")\n                return [], warnings\n\n            # Создаём отдельный блок для каждого локейшена\n            blocks = []\n            for location in all_locations:\n                block = {\n                    'location_path': location,\n                    'domain': domain,\n                    'operation': 'CREATE_LOCATION',\n                    'upstream_name': '',\n                    'upstream_config': {},\n                    'from_location': None,\n                    'to_location': None,\n                    'upstreams': [],\n                    'payload_item': {\n                        'domain': domain,\n                        'location': location,\n                        'upstreams': requested_upstreams,\n                        'parameters': agent1_data.get('parameters', []),\n                        'location_parameters': agent1_data.get('location_parameters', []),\n                        'server_block_parameters': agent1_data.get('server_block_parameters', []),\n                        'kms_mentioned': agent1_data.get('kms_mentioned', False),\n                        'kms_locations': agent1_data.get('kms_locations', []),\n                        'public_locations': agent1_data.get('public_locations', []),\n                        'location_match': agent1_data.get('location_match', 'prefix'),\n                    },\n                    'requested_upstreams': requested_upstreams,\n                }\n                blocks.append(block)\n                self.log(f\"✅ Created block for CREATE_LOCATION: {domain}{location}\")\n\n            return blocks, warnings\n\n        # Сначала пробуем найти selected_blocks (старый формат)\n        if 'selected_blocks' in input_data:\n            blocks = input_data['selected_blocks']\n            if isinstance(blocks, list):\n                filtered_blocks, dc_warnings = self._filter_multi_dc_blocks(\n                    blocks, domains_in_multiple_dc, domain_dc_mapping, warnings\n                )\n                # Дополнительно проверяем на конфликты локейшенов\n                final_blocks, loc_warnings, _ = self._check_multi_location_conflicts(filtered_blocks, input_data)\n                return final_blocks, dc_warnings + loc_warnings\n            elif isinstance(blocks, dict):\n                filtered_blocks, dc_warnings = self._filter_multi_dc_blocks(\n                    [blocks], domains_in_multiple_dc, domain_dc_mapping, warnings\n                )\n                final_blocks, loc_warnings, _ = self._check_multi_location_conflicts(filtered_blocks, input_data)\n                return final_blocks, dc_warnings + loc_warnings\n\n        # Если есть массив upstreams на верхнем уровне (новый формат от UpstreamExtractor)\n        if 'upstreams' in input_data and isinstance(input_data['upstreams'], list):\n            blocks = []\n            operation = input_data.get('operation', 'MODIFY_UPSTREAM')\n\n            agent1_data = input_data.get('agent1_data', {})\n            \n            # Пробуем получить payload, если нет - строим из agent1_data\n            payload = agent1_data.get('payload', [])\n            if not payload:\n                payload = self._build_payload_from_agent1_data(agent1_data)\n                self.log(f\"📋 Built payload from agent1_data: {len(payload)} items\")\n            else:\n                self.log(f\"📋 Found {len(payload)} items in agent1_data.payload\")\n\n            # Создаём маппинг domain+location -> payload_item\n            domain_location_to_payload: Dict[str, Dict] = {}\n            for item in payload:\n                if not isinstance(item, dict):\n                    continue\n                domain = item.get('domain', '')\n                location = item.get('location', '/')\n                if domain:\n                    key = self._get_domain_location_key(domain, location)\n                    domain_location_to_payload[key] = item\n\n            # Группируем upstreams по domain+location\n            domain_location_upstreams: Dict[str, List[Dict]] = {}\n\n            for upstream in input_data['upstreams']:\n                if not isinstance(upstream, dict):\n                    self.log(f\"Warning: upstream is not a dict, skipping: {type(upstream)}\")\n                    continue\n                    \n                domain = upstream.get('domain', '')\n                location = upstream.get('location', '/')\n\n                # ПРОВЕРКА НА MULTI-DC для домена\n                if domain in domains_in_multiple_dc:\n                    dcs = domain_dc_mapping.get(domain, [])\n                    warning = {\n                        \"type\": \"MULTI_DC_SKIPPED\",\n                        \"domain\": domain,\n                        \"location\": location,\n                        \"datacenters\": dcs,\n                        \"upstream_name\": upstream.get('upstream_name', ''),\n                        \"message\": f\"⚠️ Домен {domain} пропущен: найден в нескольких ЦОД ({', '.join(dcs)}). Требуется ручная обработка или выбор конкретного ЦОД.\",\n                        \"action_required\": True\n                    }\n                    warnings.append(warning)\n                    self.log(f\"⚠️ SKIPPED: {domain} is in multiple DCs: {dcs}\")\n                    continue\n\n                key = self._get_domain_location_key(domain, location)\n                if key not in domain_location_upstreams:\n                    domain_location_upstreams[key] = []\n                domain_location_upstreams[key].append(upstream)\n\n            # Создаём блок для каждой уникальной комбинации domain+location\n            for key, upstreams_list in domain_location_upstreams.items():\n                domain, location = key.split('::') if '::' in key else (key, '/')\n\n                # Находим соответствующий payload item\n                payload_item = domain_location_to_payload.get(key, {})\n\n                # Если нет точного совпадения, ищем по домену\n                if not payload_item:\n                    for item in payload:\n                        if isinstance(item, dict) and item.get('domain') == domain:\n                            payload_item = item\n                            break\n\n                from_location = payload_item.get('from_location') if isinstance(payload_item, dict) else None\n                to_location = payload_item.get('to_location') if isinstance(payload_item, dict) else None\n                requested_upstreams = payload_item.get('upstreams', []) if isinstance(payload_item, dict) else []\n\n                # Берём первый upstream для основной информации\n                primary_upstream = upstreams_list[0] if upstreams_list else {}\n\n                block = {\n                    'location_path': location,\n                    'domain': domain,\n                    'operation': operation,\n                    'upstream_name': primary_upstream.get('upstream_name', '') if isinstance(primary_upstream, dict) else '',\n                    'upstream_config': primary_upstream.get('upstream_config', {}) if isinstance(primary_upstream, dict) else {},\n                    'from_location': from_location,\n                    'to_location': to_location,\n                    'upstreams': upstreams_list,  # Все upstreams для этой комбинации\n                    'payload_item': payload_item,\n                    'requested_upstreams': requested_upstreams,\n                    'config_info': primary_upstream.get('config_info', {}) if isinstance(primary_upstream, dict) else {},\n                    'upstreams_count': len(upstreams_list),  # Количество upstreams для этого локейшена\n                }\n                blocks.append(block)\n                self.log(f\"✅ Added block for {domain}{location}: {len(upstreams_list)} upstream(s)\")\n\n            # Проверяем на конфликты локейшенов\n            final_blocks, loc_warnings, _ = self._check_multi_location_conflicts(blocks, input_data)\n            warnings.extend(loc_warnings)\n\n            self.log(\n                f\"📊 Extracted {len(final_blocks)} blocks by domain+location (skipped {len(domains_in_multiple_dc)} multi-DC domains)\")\n            return final_blocks, warnings\n\n        # Пробуем найти в поле selected_block\n        if 'selected_block' in input_data:\n            block_data = input_data['selected_block']\n            if isinstance(block_data, list):\n                filtered_blocks, dc_warnings = self._filter_multi_dc_blocks(\n                    block_data, domains_in_multiple_dc, domain_dc_mapping, warnings\n                )\n                final_blocks, loc_warnings, _ = self._check_multi_location_conflicts(filtered_blocks, input_data)\n                return final_blocks, dc_warnings + loc_warnings\n            elif isinstance(block_data, dict):\n                if 'selected_blocks' in block_data:\n                    filtered_blocks, dc_warnings = self._filter_multi_dc_blocks(\n                        block_data['selected_blocks'],\n                        domains_in_multiple_dc,\n                        domain_dc_mapping,\n                        warnings\n                    )\n                    final_blocks, loc_warnings, _ = self._check_multi_location_conflicts(filtered_blocks, input_data)\n                    return final_blocks, dc_warnings + loc_warnings\n                elif 'upstreams' in block_data:\n                    return self.extract_config_blocks(block_data)\n\n        self.log(\"⚠️ Warning: No config blocks found in input data\")\n        return [], warnings\n\n    def _filter_multi_dc_blocks(\n            self,\n            blocks: List[Dict],\n            domains_in_multiple_dc: set,\n            domain_dc_mapping: dict,\n            warnings: List[Dict]\n    ) -> tuple[List[Dict], List[Dict]]:\n        \"\"\"Filter out blocks for domains in multiple DCs\"\"\"\n        filtered_blocks = []\n\n        for block in blocks:\n            if not isinstance(block, dict):\n                self.log(f\"Warning: block is not a dict in _filter_multi_dc_blocks, skipping: {type(block)}\")\n                continue\n                \n            domain = block.get('domain', '')\n\n            if domain in domains_in_multiple_dc:\n                dcs = domain_dc_mapping.get(domain, [])\n                warning = {\n                    \"type\": \"MULTI_DC_SKIPPED\",\n                    \"domain\": domain,\n                    \"location\": block.get('location_path', block.get('location', '/')),\n                    \"datacenters\": dcs,\n                    \"message\": f\"⚠️ Домен {domain} пропущен: найден в нескольких ЦОД ({', '.join(dcs)}). Требуется ручная обработка.\",\n                    \"action_required\": True\n                }\n                warnings.append(warning)\n                self.log(f\"⚠️ SKIPPED: {domain} is in multiple DCs: {dcs}\")\n            else:\n                filtered_blocks.append(block)\n\n        return filtered_blocks, warnings\n\n    def _extract_upstream_data_for_json(self, upstreams_data: List) -> str:\n        \"\"\"\n        Safely extract upstream data and convert to JSON string.\n        Handles different upstream data structures.\n        \"\"\"\n        if not upstreams_data:\n            return json.dumps({}, ensure_ascii=False)\n            \n        if not isinstance(upstreams_data, list):\n            return json.dumps(upstreams_data, ensure_ascii=False)\n        \n        # Check if first item is a dict with upstream_config\n        first_item = upstreams_data[0] if upstreams_data else None\n        \n        if not isinstance(first_item, dict):\n            return json.dumps(upstreams_data, ensure_ascii=False)\n        \n        # Check for upstream_config structure\n        if 'upstream_config' in first_item:\n            if len(upstreams_data) > 1:\n                # Multiple upstreams for one location\n                agent_upstream_data = {\n                    'upstreams_count': len(upstreams_data),\n                    'upstreams': []\n                }\n                for upstream_obj in upstreams_data:\n                    if not isinstance(upstream_obj, dict):\n                        continue\n                    upstream_config = upstream_obj.get('upstream_config', {})\n                    if not isinstance(upstream_config, dict):\n                        upstream_config = {}\n                    \n                    main_data = upstream_config.get('main', {})\n                    backup_data = upstream_config.get('backup', {})\n                    \n                    # Handle both list and dict formats for main/backup\n                    if isinstance(main_data, dict):\n                        main_servers = main_data.get('servers', [])\n                    elif isinstance(main_data, list):\n                        main_servers = main_data\n                    else:\n                        main_servers = []\n                        \n                    if isinstance(backup_data, dict):\n                        backup_servers = backup_data.get('servers', [])\n                    elif isinstance(backup_data, list):\n                        backup_servers = backup_data\n                    else:\n                        backup_servers = []\n                    \n                    agent_upstream_data['upstreams'].append({\n                        'upstream_name': upstream_obj.get('upstream_name', ''),\n                        'main_servers': main_servers,\n                        'backup_servers': backup_servers,\n                        'domains': upstream_config.get('domains', []),\n                        'system_id': upstream_config.get('system_id', ''),\n                        'environment': upstream_config.get('environment', ''),\n                    })\n                return json.dumps(agent_upstream_data, ensure_ascii=False)\n            else:\n                # Single upstream\n                upstream_obj = first_item\n                upstream_config = upstream_obj.get('upstream_config', {})\n                if not isinstance(upstream_config, dict):\n                    upstream_config = {}\n                \n                main_data = upstream_config.get('main', {})\n                backup_data = upstream_config.get('backup', {})\n                \n                # Handle both list and dict formats for main/backup\n                if isinstance(main_data, dict):\n                    main_servers = main_data.get('servers', [])\n                elif isinstance(main_data, list):\n                    main_servers = main_data\n                else:\n                    main_servers = []\n                    \n                if isinstance(backup_data, dict):\n                    backup_servers = backup_data.get('servers', [])\n                elif isinstance(backup_data, list):\n                    backup_servers = backup_data\n                else:\n                    backup_servers = []\n                \n                agent_upstream_data = {\n                    'upstream_name': upstream_obj.get('upstream_name', ''),\n                    'main_servers': main_servers,\n                    'backup_servers': backup_servers,\n                    'domains': upstream_config.get('domains', []),\n                    'system_id': upstream_config.get('system_id', ''),\n                    'environment': upstream_config.get('environment', ''),\n                }\n                return json.dumps(agent_upstream_data, ensure_ascii=False)\n        \n        # Default: just serialize as-is\n        return json.dumps(upstreams_data, ensure_ascii=False)\n\n    def build_config_dataframe(self) -> DataFrame:\n        \"\"\"Convert config blocks into DataFrame, excluding multi-DC domains and handling locations\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n\n            if 'error' in input_data and not input_data.get('upstreams') and not input_data.get('selected_blocks'):\n                self.log(f\"Error in input data: {input_data.get('error')}\")\n                return DataFrame(pd.DataFrame(columns=['error'], data=[{'error': input_data.get('error')}]))\n\n            config_blocks, warnings = self.extract_config_blocks(input_data)\n\n            # Сохраняем warnings для других outputs\n            self._cached_warnings = warnings\n            self._cached_input_data = input_data\n\n            if not config_blocks:\n                # Проверяем типы пропусков\n                multi_dc_warnings = [w for w in warnings if isinstance(w, dict) and w.get('type') == 'MULTI_DC_SKIPPED']\n                multi_loc_warnings = [w for w in warnings if isinstance(w, dict) and w.get('type') in ('MULTI_CONFIG_LOCATION', 'MULTI_DC_LOCATION')]\n\n                if multi_dc_warnings or multi_loc_warnings:\n                    skip_reason = 'multi_dc' if multi_dc_warnings else 'multi_location'\n                    self.log(\n                        f\"⚠️ All items skipped. DC warnings: {len(multi_dc_warnings)}, Location warnings: {len(multi_loc_warnings)}\")\n\n                    return DataFrame(pd.DataFrame(columns=[\n                        'index', 'location_path', 'domain', 'operation', 'upstreams', 'agent1_data', 'status'\n                    ], data=[{\n                        'index': 0,\n                        'location_path': '',\n                        'domain': '',\n                        'operation': input_data.get('operation', ''),\n                        'upstreams': '{}',\n                        'agent1_data': json.dumps({\n                            'skipped_reason': skip_reason,\n                            'warnings': multi_dc_warnings + multi_loc_warnings\n                        }),\n                        'status': 'SKIPPED'\n                    }]))\n\n                self.log(\"No config blocks found, returning empty DataFrame\")\n                return DataFrame(pd.DataFrame(columns=[\n                    'index', 'location_path', 'domain', 'operation', 'upstreams', 'agent1_data'\n                ]))\n\n            agent1_data = input_data.get('agent1_data', {})\n\n            df_data = []\n            for idx, block in enumerate(config_blocks):\n                if not isinstance(block, dict):\n                    self.log(f\"Warning: Block {idx} is not a dict, skipping\")\n                    continue\n\n                upstreams_data = block.get('upstreams', [])\n                domain = block.get('domain', '')\n                location = block.get('location_path', '/')\n\n                # Используем безопасный метод для извлечения данных upstream\n                upstreams_json = self._extract_upstream_data_for_json(upstreams_data)\n\n                payload_item = block.get('payload_item', {})\n                if not isinstance(payload_item, dict):\n                    payload_item = {}\n                    \n                requested_upstreams = block.get('requested_upstreams', [])\n\n                agent1_info = {\n                    'domain': domain,\n                    'domains': [domain] if domain else [],\n                    'location': location,\n                    'requested_upstreams': requested_upstreams,\n                    'preserve_directives': payload_item.get('preserve_directives', True),\n                    'parameters': payload_item.get('parameters', []),\n                    'location_parameters': payload_item.get('location_parameters', []),\n                    'server_block_parameters': payload_item.get('server_block_parameters', []),\n                    'kms_mentioned': payload_item.get('kms_mentioned', False),\n                    'kms_locations': payload_item.get('kms_locations', []),\n                    'public_locations': payload_item.get('public_locations', []),\n                    'data_complete': payload_item.get('data_complete', True),\n                    'from_location': block.get('from_location'),\n                    'to_location': block.get('to_location'),\n                    'confidence': payload_item.get('confidence', 0),\n                    'warnings': payload_item.get('warnings', []),\n                    'ambiguities': payload_item.get('ambiguities', []),\n                    'config_info': block.get('config_info', {}),\n                    'upstreams_count': block.get('upstreams_count', 1),\n                }\n\n                row = {\n                    'index': idx,\n                    'domain': domain,\n                    'location_path': location,\n                    'operation': block.get('operation', input_data.get('operation', 'MODIFY_UPSTREAM')),\n                    'upstreams': upstreams_json,\n                    'agent1_data': json.dumps(agent1_info, ensure_ascii=False),\n                }\n                df_data.append(row)\n\n            if not df_data:\n                self.log(\"No valid blocks processed, returning empty DataFrame\")\n                return DataFrame(pd.DataFrame(columns=['error'], data=[{'error': 'No valid blocks to process'}]))\n\n            df = pd.DataFrame(df_data)\n\n            # Статистика\n            multi_dc_skipped = len([w for w in warnings if isinstance(w, dict) and w.get('type') == 'MULTI_DC_SKIPPED'])\n            multi_loc_skipped = len([w for w in warnings if isinstance(w, dict) and w.get('type') in ('MULTI_CONFIG_LOCATION', 'MULTI_DC_LOCATION')])\n\n            self.log(\n                f\"✅ Created DataFrame with {len(df)} rows \"\n                f\"(excluded {multi_dc_skipped} multi-DC domains, {multi_loc_skipped} multi-location conflicts)\"\n            )\n\n            return DataFrame(df)\n\n        except Exception as e:\n            error_msg = f\"Error building DataFrame: {str(e)}\"\n            self.log(error_msg)\n            import traceback\n            self.log(f\"Traceback: {traceback.format_exc()}\")\n            return DataFrame(pd.DataFrame(columns=['error'], data=[{'error': error_msg}]))\n\n    def build_total_count(self) -> Data:\n        \"\"\"Return total count of config blocks (excluding multi-DC and multi-location conflicts)\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n            config_blocks, warnings = self.extract_config_blocks(input_data)\n\n            multi_dc_skipped = [w for w in warnings if isinstance(w, dict) and w.get('type') == 'MULTI_DC_SKIPPED']\n            multi_loc_skipped = [w for w in warnings if isinstance(w, dict) and w.get('type') in ('MULTI_CONFIG_LOCATION', 'MULTI_DC_LOCATION')]\n\n            agent1_data = input_data.get('agent1_data', {})\n            if not isinstance(agent1_data, dict):\n                agent1_data = {}\n                \n            primary_location = agent1_data.get('location', '')\n            additional_locations = agent1_data.get('locations', [])\n\n            # Собираем уникальные локейшены из блоков\n            unique_locations = set()\n            unique_domains = set()\n            for block in config_blocks:\n                if isinstance(block, dict):\n                    unique_locations.add(block.get('location_path', '/'))\n                    unique_domains.add(block.get('domain', ''))\n\n            count_data = {\n                \"total_blocks\": len(config_blocks),\n                \"skipped_multi_dc\": len(multi_dc_skipped),\n                \"skipped_multi_location\": len(multi_loc_skipped),\n                \"total_skipped\": len(multi_dc_skipped) + len(multi_loc_skipped),\n                \"total_with_skipped\": len(config_blocks) + len(multi_dc_skipped) + len(multi_loc_skipped),\n                \"has_data\": len(config_blocks) > 0,\n                \"has_skipped\": len(multi_dc_skipped) > 0 or len(multi_loc_skipped) > 0,\n                \"operation\": input_data.get(\"operation\", \"\"),\n                \"upstream_processing_needed\": input_data.get(\"upstream_processing_needed\", False),\n                \"config_file\": input_data.get(\"config_file\", \"\"),\n                \"config_key\": input_data.get(\"config_key\", \"\"),\n                \"primary_location\": primary_location,\n                \"all_locations\": list(unique_locations),\n                \"unique_domains\": list(unique_domains),\n                \"unique_locations_count\": len(unique_locations),\n                \"unique_domains_count\": len(unique_domains),\n                \"skipped_domains\": [w.get('domain') for w in multi_dc_skipped if isinstance(w, dict)],\n                \"skipped_locations\": [\n                    f\"{w.get('domain', '')}{w.get('location', '')}\"\n                    for w in multi_loc_skipped if isinstance(w, dict)\n                ],\n            }\n\n            return Data(data=count_data)\n\n        except Exception as e:\n            error_msg = f\"Error getting total count: {str(e)}\"\n            self.log(error_msg)\n            return Data(data={\"total_blocks\": 0, \"has_data\": False, \"error\": error_msg})\n\n    def build_metadata(self) -> Data:\n        \"\"\"Extract and return metadata including multi-DC and multi-location info\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n            config_blocks, warnings = self.extract_config_blocks(input_data)\n\n            multi_dc_skipped = [w for w in warnings if isinstance(w, dict) and w.get('type') == 'MULTI_DC_SKIPPED']\n            multi_loc_skipped = [w for w in warnings if isinstance(w, dict) and w.get('type') in ('MULTI_CONFIG_LOCATION', 'MULTI_DC_LOCATION')]\n\n            # Собираем статистику по domain+location\n            domain_location_stats = {}\n            for block in config_blocks:\n                if not isinstance(block, dict):\n                    continue\n                domain = block.get('domain', '')\n                location = block.get('location_path', '/')\n                key = f\"{domain}{location}\"\n                domain_location_stats[key] = {\n                    'domain': domain,\n                    'location': location,\n                    'upstreams_count': block.get('upstreams_count', 1)\n                }\n\n            metadata = {\n                \"status\": input_data.get(\"status\", \"\"),\n                \"operation\": input_data.get(\"operation\", \"\"),\n                \"upstream_processing_needed\": input_data.get(\"upstream_processing_needed\", False),\n                \"config_file\": input_data.get(\"config_file\", \"\"),\n                \"config_key\": input_data.get(\"config_key\", \"\"),\n                # Multi-DC info\n                \"found_in_multiple_dc\": input_data.get(\"found_in_multiple_dc\", False),\n                \"domains_in_multiple_dc\": input_data.get(\"domains_in_multiple_dc\", []),\n                \"domain_dc_mapping\": input_data.get(\"domain_dc_mapping\", {}),\n                \"unique_dcs\": input_data.get(\"unique_dcs\", []),\n                \"dc_count\": input_data.get(\"dc_count\", 1),\n                # Multi-location info\n                \"locations_in_multiple_dc\": input_data.get(\"locations_in_multiple_dc\", []),\n                \"location_dc_mapping\": input_data.get(\"location_dc_mapping\", {}),\n                # Processing stats\n                \"blocks_to_process\": len(config_blocks),\n                \"blocks_skipped_multi_dc\": len(multi_dc_skipped),\n                \"blocks_skipped_multi_location\": len(multi_loc_skipped),\n                \"domain_location_stats\": domain_location_stats,\n                \"has_warnings\": len(warnings) > 0,\n                \"warnings_count\": len(warnings),\n            }\n\n            agent1_data = input_data.get('agent1_data')\n            if isinstance(agent1_data, dict):\n                metadata['agent1_data'] = agent1_data\n\n            full_config_data = input_data.get('full_config_data')\n            if isinstance(full_config_data, dict):\n                metadata['has_full_config'] = True\n                metadata['server_names'] = full_config_data.get('server_names', [])\n\n            if 'error' in input_data:\n                metadata['error'] = input_data['error']\n\n            return Data(data=metadata)\n\n        except Exception as e:\n            error_msg = f\"Error extracting metadata: {str(e)}\"\n            self.log(error_msg)\n            return Data(data={\"error\": error_msg})\n\n    def build_warnings(self) -> Data:\n        \"\"\"Return all warnings including multi-DC and multi-location issues\"\"\"\n        try:\n            input_data = self.process_input_data(self.selected_block)\n            _, warnings = self.extract_config_blocks(input_data)\n\n            # Группируем warnings по типу (с проверкой типа)\n            multi_dc_warnings = [w for w in warnings if isinstance(w, dict) and w.get('type') == 'MULTI_DC_SKIPPED']\n            multi_loc_warnings = [w for w in warnings if isinstance(w, dict) and w.get('type') in ('MULTI_CONFIG_LOCATION', 'MULTI_DC_LOCATION')]\n            other_warnings = [w for w in warnings if isinstance(w, dict) and w.get('type') not in ('MULTI_DC_SKIPPED', 'MULTI_CONFIG_LOCATION', 'MULTI_DC_LOCATION')]\n\n            summary_messages = []\n\n            if multi_dc_warnings:\n                domains = [w.get('domain') for w in multi_dc_warnings if isinstance(w, dict)]\n                summary_messages.append(\n                    f\"⚠️ ВНИМАНИЕ: {len(multi_dc_warnings)} домен(ов) пропущено из-за наличия в нескольких ЦОД: {', '.join(filter(None, domains))}. \"\n                    f\"Для этих доменов требуется выбрать конкретный ЦОД или обработать вручную.\"\n                )\n\n            if multi_loc_warnings:\n                locations = [f\"{w.get('domain', '')}{w.get('location', '')}\" for w in multi_loc_warnings if isinstance(w, dict)]\n                summary_messages.append(\n                    f\"⚠️ ВНИМАНИЕ: {len(multi_loc_warnings)} локейшен(ов) пропущено из-за конфликтов: {', '.join(filter(None, locations))}. \"\n                    f\"Требуется выбор конкретной конфигурации.\"\n                )\n\n            if other_warnings:\n                summary_messages.append(f\"ℹ️ Дополнительные предупреждения: {len(other_warnings)}\")\n\n            warnings_data = {\n                \"has_warnings\": len(warnings) > 0,\n                \"total_warnings\": len(warnings),\n                # Multi-DC\n                \"multi_dc_warnings\": multi_dc_warnings,\n                \"multi_dc_count\": len(multi_dc_warnings),\n                # Multi-location\n                \"multi_location_warnings\": multi_loc_warnings,\n                \"multi_location_count\": len(multi_loc_warnings),\n                # Other\n                \"other_warnings\": other_warnings,\n                \"other_count\": len(other_warnings),\n                # All\n                \"all_warnings\": warnings,\n                \"summary\": \"\\n\".join(summary_messages) if summary_messages else \"✅ Нет предупреждений\",\n                \"action_required\": any(w.get('action_required', False) for w in warnings if isinstance(w, dict)),\n                \"skipped_domains\": [w.get('domain') for w in multi_dc_warnings if isinstance(w, dict)],\n                \"skipped_locations\": [f\"{w.get('domain', '')}{w.get('location', '')}\" for w in multi_loc_warnings if isinstance(w, dict)],\n            }\n\n            if multi_dc_warnings:\n                self.log(f\"⚠️ Generated {len(multi_dc_warnings)} multi-DC warnings\")\n            if multi_loc_warnings:\n                self.log(f\"⚠️ Generated {len(multi_loc_warnings)} multi-location warnings\")\n\n            return Data(data=warnings_data)\n\n        except Exception as e:\n            error_msg = f\"Error building warnings: {str(e)}\"\n            self.log(error_msg)\n            return Data(data={\n                \"has_warnings\": True,\n                \"error\": error_msg,\n                \"all_warnings\": [{\"type\": \"ERROR\", \"message\": error_msg}]\n            })"
              },
              "selected_block": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Selected Block",
                "dynamic": false,
                "info": "Output from UpstreamExtractor containing upstreams",
                "input_types": [
                  "Message",
                  "Data",
                  "dict"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "selected_block",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "config_items_df",
          "showNode": true,
          "type": "UpstreamConfigBlockSplitter"
        },
        "dragging": false,
        "id": "UpstreamConfigBlockSplitter-6qh1v",
        "measured": {
          "height": 181,
          "width": 320
        },
        "position": {
          "x": 7232.501345071293,
          "y": 2526.4598955652764
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "UniversalSearchConfigComponent-RvEQ1",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Универсально сканирует YML файлы по доменам из любой структуры JSON (включая Arbitrator payload)",
            "display_name": "Universal Search Config",
            "documentation": "",
            "edited": true,
            "field_order": [
              "agent1_json",
              "config_base_path"
            ],
            "frozen": false,
            "icon": "search",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Config Data",
                "group_outputs": false,
                "hidden": null,
                "method": "search_config",
                "name": "config_data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "agent1_json": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Agent 1 JSON Output",
                "dynamic": false,
                "info": "JSON с извлечёнными данными от Agent 1 или Arbitrator (любая структура)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "agent1_json",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageTextInput, StrInput, Output\nfrom langflow.schema import Data\nimport json\nimport yaml\nimport os\nimport glob\nimport re\nfrom typing import List, Dict, Any, Optional\n\n\nclass UniversalSearchConfigComponent(Component):\n    display_name = \"Universal Search Config\"\n    description = \"Универсально сканирует YML файлы по доменам из любой структуры JSON (включая Arbitrator payload)\"\n    icon = \"search\"\n    inputs = [\n        MessageTextInput(\n            name=\"agent1_json\",\n            display_name=\"Agent 1 JSON Output\",\n            info=\"JSON с извлечёнными данными от Agent 1 или Arbitrator (любая структура)\",\n            required=True\n        ),\n        StrInput(\n            name=\"config_base_path\",\n            display_name=\"Config Base Path\",\n            info=\"Путь к родительской папке с конфигами (например, /path/to/mos_ru_nginx/)\",\n            value=\"/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/\",\n            required=True\n        )\n    ]\n    outputs = [\n        Output(\n            display_name=\"Config Data\",\n            name=\"config_data\",\n            method=\"search_config\"\n        )\n    ]\n\n    def search_config(self) -> Data:\n        \"\"\"\n        Универсально обрабатывает любой JSON/Python dict и ищет конфигурации\n        \"\"\"\n        try:\n            # 🔧 ПРЕДОБРАБОТКА: Очищаем от markdown блоков\n            cleaned_input = self._clean_markdown(self.agent1_json)\n\n            # 🔄 ПАРСИМ: Поддержка и JSON, и Python dict\n            raw_data = self._parse_input(cleaned_input)\n\n            # 🔄 НОРМАЛИЗАЦИЯ: Извлекаем payload если это Arbitrator output\n            agent1_data = self._normalize_input(raw_data)\n            # 🔍 УНИВЕРСАЛЬНОЕ ИЗВЛЕЧЕНИЕ ДОМЕНОВ\n            domains = self._universal_extract_domains(agent1_data)\n\n            # 🔍 УНИВЕРСАЛЬНОЕ ИЗВЛЕЧЕНИЕ ДРУГИХ ДАННЫХ\n            locations = self._universal_extract_locations(agent1_data)\n            ip_addresses = self._universal_extract_ips(agent1_data)\n            upstreams = self._universal_extract_upstreams(agent1_data)\n            parameters = self._universal_extract_parameters(agent1_data)\n            location_parameters = self._universal_extract_location_parameters(agent1_data)\n            operation = self._universal_extract_operation(agent1_data)\n            selected_dc = self._universal_extract_selected_dc(agent1_data)\n            # ✅ ПРОВЕРЯЕМ СТАТУС\n            status = self._check_status(raw_data)  # Проверяем оригинальные данные\n            if status and status.get(\"is_error\"):\n                return self._return_error_status(status, agent1_data)\n            # ❌ ОШИБКА: Домены не найдены\n            if not domains:\n                return self._return_no_domains_error(\n                    agent1_data, locations, ip_addresses, parameters, operation\n                )\n            # 🔍 ОПРЕДЕЛЯЕМ ПАПКИ ДЛЯ ПОИСКА\n            search_folders = self._get_search_folders(selected_dc)\n            # 🔍 СКАНИРУЕМ ВСЕ YML ФАЙЛЫ В ВЫБРАННЫХ ПАПКАХ\n            config_results = []\n            scanned_files = 0\n            for folder in search_folders:\n                folder_path = os.path.join(self.config_base_path, folder)\n                if not os.path.isdir(folder_path):\n                    continue\n                yml_files = glob.glob(os.path.join(folder_path, \"*.yml\"))\n                scanned_files += len(yml_files)\n                for yml_file in yml_files:\n                    file_results = self._scan_yml_file(yml_file, domains)\n                    for res in file_results:\n                        res[\"folder\"] = folder\n                        res[\"inferred_dc\"] = self._infer_dc_from_folder(folder)\n                    config_results.extend(file_results)\n            # Удаляем дубликаты (по полному пути и ключу)\n            unique_results = self._deduplicate_results(config_results)\n            # ❌ ОШИБКА: Конфиги не найдены\n            if not unique_results:\n                return self._return_not_found_error(\n                    domains, scanned_files, agent1_data,\n                    locations, ip_addresses, parameters, operation\n                )\n            # ✅ УСПЕХ: Конфиг найден\n            first_config = unique_results[0]\n\n            # 🆕 АНАЛИЗ: Проверяем, найден ли домен в нескольких ЦОД\n            multi_dc_info = self._analyze_multi_dc_presence(unique_results, domains)\n\n            result = {\n                \"status\": \"success\",\n\n                # 📦 Конфиг данные\n                \"config_file\": first_config[\"config_file\"],\n                \"config_key\": first_config[\"config_key\"],\n                \"full_config_text\": first_config[\"full_config_text\"],\n                \"server_names\": first_config[\"server_names\"],\n                \"matching_domains\": first_config[\"matching_domains\"],\n                # 📦 Извлечённые данные (нормализованные)\n                \"agent1_data\": agent1_data,\n                \"operation\": operation,\n                \"domains\": domains,\n                \"locations\": locations,\n                \"ip_addresses\": ip_addresses,\n                \"upstreams\": upstreams,\n                \"parameters\": parameters,\n                \"location_parameters\": location_parameters,\n                \"selected_dc\": selected_dc,\n                # 📊 Метаданные\n                \"scanned_files\": scanned_files,\n                \"found_configs\": len(unique_results),\n                \"all_configs\": unique_results,\n                \"data_complete\": True,\n                \"error_type\": None,\n                \"error_message\": None,\n\n                # 🆕 НОВЫЕ КЛЮЧИ: Информация о нахождении в нескольких ЦОД\n                \"found_in_multiple_dc\": multi_dc_info[\"found_in_multiple_dc\"],\n                \"dc_count\": multi_dc_info[\"dc_count\"],\n                \"unique_dcs\": multi_dc_info[\"unique_dcs\"],\n                \"domain_dc_mapping\": multi_dc_info[\"domain_dc_mapping\"],\n                \"domains_in_multiple_dc\": multi_dc_info[\"domains_in_multiple_dc\"],\n            }\n            # Формируем сообщение\n            msg = self._format_success_message(result)\n            return Data(data=result, text=msg)\n        except json.JSONDecodeError as e:\n            return self._return_json_error(e, self.agent1_json)\n        except Exception as e:\n            return self._return_unexpected_error(e)\n\n    # ==========================================\n    # 🆕 НОВЫЙ МЕТОД: Анализ присутствия в нескольких ЦОД\n    # ==========================================\n    def _analyze_multi_dc_presence(self, config_results: List[Dict], domains: List[str]) -> Dict:\n        \"\"\"\n        Анализирует, найден ли домен в нескольких ЦОД\n\n        Returns:\n            Dict с ключами:\n            - found_in_multiple_dc: bool - True если хотя бы один домен найден в >1 ЦОД\n            - dc_count: int - количество уникальных ЦОД где найдены конфиги\n            - unique_dcs: List[str] - список уникальных ЦОД\n            - domain_dc_mapping: Dict[str, List[str]] - маппинг домен -> список ЦОД\n            - domains_in_multiple_dc: List[str] - домены, найденные в нескольких ЦОД\n        \"\"\"\n        # Собираем все уникальные ЦОД из результатов\n        all_dcs = set()\n        for config in config_results:\n            inferred_dc = config.get(\"inferred_dc\", [])\n            all_dcs.update(inferred_dc)\n\n        unique_dcs = sorted(list(all_dcs))\n        dc_count = len(unique_dcs)\n\n        # Строим маппинг: домен -> в каких ЦОД найден\n        domain_dc_mapping = {}\n        for domain in domains:\n            domain_dcs = set()\n            for config in config_results:\n                matching_domains = config.get(\"matching_domains\", [])\n                if domain in matching_domains:\n                    inferred_dc = config.get(\"inferred_dc\", [])\n                    domain_dcs.update(inferred_dc)\n            domain_dc_mapping[domain] = sorted(list(domain_dcs))\n\n        # Определяем домены, которые найдены в нескольких ЦОД\n        domains_in_multiple_dc = [\n            domain for domain, dcs in domain_dc_mapping.items()\n            if len(dcs) > 1\n        ]\n\n        # Главный флаг: есть ли хотя бы один домен в нескольких ЦОД\n        found_in_multiple_dc = len(domains_in_multiple_dc) > 0\n\n        return {\n            \"found_in_multiple_dc\": found_in_multiple_dc,\n            \"dc_count\": dc_count,\n            \"unique_dcs\": unique_dcs,\n            \"domain_dc_mapping\": domain_dc_mapping,\n            \"domains_in_multiple_dc\": domains_in_multiple_dc\n        }\n\n    # ==========================================\n    # ПРЕДОБРАБОТКА И НОРМАЛИЗАЦИЯ\n    # ==========================================\n    def _clean_markdown(self, raw_input: str) -> str:\n        \"\"\"Убирает только markdown разметку\"\"\"\n        if not raw_input:\n            return raw_input\n\n        cleaned = raw_input.strip()\n\n        patterns = [\n            (r'^```json\\s*\\n', ''),\n            (r'^```\\s*\\n', ''),\n            (r'\\n```\\s*$', ''),\n            (r'^```json\\s*', ''),\n            (r'^```\\s*', ''),\n            (r'```\\s*$', ''),\n        ]\n\n        for pattern, replacement in patterns:\n            cleaned = re.sub(pattern, replacement, cleaned)\n\n        return cleaned.strip()\n\n    def _parse_input(self, text: str) -> Dict:\n        \"\"\"\n        🔄 Парсит входные данные — поддерживает JSON и Python dict\n        \"\"\"\n        # Способ 1: Пробуем как JSON\n        try:\n            return json.loads(text)\n        except json.JSONDecodeError:\n            pass\n\n        # Способ 2: Пробуем как Python dict через ast.literal_eval\n        try:\n            import ast\n            result = ast.literal_eval(text)\n            if isinstance(result, dict):\n                return result\n        except (ValueError, SyntaxError):\n            pass\n\n        # Способ 3: Ручная конвертация Python → JSON\n        try:\n            converted = text\n            converted = re.sub(r'\\bNone\\b', 'null', converted)\n            converted = re.sub(r'\\bTrue\\b', 'true', converted)\n            converted = re.sub(r'\\bFalse\\b', 'false', converted)\n            converted = converted.replace(\"'\", '\"')\n            return json.loads(converted)\n        except json.JSONDecodeError:\n            pass\n\n        # Если ничего не сработало — выбрасываем ошибку\n        raise json.JSONDecodeError(\n            f\"Не удалось распарсить ни как JSON, ни как Python dict\",\n            text,\n            0\n        )\n\n    def _normalize_input(self, raw_data: Any) -> Dict:\n        \"\"\"\n        🔄 НОРМАЛИЗАЦИЯ: Извлекает payload из Arbitrator output\n\n        Поддерживает форматы:\n        1. Arbitrator: {\"status\": \"SUCCESS\", \"payload\": {...}, \"ready_for_execution\": true}\n        2. Прямой Agent1: {\"operation\": \"...\", \"domain\": \"...\", ...}\n        3. Вложенный: {\"data\": {\"payload\": {...}}}\n        \"\"\"\n        if not isinstance(raw_data, dict):\n            return raw_data\n\n        # Случай 1: Arbitrator output с payload\n        if \"payload\" in raw_data and isinstance(raw_data[\"payload\"], dict):\n            # Проверяем что это успешный Arbitrator response\n            status = raw_data.get(\"status\", \"\").upper()\n            if status in [\"SUCCESS\", \"COMPLETE\", \"OK\"]:\n                return raw_data[\"payload\"]\n            # Даже если статус не SUCCESS, но payload есть — используем его\n            if raw_data[\"payload\"]:\n                return raw_data[\"payload\"]\n\n        # Случай 2: Вложенный data.payload\n        if \"data\" in raw_data and isinstance(raw_data[\"data\"], dict):\n            if \"payload\" in raw_data[\"data\"]:\n                return raw_data[\"data\"][\"payload\"]\n            return raw_data[\"data\"]\n\n        # Случай 3: Прямой Agent1 output (уже нормализован)\n        return raw_data\n\n    # ==========================================\n    # УНИВЕРСАЛЬНЫЕ МЕТОДЫ ИЗВЛЕЧЕНИЯ ДАННЫХ\n    # ==========================================\n    def _universal_extract_domains(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет домены во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        domains = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return domains\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"domain\", \"domains\", \"server_name\", \"server_names\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        domains.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                domains.append(item.strip())\n\n            for value in data.values():\n                domains.extend(self._universal_extract_domains(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                domains.extend(self._universal_extract_domains(item, visited))\n\n        return list(set([d for d in domains if d and self._looks_like_domain(d)]))\n\n    def _universal_extract_locations(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет location/locations во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        locations = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return locations\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"location\", \"locations\", \"kms_locations\", \"public_locations\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        locations.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                locations.append(item.strip())\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    locations.extend(self._universal_extract_locations(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                locations.extend(self._universal_extract_locations(item, visited))\n\n        return list(set([loc for loc in locations if loc and loc.startswith(\"/\")]))\n\n    def _universal_extract_ips(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет IP адреса во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        ips = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return ips\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"ip_addresses\", \"ips\", \"servers\", \"upstream\", \"ip\", \"address\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        ips.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                ips.append(item.strip())\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    ips.extend(self._universal_extract_ips(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                ips.extend(self._universal_extract_ips(item, visited))\n\n        return list(set([ip for ip in ips if ip and self._looks_like_ip(ip)]))\n\n    def _universal_extract_upstreams(self, data: Any, visited: Optional[set] = None) -> List[Dict]:\n        \"\"\"\n        🆕 Извлекает структурированные upstreams\n\n        Формат входа:\n        \"upstreams\": [\n            {\"upstream_type\": \"main\", \"ip_addresses\": [\"10.10.10.10\", ...], \"params\": []},\n            {\"upstream_type\": \"backup\", \"ip_addresses\": [...], \"params\": []}\n        ]\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        upstreams = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return upstreams\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            # Прямой ключ upstreams\n            if \"upstreams\" in data and isinstance(data[\"upstreams\"], list):\n                for upstream in data[\"upstreams\"]:\n                    if isinstance(upstream, dict):\n                        normalized = {\n                            \"type\": upstream.get(\"upstream_type\", upstream.get(\"type\", \"main\")),\n                            \"ip_addresses\": upstream.get(\"ip_addresses\", upstream.get(\"ips\", [])),\n                            \"params\": upstream.get(\"params\", upstream.get(\"parameters\", []))\n                        }\n                        if normalized[\"ip_addresses\"]:\n                            upstreams.append(normalized)\n\n            # Рекурсивный поиск\n            for key, value in data.items():\n                if key != \"upstreams\" and isinstance(value, (dict, list)):\n                    upstreams.extend(self._universal_extract_upstreams(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                upstreams.extend(self._universal_extract_upstreams(item, visited))\n\n        return upstreams\n\n    def _universal_extract_location_parameters(self, data: Any, visited: Optional[set] = None) -> List[Dict]:\n        \"\"\"\n        🆕 Извлекает параметры для конкретных locations\n\n        Формат входа:\n        \"location_parameters\": [\n            {\"location\": \"/api_V2/\", \"parameters\": [], \"kms_required\": false},\n            ...\n        ]\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        loc_params = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return loc_params\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            if \"location_parameters\" in data and isinstance(data[\"location_parameters\"], list):\n                for lp in data[\"location_parameters\"]:\n                    if isinstance(lp, dict) and \"location\" in lp:\n                        normalized = {\n                            \"location\": lp.get(\"location\"),\n                            \"parameters\": lp.get(\"parameters\", []),\n                            \"kms_required\": lp.get(\"kms_required\", False)\n                        }\n                        loc_params.append(normalized)\n\n            for key, value in data.items():\n                if key != \"location_parameters\" and isinstance(value, (dict, list)):\n                    loc_params.extend(self._universal_extract_location_parameters(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                loc_params.extend(self._universal_extract_location_parameters(item, visited))\n\n        return loc_params\n\n    def _universal_extract_parameters(self, data: Any, visited: Optional[set] = None) -> Dict:\n        \"\"\"\n        Ищет общие параметры в структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        parameters = {}\n\n        data_id = id(data)\n        if data_id in visited:\n            return parameters\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            # server_block_parameters\n            if \"server_block_parameters\" in data:\n                params = data[\"server_block_parameters\"]\n                if isinstance(params, list):\n                    parameters[\"server_block\"] = params\n                elif isinstance(params, dict):\n                    parameters[\"server_block\"] = params\n\n            # Общие parameters\n            if \"parameters\" in data:\n                params = data[\"parameters\"]\n                if isinstance(params, dict):\n                    parameters.update(params)\n                elif isinstance(params, list):\n                    parameters[\"general\"] = params\n\n            # Рекурсивно (но не в уже обработанные ключи)\n            for key, value in data.items():\n                if key not in [\"parameters\", \"server_block_parameters\", \"location_parameters\"] \\\n                        and isinstance(value, (dict, list)):\n                    sub_params = self._universal_extract_parameters(value, visited)\n                    for k, v in sub_params.items():\n                        if k not in parameters:\n                            parameters[k] = v\n\n        elif isinstance(data, list):\n            for item in data:\n                sub_params = self._universal_extract_parameters(item, visited)\n                parameters.update(sub_params)\n\n        return parameters\n\n    def _universal_extract_operation(self, data: Any) -> Optional[str]:\n        \"\"\"\n        Ищет тип операции в любой структуре\n        \"\"\"\n        if isinstance(data, dict):\n            for key in [\"operation\", \"operation_type\", \"action\", \"type\"]:\n                if key in data and data[key]:\n                    val = str(data[key])\n                    # Фильтруем не-операции\n                    if val.upper() not in [\"MAIN\", \"BACKUP\", \"PREFIX\", \"EXACT\"]:\n                        return val\n\n            for value in data.values():\n                if isinstance(value, (dict, list)):\n                    result = self._universal_extract_operation(value)\n                    if result:\n                        return result\n\n        elif isinstance(data, list):\n            for item in data:\n                result = self._universal_extract_operation(item)\n                if result:\n                    return result\n\n        return None\n\n    def _universal_extract_selected_dc(self, data: Any, visited: Optional[set] = None) -> List[str]:\n        \"\"\"\n        Рекурсивно ищет selected_dc во ВСЕЙ структуре JSON\n        \"\"\"\n        if visited is None:\n            visited = set()\n\n        dcs = []\n\n        data_id = id(data)\n        if data_id in visited:\n            return dcs\n        visited.add(data_id)\n\n        if isinstance(data, dict):\n            for key in [\"selected_dc\", \"dc\", \"datacenters\", \"datacenter\"]:\n                if key in data:\n                    value = data[key]\n                    if isinstance(value, str) and value.strip():\n                        dcs.append(value.strip())\n                    elif isinstance(value, list):\n                        for item in value:\n                            if isinstance(item, str) and item.strip():\n                                dcs.append(item.strip())\n\n            for value in data.values():\n                dcs.extend(self._universal_extract_selected_dc(value, visited))\n\n        elif isinstance(data, list):\n            for item in data:\n                dcs.extend(self._universal_extract_selected_dc(item, visited))\n\n        return list(set(dcs))\n\n    def _check_status(self, data: Any) -> Optional[Dict]:\n        \"\"\"\n        Проверяет статус ошибки в данных\n        \"\"\"\n        if isinstance(data, dict):\n            status = data.get(\"status\", \"\")\n\n            # Ошибка Arbitrator\n            if status == \"VALIDATION_FAILED\":\n                return {\n                    \"is_error\": True,\n                    \"status\": status,\n                    \"error_type\": \"VALIDATION_FAILED\",\n                    \"error_message\": \"Валидация не прошла\",\n                    \"missing_fields\": data.get(\"missing_fields\", []),\n                    \"clarification_questions\": data.get(\"clarification_questions\", [])\n                }\n\n            # Ошибка Agent1\n            if status == \"error\":\n                return {\n                    \"is_error\": True,\n                    \"status\": data.get(\"status\"),\n                    \"error_type\": data.get(\"error_type\"),\n                    \"error_message\": data.get(\"error_message\"),\n                    \"explanation\": data.get(\"explanation\"),\n                    \"warnings\": data.get(\"warnings\", [])\n                }\n        return None\n\n    # ==========================================\n    # ВАЛИДАЦИЯ\n    # ==========================================\n    def _looks_like_domain(self, text: str) -> bool:\n        \"\"\"Проверяет, похоже ли на домен\"\"\"\n        if not text or len(text) < 3:\n            return False\n        return '.' in text or re.match(r'^[a-zA-Z0-9\\-\\.]+$', text) is not None\n\n    def _looks_like_ip(self, text: str) -> bool:\n        \"\"\"Проверяет, похоже ли на IP адрес\"\"\"\n        if not text:\n            return False\n        ip_pattern = r'^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}(:\\d+)?$'\n        return re.match(ip_pattern, text) is not None\n\n    # ==========================================\n    # ЛОГИКА ПОИСКА ПО ПАПКАМ И DC\n    # ==========================================\n    def _get_all_folders(self) -> List[str]:\n        \"\"\"Возвращает список всех возможных папок\"\"\"\n        return [\n            \"production_ext_kor_sites\",\n            \"production_ext_nag_http\",\n            \"production_ext_nag_sites\",\n            \"production_ext_sites\",\n            \"production_kor_ngate_sites\",\n            \"production_kor_sites\",\n            \"production_mesh_main_kor_sites\",\n            \"production_mesh_rus_kor_sites\",\n            \"production_metro_kor_sites\",\n            \"production_metro_sites\",\n            \"production_moshub_ext_kor_sites\",\n            \"production_moshub_kor_sites\",\n            \"production_nag_sites\",\n            \"production_sites\",\n            \"production_upload_sites\",\n            \"stage_kor_sites\",\n            \"stage_nag_sites\",\n            \"stage_sites\",\n            \"test_kor_sites\",\n            \"test_nag_sites\",\n            \"test_sites\"\n        ]\n\n    def _get_search_folders(self, selected_dc: List[str]) -> List[str]:\n        \"\"\"Определяет папки для поиска на основе selected_dc\"\"\"\n        all_folders = self._get_all_folders()\n        if not selected_dc:\n            return all_folders\n\n        search_folders = set()\n        for dc in selected_dc:\n            if dc == \"dr\":\n                search_folders.update(self._get_folders_for_dc(\"korovinskiy\"))\n                search_folders.update(self._get_folders_for_dc(\"kurchatovskiy\"))\n            else:\n                search_folders.update(self._get_folders_for_dc(dc))\n        return list(search_folders)\n\n    def _get_folders_for_dc(self, dc: str) -> List[str]:\n        \"\"\"Возвращает папки для конкретного DC\"\"\"\n        all_folders = self._get_all_folders()\n\n        if dc == \"korovinskiy\":\n            # Исключаем metro и mesh - они относятся к отдельным DC\n            return [f for f in all_folders\n                    if \"_kor_\" in f\n                    and \"metro\" not in f\n                    and \"mesh\" not in f]\n\n        elif dc == \"kurchatovskiy\":\n            return [f for f in all_folders if\n                    f in [\"production_sites\", \"stage_sites\", \"test_sites\", \"production_ext_sites\",\n                          \"production_upload_sites\"]]  # убрал production_metro_sites\n\n        elif dc == \"nagornaya\":\n            return [f for f in all_folders if \"_nag_\" in f]\n\n        elif dc == \"moshub_rus\":\n            return [f for f in all_folders if \"moshub\" in f and \"ext\" not in f]\n\n        elif dc == \"ext_kurchatovskiy\":\n            return [f for f in all_folders if \"ext\" in f and \"_kor_\" not in f and \"_nag_\" not in f]\n\n        elif dc == \"ext_korovinskiy\":\n            return [f for f in all_folders if \"ext\" in f and \"_kor_\" in f]\n\n        elif dc == \"ext_nagornaya\":\n            return [f for f in all_folders if \"ext\" in f and \"_nag_\" in f]\n\n        elif dc == \"mesh\":\n            return [f for f in all_folders if \"mesh\" in f]\n\n        elif dc == \"top10_kurchatovskiy\":\n            return [f for f in all_folders if \"metro\" in f and \"_kor_\" not in f]\n\n        elif dc == \"top10_korovinskiy\":\n            return [f for f in all_folders if \"metro\" in f and \"_kor_\" in f]\n\n        return []\n\n    def _infer_dc_from_folder(self, folder: str) -> List[str]:\n        \"\"\"Точно определяет DC на основе имени папки с приоритетами\"\"\"\n        folder_lower = folder.lower()\n\n        # Приоритетные шаблоны - проверяем самые конкретные сначала\n        if \"mesh\" in folder_lower:\n            # Для mesh-конфигураций проверяем подтипы\n            if \"_main_kor_\" in folder_lower:\n                return [\"mesh\"]\n            elif \"_rus_kor_\" in folder_lower:\n                return [\"mesh\"]\n            return [\"mesh\"]\n        elif \"metro\" in folder_lower:\n            if \"_kor_\" in folder_lower:\n                return [\"top10_korovinskiy\"]\n            return [\"top10_kurchatovskiy\"]\n        elif \"moshub\" in folder_lower:\n            if \"ext\" in folder_lower:\n                return [\"ext_korovinskiy\"]\n            return [\"moshub_rus\"]\n        elif \"_kor_\" in folder_lower:\n            if \"ext\" in folder_lower:\n                return [\"ext_korovinskiy\"]\n            return [\"korovinskiy\"]\n        elif \"_nag_\" in folder_lower:\n            if \"ext\" in folder_lower:\n                return [\"ext_nagornaya\"]\n            return [\"nagornaya\"]\n        elif \"ext\" in folder_lower:\n            return [\"ext_kurchatovskiy\"]\n        elif folder in [\"production_sites\", \"stage_sites\", \"test_sites\",\n                        \"production_ext_sites\", \"production_upload_sites\"]:\n            return [\"kurchatovskiy\"]\n\n        # Если ничего не подошло, возвращаем пустой список\n        return []\n\n    # ==========================================\n    # СКАНИРОВАНИЕ YML\n    # ==========================================\n    def _scan_yml_file(self, yml_file: str, target_domains: List[str]) -> List[Dict]:\n        \"\"\"Сканирует один YML файл и находит совпадения по server_name\"\"\"\n        results = []\n        try:\n            with open(yml_file, 'r', encoding='utf-8') as f:\n                config_text = f.read()\n                config_yaml = yaml.safe_load(config_text)\n            if not config_yaml:\n                return results\n            for config_key, config_block in config_yaml.items():\n                server_names = self._extract_server_names(config_block)\n                if not server_names:\n                    continue\n                matching_domains = []\n                for target_domain in target_domains:\n                    if self._is_domain_match(target_domain, server_names):\n                        matching_domains.append(target_domain)\n                if matching_domains:\n                    result = {\n                        \"config_key\": config_key,\n                        \"config_file\": yml_file,\n                        \"server_names\": server_names,\n                        \"matching_domains\": matching_domains,\n                        \"full_config_text\": config_text,\n                        \"parsed_yaml\": config_yaml,\n                        \"config_block\": config_block\n                    }\n                    results.append(result)\n        except yaml.YAMLError as e:\n            print(f\"⚠️ Ошибка чтения YAML {yml_file}: {e}\")\n        except Exception as e:\n            print(f\"⚠️ Ошибка обработки {yml_file}: {e}\")\n        return results\n\n    def _extract_server_names(self, config_block: Any) -> List[str]:\n        \"\"\"Извлекает все server_name из конфигурационного блока\"\"\"\n        server_names = []\n        if isinstance(config_block, list):\n            for item in config_block:\n                if isinstance(item, str) and item.startswith(\"server_name \"):\n                    server_name_part = item.replace(\"server_name \", \"\").strip()\n                    names = [n.strip() for n in server_name_part.split() if n.strip()]\n                    server_names.extend(names)\n        return list(set(server_names))\n\n    def _is_domain_match(self, target_domain: str, server_names: List[str]) -> bool:\n        \"\"\"Проверяет, совпадает ли target_domain с любым server_name\"\"\"\n        target_domain = target_domain.strip().lower()\n        for server_name in server_names:\n            server_name = server_name.strip().lower()\n            if server_name == target_domain:\n                return True\n            if server_name.startswith(\"~^\") and server_name.endswith(\"$\"):\n                pattern = server_name[2:-1]\n                try:\n                    if re.match(pattern, target_domain):\n                        return True\n                except re.error:\n                    continue\n        return False\n\n    def _deduplicate_results(self, results: List[Dict]) -> List[Dict]:\n        \"\"\"Удаляет дубликаты результатов\"\"\"\n        seen = set()\n        unique = []\n        for result in results:\n            key = (result[\"config_file\"], result[\"config_key\"])\n            if key not in seen:\n                seen.add(key)\n                unique.append(result)\n        return unique\n\n    # ==========================================\n    # ОБРАБОТКА ОШИБОК\n    # ==========================================\n    def _return_error_status(self, status: Dict, agent1_data: Any) -> Data:\n        \"\"\"Возвращает ошибку из статуса\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": status.get(\"error_type\", \"UNKNOWN_ERROR\"),\n            \"error_message\": status.get(\"error_message\", \"Unknown error\"),\n            \"explanation\": status.get(\"explanation\", \"\"),\n            \"warnings\": status.get(\"warnings\", []),\n            \"missing_fields\": status.get(\"missing_fields\", []),\n            \"clarification_questions\": status.get(\"clarification_questions\", []),\n            \"agent1_data\": agent1_data,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: {status.get('error_message')}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        questions = status.get(\"clarification_questions\", [])\n        missing = status.get(\"missing_fields\", [])\n\n        error_msg = f\"\"\"❌ **Ошибка**\n🔴 **Тип:** {status.get('error_type')}\n📝 **Сообщение:** {status.get('error_message')}\n\"\"\"\n        if missing:\n            error_msg += f\"\\n📋 **Не хватает:** {', '.join(missing[:3])}\"\n        if questions:\n            error_msg += f\"\\n❓ **Вопросы:** {questions[0]}\"\n        return Data(data=error_result, text=error_msg)\n\n    def _return_no_domains_error(self, agent1_data: Any, locations: List[str],\n                                 ip_addresses: List[str], parameters: Dict,\n                                 operation: Optional[str]) -> Data:\n        \"\"\"Возвращает ошибку об отсутствии доменов\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"NO_DOMAINS\",\n            \"error_message\": \"Домены не найдены в данных\",\n            \"agent1_data\": agent1_data,\n            \"operation\": operation,\n            \"locations\": locations,\n            \"ip_addresses\": ip_addresses,\n            \"parameters\": parameters,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": \"# Error: No domains specified\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        error_msg = f\"\"\"❌ **Ошибка: домен не указан**\n📋 **Что извлечено:**\n- Operation: {operation or 'N/A'}\n- Locations: {', '.join(locations[:3]) if locations else 'N/A'}\n- IPs: {', '.join(ip_addresses[:3]) if ip_addresses else 'N/A'}\n💡 Укажите домен явно в запросе.\n\"\"\"\n        return Data(data=error_result, text=error_msg)\n\n    def _return_not_found_error(self, domains: List[str], scanned_files: int,\n                                agent1_data: Any, locations: List[str],\n                                ip_addresses: List[str], parameters: Dict,\n                                operation: Optional[str]) -> Data:\n        \"\"\"Возвращает ошибку о ненайденной конфигурации\"\"\"\n        not_found_result = {\n            \"status\": \"not_found\",\n            \"error_type\": \"CONFIG_NOT_FOUND\",\n            \"error_message\": f\"Конфигурация не найдена для: {', '.join(domains)}\",\n            \"domains\": domains,\n            \"scanned_files\": scanned_files,\n            \"agent1_data\": agent1_data,\n            \"operation\": operation,\n            \"locations\": locations,\n            \"ip_addresses\": ip_addresses,\n            \"parameters\": parameters,\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: Config not found for: {', '.join(domains)}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        error_msg = f\"\"\"❌ **Конфигурация не найдена**\n🔍 **Домены:** {', '.join(domains)}\n📊 **Просканировано:** {scanned_files} файлов\n\"\"\"\n        return Data(data=not_found_result, text=error_msg)\n\n    def _return_json_error(self, error: Exception, raw_json: str) -> Data:\n        \"\"\"Возвращает ошибку парсинга JSON\"\"\"\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"JSON_PARSE_ERROR\",\n            \"error_message\": f\"Ошибка парсинга JSON: {str(error)}\",\n            \"raw_input\": raw_json[:500],\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: JSON parse error\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        return Data(data=error_result, text=f\"❌ **Ошибка парсинга JSON**\\n\\n{str(error)}\")\n\n    def _return_unexpected_error(self, error: Exception) -> Data:\n        \"\"\"Возвращает неожиданную ошибку\"\"\"\n        import traceback\n        error_result = {\n            \"status\": \"error\",\n            \"error_type\": \"UNEXPECTED_ERROR\",\n            \"error_message\": f\"Неожиданная ошибка: {str(error)}\",\n            \"traceback\": traceback.format_exc(),\n            \"config_file\": \"N/A\",\n            \"config_key\": \"N/A\",\n            \"full_config_text\": f\"# Error: {str(error)}\",\n            \"data_complete\": False,\n            # 🆕 Добавляем ключи даже в ошибку для консистентности\n            \"found_in_multiple_dc\": False,\n            \"dc_count\": 0,\n            \"unique_dcs\": [],\n            \"domain_dc_mapping\": {},\n            \"domains_in_multiple_dc\": []\n        }\n        print(f\"❌ UNEXPECTED ERROR: {str(error)}\")\n        traceback.print_exc()\n        return Data(data=error_result, text=f\"❌ **Неожиданная ошибка**\\n\\n{str(error)}\")\n\n    # ==========================================\n    # ФОРМАТИРОВАНИЕ РЕЗУЛЬТАТА\n    # ==========================================\n    def _format_success_message(self, result: Dict) -> str:\n        \"\"\"Формирует читаемое сообщение о результате\"\"\"\n        all_configs = result.get(\"all_configs\", [])\n        found_configs = len(all_configs)\n        scanned_files = result.get(\"scanned_files\", 0)\n        operation = result.get(\"operation\")\n        locations = result.get(\"locations\", [])\n        upstreams = result.get(\"upstreams\", [])\n        location_parameters = result.get(\"location_parameters\", [])\n        selected_dc = result.get(\"selected_dc\", [])\n\n        # 🆕 Новые данные о multi-DC\n        found_in_multiple_dc = result.get(\"found_in_multiple_dc\", False)\n        dc_count = result.get(\"dc_count\", 0)\n        unique_dcs = result.get(\"unique_dcs\", [])\n        domains_in_multiple_dc = result.get(\"domains_in_multiple_dc\", [])\n        domain_dc_mapping = result.get(\"domain_dc_mapping\", {})\n\n        msg = f\"✅ **Найдено {found_configs} конфигурац{'ия' if found_configs == 1 else 'ий' if 2 <= found_configs <= 4 else 'ий'}**\\n\\n\"\n\n        # 🆕 Предупреждение о нескольких ЦОД\n        if found_in_multiple_dc:\n            msg += f\"⚠️ **ВНИМАНИЕ: Домен найден в {dc_count} ЦОД!**\\n\\n\"\n\n            msg += f\"🏢 **ЦОД:** {', '.join(unique_dcs)}\\n\"\n            if domains_in_multiple_dc:\n                msg += f\"🌐 **Домены в нескольких ЦОД:** {', '.join(domains_in_multiple_dc)}\\n\"\n            msg += \"\\n\"\n\n        for i, cfg in enumerate(all_configs):\n            if i > 0:\n                msg += \"\\n\" + (\"-\" * 40) + \"\\n\\n\"\n            msg += f\"📁 **Файл:** `{os.path.basename(cfg['config_file'])}`\\n\"\n            server_names = cfg.get(\"server_names\", [])\n            msg += f\"🌐 **Server names:** {', '.join(server_names[:3])}{'...' if len(server_names) > 3 else ''}\\n\"\n            matching_domains = cfg.get(\"matching_domains\", [])\n            msg += f\"✅ **Совпадения:** {', '.join(matching_domains)}\\n\"\n            inferred_dc = cfg.get(\"inferred_dc\", [])\n            if inferred_dc:\n                msg += f\"🏢 **DC:** {', '.join(inferred_dc)}\\n\"\n            else:\n                msg += f\"🏢 **DC:** N/A\\n\"\n\n        msg += f\"\\n📊 **Просканировано:** {scanned_files} файлов\"\n\n        if selected_dc:\n            msg += f\"\\n🗺 **Selected DC:** {', '.join(selected_dc)}\"\n        if operation:\n            msg += f\"\\n🔄 **Operation:** {operation}\"\n        if locations:\n            msg += f\"\\n📍 **Locations:** {', '.join(locations[:5])}\"\n        if upstreams:\n            for up in upstreams[:2]:\n                ips = up.get(\"ip_addresses\", [])\n                up_type = up.get(\"type\", \"unknown\")\n                msg += f\"\\n🔗 **Upstream ({up_type}):** {', '.join(ips[:3])}\"\n        if location_parameters:\n            msg += f\"\\n⚙️ **Location params:** {len(location_parameters)} записей\"\n\n        # 🆕 Расширенное примечание\n        if found_in_multiple_dc:\n            msg += \"\\n\\n⚠️ **ВАЖНО:** Конфигурация найдена в нескольких ЦОД. \"\n            msg += \"Убедитесь, что изменения применяются ко всем необходимым площадкам!\"\n            # Детальный маппинг\n            if domain_dc_mapping:\n                msg += \"\\n\\n📋 **Детали по доменам:**\"\n                for domain, dcs in domain_dc_mapping.items():\n                    if len(dcs) > 1:\n                        msg += f\"\\n  • `{domain}` → {', '.join(dcs)}\"\n        elif found_configs > 1:\n            msg += \"\\n\\nℹ️ **Примечание:** Найдено несколько конфигураций. Проверьте все варианты.\"\n\n        return msg\n"
              },
              "config_base_path": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Config Base Path",
                "dynamic": false,
                "info": "Путь к родительской папке с конфигами (например, /path/to/mos_ru_nginx/)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "config_base_path",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/production_kor_sites"
              }
            },
            "tool_mode": false
          },
          "selected_output": "config_file_path",
          "showNode": true,
          "type": "UniversalSearchConfigComponent"
        },
        "dragging": false,
        "id": "UniversalSearchConfigComponent-RvEQ1",
        "measured": {
          "height": 317,
          "width": 320
        },
        "position": {
          "x": 6482.573689431036,
          "y": 2414.1820181860307
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-HriUz",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{location_path}\n{operation}\n{upstreams}\n{agent1_data}"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-HriUz",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 9108.445583442872,
          "y": 3104.342786014836
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TypeConverterComponent-6M3Tu",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert between different types (Message, Data, DataFrame)",
            "display_name": "Type Convert",
            "documentation": "https://docs.langflow.org/components-processing#type-convert",
            "edited": false,
            "field_order": [
              "input_data",
              "output_type"
            ],
            "frozen": false,
            "icon": "repeat",
            "key": "TypeConverterComponent",
            "last_updated": "2025-11-21T11:34:07.249Z",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data Output",
                "group_outputs": false,
                "hidden": null,
                "method": "convert_to_data",
                "name": "data_output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.008834292878014125,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, Output, TabInput\nfrom langflow.schema import Data, DataFrame, Message\n\n\ndef convert_to_message(v) -> Message:\n    \"\"\"Convert input to Message type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Message: Converted Message object\n    \"\"\"\n    return v if isinstance(v, Message) else v.to_message()\n\n\ndef convert_to_data(v: DataFrame | Data | Message | dict) -> Data:\n    \"\"\"Convert input to Data type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        Data: Converted Data object\n    \"\"\"\n    if isinstance(v, dict):\n        return Data(v)\n    if isinstance(v, Message):\n        return v.to_data()\n    return v if isinstance(v, Data) else v.to_data()\n\n\ndef convert_to_dataframe(v: DataFrame | Data | Message | dict) -> DataFrame:\n    \"\"\"Convert input to DataFrame type.\n\n    Args:\n        v: Input to convert (Message, Data, DataFrame, or dict)\n\n    Returns:\n        DataFrame: Converted DataFrame object\n    \"\"\"\n    if isinstance(v, dict):\n        return DataFrame([v])\n    return v if isinstance(v, DataFrame) else v.to_dataframe()\n\n\nclass TypeConverterComponent(Component):\n    display_name = \"Type Convert\"\n    description = \"Convert between different types (Message, Data, DataFrame)\"\n    documentation: str = \"https://docs.langflow.org/components-processing#type-convert\"\n    icon = \"repeat\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Input\",\n            input_types=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Accept Message, Data or DataFrame as input\",\n            required=True,\n        ),\n        TabInput(\n            name=\"output_type\",\n            display_name=\"Output Type\",\n            options=[\"Message\", \"Data\", \"DataFrame\"],\n            info=\"Select the desired output data type\",\n            real_time_refresh=True,\n            value=\"Message\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message Output\",\n            name=\"message_output\",\n            method=\"convert_to_message\",\n        )\n    ]\n\n    def update_outputs(self, frontend_node: dict, field_name: str, field_value: Any) -> dict:\n        \"\"\"Dynamically show only the relevant output based on the selected output type.\"\"\"\n        if field_name == \"output_type\":\n            # Start with empty outputs\n            frontend_node[\"outputs\"] = []\n\n            # Add only the selected output type\n            if field_value == \"Message\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Message Output\",\n                        name=\"message_output\",\n                        method=\"convert_to_message\",\n                    ).to_dict()\n                )\n            elif field_value == \"Data\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"Data Output\",\n                        name=\"data_output\",\n                        method=\"convert_to_data\",\n                    ).to_dict()\n                )\n            elif field_value == \"DataFrame\":\n                frontend_node[\"outputs\"].append(\n                    Output(\n                        display_name=\"DataFrame Output\",\n                        name=\"dataframe_output\",\n                        method=\"convert_to_dataframe\",\n                    ).to_dict()\n                )\n\n        return frontend_node\n\n    def convert_to_message(self) -> Message:\n        \"\"\"Convert input to Message type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_message(input_value)\n        self.status = result\n        return result\n\n    def convert_to_data(self) -> Data:\n        \"\"\"Convert input to Data type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_data(input_value)\n        self.status = result\n        return result\n\n    def convert_to_dataframe(self) -> DataFrame:\n        \"\"\"Convert input to DataFrame type.\"\"\"\n        input_value = self.input_data[0] if isinstance(self.input_data, list) else self.input_data\n\n        # Handle string input by converting to Message first\n        if isinstance(input_value, str):\n            input_value = Message(text=input_value)\n\n        result = convert_to_dataframe(input_value)\n        self.status = result\n        return result\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "Accept Message, Data or DataFrame as input",
                "input_types": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "output_type": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Output Type",
                "dynamic": false,
                "info": "Select the desired output data type",
                "name": "output_type",
                "options": [
                  "Message",
                  "Data",
                  "DataFrame"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Data"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TypeConverterComponent"
        },
        "dragging": false,
        "id": "TypeConverterComponent-6M3Tu",
        "measured": {
          "height": 261,
          "width": 320
        },
        "position": {
          "x": 11439.16316173652,
          "y": 4031.066645394195
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-xTkpM",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}\n"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-xTkpM",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 9811.750971432195,
          "y": 3668.421501763646
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-CeAWi",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007216440637271487,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-CeAWi",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 10247.609156749597,
          "y": 3929.956202645129
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "JSONCleaner-g1nlX",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.",
            "display_name": "JSON Cleaner",
            "documentation": "",
            "edited": false,
            "field_order": [
              "json_str",
              "remove_control_chars",
              "normalize_unicode",
              "validate_json"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "JSONCleaner",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Cleaned JSON String",
                "group_outputs": false,
                "method": "clean_json",
                "name": "output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.ParserComponent"
            ],
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport unicodedata\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import BoolInput, MessageTextInput\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass JSONCleaner(Component):\n    icon = \"braces\"\n    display_name = \"JSON Cleaner\"\n    description = (\n        \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs \"\n        \"so that they are fully compliant with the JSON spec.\"\n    )\n    legacy = True\n    replacement = [\"processing.ParserComponent\"]\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json\n        except ImportError as e:\n            msg = \"Could not import the json_repair package. Please install it with `pip install json_repair`.\"\n            raise ImportError(msg) from e\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        start = json_str.find(\"{\")\n        end = json_str.rfind(\"}\")\n        if start == -1 or end == -1:\n            msg = \"Invalid JSON string: Missing '{' or '}'\"\n            raise ValueError(msg)\n        try:\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            msg = f\"Error cleaning JSON string: {e}\"\n            raise ValueError(msg) from e\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return s.translate(self.translation_table)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n        except json.JSONDecodeError as e:\n            msg = f\"Invalid JSON string: {e}\"\n            raise ValueError(msg) from e\n        return s\n\n    def __init__(self, *args, **kwargs):\n        # Create a translation table that maps control characters to None\n        super().__init__(*args, **kwargs)\n        self.translation_table = str.maketrans(\"\", \"\", \"\".join(chr(i) for i in range(32)) + chr(127))\n"
              },
              "json_str": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JSON String",
                "dynamic": false,
                "info": "The JSON string to be cleaned.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "json_str",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "normalize_unicode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Normalize Unicode",
                "dynamic": false,
                "info": "Normalize Unicode characters in the JSON string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "normalize_unicode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "remove_control_chars": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Remove Control Characters",
                "dynamic": false,
                "info": "Remove control characters from the JSON string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "remove_control_chars",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "validate_json": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Validate JSON",
                "dynamic": false,
                "info": "Validate the JSON string to ensure it is well-formed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "validate_json",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "JSONCleaner"
        },
        "dragging": false,
        "id": "JSONCleaner-g1nlX",
        "measured": {
          "height": 440,
          "width": 320
        },
        "position": {
          "x": 11728.967015802526,
          "y": 1879.8883419459837
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "JSONCleaner-9rVTs",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.",
            "display_name": "JSON Cleaner",
            "documentation": "",
            "edited": false,
            "field_order": [
              "json_str",
              "remove_control_chars",
              "normalize_unicode",
              "validate_json"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "JSONCleaner",
            "legacy": true,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Cleaned JSON String",
                "group_outputs": false,
                "method": "clean_json",
                "name": "output",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "replacement": [
              "processing.ParserComponent"
            ],
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport unicodedata\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import BoolInput, MessageTextInput\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass JSONCleaner(Component):\n    icon = \"braces\"\n    display_name = \"JSON Cleaner\"\n    description = (\n        \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs \"\n        \"so that they are fully compliant with the JSON spec.\"\n    )\n    legacy = True\n    replacement = [\"processing.ParserComponent\"]\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json\n        except ImportError as e:\n            msg = \"Could not import the json_repair package. Please install it with `pip install json_repair`.\"\n            raise ImportError(msg) from e\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        start = json_str.find(\"{\")\n        end = json_str.rfind(\"}\")\n        if start == -1 or end == -1:\n            msg = \"Invalid JSON string: Missing '{' or '}'\"\n            raise ValueError(msg)\n        try:\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            msg = f\"Error cleaning JSON string: {e}\"\n            raise ValueError(msg) from e\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return s.translate(self.translation_table)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n        except json.JSONDecodeError as e:\n            msg = f\"Invalid JSON string: {e}\"\n            raise ValueError(msg) from e\n        return s\n\n    def __init__(self, *args, **kwargs):\n        # Create a translation table that maps control characters to None\n        super().__init__(*args, **kwargs)\n        self.translation_table = str.maketrans(\"\", \"\", \"\".join(chr(i) for i in range(32)) + chr(127))\n"
              },
              "json_str": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "JSON String",
                "dynamic": false,
                "info": "The JSON string to be cleaned.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "json_str",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "normalize_unicode": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Normalize Unicode",
                "dynamic": false,
                "info": "Normalize Unicode characters in the JSON string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "normalize_unicode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "remove_control_chars": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Remove Control Characters",
                "dynamic": false,
                "info": "Remove control characters from the JSON string.",
                "list": false,
                "list_add_label": "Add More",
                "name": "remove_control_chars",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "validate_json": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Validate JSON",
                "dynamic": false,
                "info": "Validate the JSON string to ensure it is well-formed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "validate_json",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "JSONCleaner"
        },
        "dragging": false,
        "id": "JSONCleaner-9rVTs",
        "measured": {
          "height": 440,
          "width": 320
        },
        "position": {
          "x": 10589.737226386562,
          "y": 3145.492327631344
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-hZzcn",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007216440637271487,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-hZzcn",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 10043.517223142564,
          "y": 1822.4134394701305
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "NginxConfigAssemblerAST-qbIoX",
          "node": {
            "base_classes": [
              "Data",
              "Text"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Собирает YAML конфиг Nginx. Поддерживает работу в цикле с накоплением изменений.",
            "display_name": "Nginx Config Assembler (AST)",
            "documentation": "",
            "edited": true,
            "field_order": [
              "llm_responses",
              "parser_output",
              "output_dir",
              "is_final",
              "clear_cache"
            ],
            "frozen": false,
            "icon": "file-code",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "group_outputs": false,
                "hidden": null,
                "method": "build_output",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "YAML String",
                "group_outputs": false,
                "hidden": null,
                "method": "get_yaml_string",
                "name": "yaml_output",
                "options": null,
                "required_inputs": null,
                "selected": "Text",
                "tool_mode": true,
                "types": [
                  "Text"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "All Changes",
                "group_outputs": false,
                "hidden": null,
                "method": "get_all_changes",
                "name": "all_changes",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clear_cache": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Clear Cache",
                "dynamic": false,
                "info": "Очистить кэш перед обработкой (начать заново)",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "clear_cache",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output, BoolInput\nfrom langflow.schema.data import Data\nimport json\nimport re\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Tuple, Optional\nimport yaml\nimport hashlib\n\n\nclass MyDumper(yaml.Dumper):\n    def increase_indent(self, flow=False, indentless=False):\n        return super(MyDumper, self).increase_indent(flow, False)\n\n\nclass NginxConfigAssemblerAST(Component):\n    display_name = \"Nginx Config Assembler (AST)\"\n    description = \"Собирает YAML конфиг Nginx. Поддерживает работу в цикле с накоплением изменений.\"\n    icon = \"file-code\"\n    name = \"NginxConfigAssemblerAST\"\n\n    # Хранилище для накопления изменений между вызовами\n    _config_cache: Dict[str, Dict[str, Any]] = {}  # path -> {config, ast, changes}\n\n    inputs = [\n        MessageTextInput(\n            name=\"llm_responses\",\n            display_name=\"LLM Responses\",\n            info=\"JSON ответы от LLM\",\n            value=\"\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"parser_output\",\n            display_name=\"Parser Output\",\n            info=\"Выход от парсера с полями: Index, Operation, Config Key, Config File и др.\",\n            value=\"\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"output_dir\",\n            display_name=\"Output Directory\",\n            info=\"Директория для сохранения результатов\",\n            value=\"/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/output/\",\n            tool_mode=False,\n        ),\n        BoolInput(\n            name=\"is_final\",\n            display_name=\"Is Final Iteration\",\n            info=\"Финальная итерация цикла — сохранить все накопленные изменения\",\n            value=False,\n        ),\n        BoolInput(\n            name=\"clear_cache\",\n            display_name=\"Clear Cache\",\n            info=\"Очистить кэш перед обработкой (начать заново)\",\n            value=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n        Output(display_name=\"YAML String\", name=\"yaml_output\", method=\"get_yaml_string\"),\n        Output(display_name=\"All Changes\", name=\"all_changes\", method=\"get_all_changes\"),\n    ]\n\n    # ================== Parser Output Parsing ==================\n\n    def parse_parser_output(self, parser_output: str) -> Dict[str, Any]:\n        \"\"\"\n        Парсит выход от парсера в формате:\n        - Index: {index}\n        - Operation: {operation}\n        - Config Key: {config_key}\n        - Config File: {config_file}\n        - Location Path: {location_path}\n        - Type: {type}\n        - Directives: {directives}\n        - Parameters: {parameters}\n        - ServerBlockParameters: {server_block_parameters}\n        - IP Addresses: {ip_addresses}\n        - KMS Required: {kms_required}\n        - Create Mode: {create_mode}\n        - Delete Mode: {delete_mode}\n        - New Location Path: {new_location_path}\n        - Existing Locations: {existing_locations}\n        - Matching Domains: {matching_domains}\n        - Server Names: {server_names}\n        - Hash: {hash}\n        - Warnings: {warnings}\n        \"\"\"\n        if not parser_output:\n            return {}\n\n        result = {}\n\n        # Маппинг имён полей из парсера на внутренние имена\n        field_mapping = {\n            'index': 'index',\n            'operation': 'operation',\n            'config key': 'config_key',\n            'config file': 'config_file',\n            'location path': 'location_path',\n            'type': 'type',\n            'directives': 'directives',\n            'parameters': 'parameters',\n            'serverblockparameters': 'server_block_parameters',\n            'ip addresses': 'ip_addresses',\n            'kms required': 'kms_required',\n            'create mode': 'create_mode',\n            'delete mode': 'delete_mode',\n            'new location path': 'new_location_path',\n            'existing locations': 'existing_locations',\n            'matching domains': 'matching_domains',\n            'server names': 'server_names',\n            'hash': 'hash',\n            'warnings': 'warnings',\n        }\n\n        lines = parser_output.strip().split('\\n')\n\n        for line in lines:\n            line = line.strip()\n            if not line or not line.startswith('-'):\n                continue\n\n            # Убираем начальный \"- \"\n            line = line[1:].strip()\n\n            # Разделяем по первому \":\"\n            if ':' not in line:\n                continue\n\n            key_part, value_part = line.split(':', 1)\n            key = key_part.strip().lower()\n            value = value_part.strip()\n\n            # Маппим ключ\n            internal_key = field_mapping.get(key)\n            if not internal_key:\n                continue\n\n            # Парсим значение\n            parsed_value = self._parse_field_value(internal_key, value)\n            result[internal_key] = parsed_value\n\n        return result\n\n    def _parse_field_value(self, field_name: str, value: str) -> Any:\n        \"\"\"Парсит значение поля в зависимости от его типа\"\"\"\n        if not value or value.lower() in ('none', 'null', ''):\n            return None\n\n        # Булевые поля\n        if field_name in ('kms_required', 'create_mode', 'delete_mode'):\n            return value.lower() in ('true', '1', 'yes')\n\n        # Поля-списки\n        if field_name in ('directives', 'parameters', 'server_block_parameters',\n                          'ip_addresses', 'existing_locations', 'matching_domains',\n                          'server_names', 'warnings'):\n            # Пробуем JSON\n            if value.startswith('['):\n                try:\n                    return json.loads(value)\n                except:\n                    pass\n            # Пробуем через запятую\n            if ',' in value:\n                return [v.strip() for v in value.split(',') if v.strip()]\n            # Одиночное значение\n            return [value] if value else []\n\n        # Числовые поля\n        if field_name == 'index':\n            try:\n                return int(value)\n            except:\n                return 0\n\n        return value\n\n    # ================== Cache Management ==================\n\n    def get_cache_key(self, file_path: str) -> str:\n        \"\"\"Генерирует ключ кэша из пути файла\"\"\"\n        return str(Path(file_path).resolve())\n\n    def get_cached_ast(self, file_path: str) -> Optional[Tuple[Dict, str, List]]:\n        \"\"\"Получает AST из кэша или загружает из файла\"\"\"\n        key = self.get_cache_key(file_path)\n\n        if key in self._config_cache:\n            cached = self._config_cache[key]\n            return cached['config'], cached['config_key'], cached['ast']\n\n        return None\n\n    def cache_ast(self, file_path: str, config: Dict, config_key: str, ast: List, changes: List[str]):\n        \"\"\"Сохраняет AST в кэш\"\"\"\n        key = self.get_cache_key(file_path)\n\n        if key not in self._config_cache:\n            self._config_cache[key] = {\n                'config': config,\n                'config_key': config_key,\n                'ast': ast,\n                'changes': [],\n                'original_hash': self.compute_hash(ast)\n            }\n\n        self._config_cache[key]['ast'] = ast\n        self._config_cache[key]['changes'].extend(changes)\n\n    def get_all_cached_changes(self) -> Dict[str, List[str]]:\n        \"\"\"Возвращает все накопленные изменения\"\"\"\n        return {k: v['changes'] for k, v in self._config_cache.items()}\n\n    def clear_all_cache(self):\n        \"\"\"Очищает весь кэш\"\"\"\n        self._config_cache.clear()\n\n    def compute_hash(self, ast: List) -> str:\n        \"\"\"Вычисляет хэш AST для отслеживания изменений\"\"\"\n        return hashlib.md5(json.dumps(ast, sort_keys=True, default=str).encode()).hexdigest()\n\n    # ================== File Operations ==================\n\n    def load_yaml_config(self, file_path: str) -> Tuple[Dict[str, Any], str, List[str]]:\n        if not file_path:\n            raise ValueError(\"Путь к файлу не указан\")\n\n        path = Path(file_path.strip())\n        if not path.exists():\n            raise FileNotFoundError(f\"Файл не найден: {file_path}\")\n\n        text = path.read_text(encoding=\"utf-8\")\n        data = yaml.safe_load(text)\n\n        if not data or not isinstance(data, dict):\n            raise ValueError(\"Некорректный YAML\")\n\n        config_key = list(data.keys())[0]\n        directives = data[config_key]\n\n        if not isinstance(directives, list):\n            raise ValueError(\"Ожидался список директив\")\n\n        return data, config_key, directives\n\n    def save_config(self, file_path: str, config: Dict, config_key: str, ast: List) -> str:\n        \"\"\"Сохраняет конфиг в файл\"\"\"\n        new_directives = self.render_ast(ast)\n        config[config_key] = new_directives\n\n        yaml_result = yaml.dump(\n            config,\n            default_flow_style=False,\n            allow_unicode=True,\n            sort_keys=False,\n            width=4096,\n            Dumper=MyDumper,\n        )\n\n        path = Path(file_path)\n        path.parent.mkdir(parents=True, exist_ok=True)\n        path.write_text(yaml_result, encoding='utf-8')\n\n        return yaml_result\n\n    def get_output_path(self, source_path: str, output_dir: str) -> str:\n        \"\"\"Генерирует путь для выходного файла\"\"\"\n        source = Path(source_path)\n        out_dir = Path(output_dir) if output_dir else source.parent\n\n        # Добавляем _modified к имени\n        new_name = f\"{source.stem}_modified{source.suffix}\"\n        return str(out_dir / new_name)\n\n    # ================== JSON Extraction ==================\n\n    def extract_json_blocks(self, text: str) -> List[Dict[str, Any]]:\n        if not text:\n            return []\n\n        results: List[Dict[str, Any]] = []\n\n        # 1. Пробуем ```json блоки\n        json_blocks = re.findall(r'```json\\s*(.*?)\\s*```', text, re.DOTALL)\n        for block in json_blocks:\n            try:\n                parsed = json.loads(block)\n                if isinstance(parsed, dict):\n                    results.append(parsed)\n                elif isinstance(parsed, list):\n                    results.extend(parsed)\n            except Exception:\n                continue\n\n        if results:\n            return results\n\n        # 2. Пробуем как единый JSON (объект или массив)\n        try:\n            parsed = json.loads(text)\n            if isinstance(parsed, dict):\n                return [parsed]\n            if isinstance(parsed, list):\n                return parsed\n        except Exception:\n            pass\n\n        # 3. Пробуем несколько JSON объектов подряд (разделённых переносами или пробелами)\n        # Ищем все {...} на верхнем уровне\n        brace_depth = 0\n        current_start = None\n\n        for i, char in enumerate(text):\n            if char == '{':\n                if brace_depth == 0:\n                    current_start = i\n                brace_depth += 1\n            elif char == '}':\n                brace_depth -= 1\n                if brace_depth == 0 and current_start is not None:\n                    json_str = text[current_start:i + 1]\n                    try:\n                        results.append(json.loads(json_str))\n                    except Exception:\n                        pass\n                    current_start = None\n\n        if results:\n            return results\n\n        # 4. Пробуем построчно\n        for line in text.strip().split('\\n'):\n            line = line.strip()\n            if line.startswith('{') and line.endswith('}'):\n                try:\n                    results.append(json.loads(line))\n                except Exception:\n                    continue\n\n        return results\n\n    # ================== AST Operations ==================\n\n    def parse_directive_name(self, line: str) -> str:\n        if not line:\n            return \"\"\n        line = str(line).strip().lstrip('- ').rstrip(';')\n        if line.startswith('location'):\n            return 'location'\n        match = re.match(r'^(\\w+)', line)\n        return match.group(1) if match else line\n\n    def parse_directive_value(self, line: str) -> Optional[str]:\n        if not line:\n            return None\n        line = str(line).strip().lstrip('- ').rstrip(';')\n        parts = line.split(None, 1)\n        return parts[1] if len(parts) > 1 else None\n\n    def parse_location_path(self, line: str) -> Optional[str]:\n        if not line:\n            return None\n        match = re.match(r'location\\s+([^\\s{]+)', str(line).strip())\n        return match.group(1) if match else None\n\n    def parse_location_inner(self, line: str) -> List[str]:\n        if not line:\n            return []\n        match = re.search(r'\\{(.+)\\}', str(line))\n        if not match:\n            return []\n        inner = match.group(1).strip()\n        return [p.strip() for p in inner.split(';') if p.strip()]\n\n    def build_ast(self, directives: List[str]) -> List[Dict[str, Any]]:\n        ast: List[Dict[str, Any]] = []\n\n        for line in directives:\n            if line is None:\n                continue\n            line_str = str(line).strip()\n            if not line_str:\n                continue\n\n            if line_str.startswith('location'):\n                ast.append({\n                    'type': 'location',\n                    'path': self.parse_location_path(line_str) or '/',\n                    'directives': self.parse_location_inner(line_str),\n                    'raw': line_str\n                })\n            else:\n                ast.append({\n                    'type': 'directive',\n                    'name': self.parse_directive_name(line_str),\n                    'value': self.parse_directive_value(line_str),\n                    'raw': line_str\n                })\n\n        return ast\n\n    def render_ast(self, ast: List[Dict[str, Any]]) -> List[str]:\n        result: List[str] = []\n\n        for node in ast:\n            if node.get('type') == 'directive':\n                name = node.get('name', '')\n                value = node.get('value')\n                result.append(f\"{name} {value}\" if value else name)\n            elif node.get('type') == 'location':\n                path = node.get('path', '/')\n                inner = node.get('directives', [])\n                inner_str = '; '.join(str(d).rstrip(';') for d in inner if d)\n                if inner_str:\n                    inner_str += ';'\n                result.append(f\"location {path} {{ {inner_str}}}\")\n\n        return result\n\n    # ================== AST Helpers ==================\n\n    def is_server_block_target(self, location_value: Any) -> bool:\n        if not location_value:\n            return True\n        loc_str = str(location_value).lower().strip()\n        return loc_str in ('server_block', 'server', 'root', '', 'none', 'null')\n\n    def find_location_index(self, ast: List[Dict[str, Any]], path: str) -> Optional[int]:\n        for i, node in enumerate(ast):\n            if node.get('type') == 'location' and node.get('path') == path:\n                return i\n        return None\n\n    def find_root_location_index(self, ast: List[Dict[str, Any]]) -> int:\n        for i, node in enumerate(ast):\n            if node.get('type') == 'location' and node.get('path') == '/':\n                return i\n        return len(ast)\n\n    def extract_deleted_from_changes_made(self, changes_made: List[str]) -> List[str]:\n        deleted = []\n        for change in changes_made:\n            if not change:\n                continue\n            change_lower = str(change).lower()\n            if 'removed' in change_lower or 'deleted' in change_lower:\n                match = re.search(r\"['\\\"]([^'\\\"]+)['\\\"]\", str(change))\n                if match:\n                    deleted.append(match.group(1).strip().rstrip(';'))\n        return deleted\n\n    # ================== Operation Handlers ==================\n\n    def apply_create_location(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                              parser_data: Dict[str, Any]) -> List[str]:\n        \"\"\"CREATE_LOCATION — создаёт новый location\"\"\"\n        changes: List[str] = []\n\n        # Приоритет: response -> parser_data\n        location_path = (\n                response.get('location_path') or\n                response.get('location') or\n                response.get('path') or\n                parser_data.get('location_path')\n        )\n\n        if not location_path or self.is_server_block_target(location_path):\n            return [\"CREATE_LOCATION: некорректный location_path\"]\n\n        if self.find_location_index(ast, location_path) is not None:\n            return [f\"Location {location_path} уже существует\"]\n\n        # Собираем директивы из разных источников\n        updated_directives = response.get('updated_directives', [])\n        location_parameters = response.get('location_parameters', {})\n        parser_directives = parser_data.get('directives', [])\n        parser_parameters = parser_data.get('parameters', [])\n\n        inner_directives: List[str] = []\n\n        # Из updated_directives (LLM)\n        for d in updated_directives:\n            if not d:\n                continue\n            d_str = str(d).strip()\n            if d_str.startswith('location') or d_str == '}':\n                continue\n            d_str = d_str.strip().rstrip(';')\n            if d_str:\n                inner_directives.append(d_str)\n\n        # Из location_parameters (LLM)\n        if isinstance(location_parameters, dict):\n            for name, value in location_parameters.items():\n                if isinstance(value, list):\n                    for v in value:\n                        inner_directives.append(f\"{name} {v}\")\n                else:\n                    inner_directives.append(f\"{name} {value}\")\n\n        # Из parser_data (если LLM не предоставил)\n        if not inner_directives:\n            for d in parser_directives:\n                if d and not str(d).startswith('location'):\n                    inner_directives.append(str(d).strip().rstrip(';'))\n            for p in parser_parameters:\n                if p:\n                    inner_directives.append(str(p).strip().rstrip(';'))\n\n        insert_pos = self.find_root_location_index(ast)\n        ast.insert(insert_pos, {\n            'type': 'location',\n            'path': location_path,\n            'directives': inner_directives,\n            'raw': ''\n        })\n\n        changes.append(f\"✅ Создан location {location_path}\")\n        return changes\n\n    def apply_delete_location(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                              parser_data: Dict[str, Any]) -> List[str]:\n        \"\"\"DELETE_LOCATION — удаляет весь location блок\"\"\"\n        changes: List[str] = []\n\n        location_path = (\n                response.get('location_path') or\n                response.get('location') or\n                response.get('path') or\n                parser_data.get('location_path')\n        )\n\n        if not location_path or self.is_server_block_target(location_path):\n            return [\"DELETE_LOCATION: некорректный location_path\"]\n\n        idx = self.find_location_index(ast, location_path)\n        if idx is None:\n            return [f\"Location {location_path} не найден\"]\n\n        ast.pop(idx)\n        changes.append(f\"🗑️ Удалён location {location_path}\")\n        return changes\n\n    def apply_modify_location_path(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                                   parser_data: Dict[str, Any]) -> List[str]:\n        \"\"\"MODIFY_LOCATION_PATH — переименовывает location\"\"\"\n        changes: List[str] = []\n\n        old_path = (\n                response.get('location_path') or\n                response.get('old_location') or\n                response.get('location') or\n                parser_data.get('location_path')\n        )\n        new_path = (\n                response.get('new_location_path') or\n                response.get('new_path') or\n                parser_data.get('new_location_path')\n        )\n\n        if not old_path or not new_path:\n            return [\"MODIFY_LOCATION_PATH: нужны old и new path\"]\n\n        idx = self.find_location_index(ast, old_path)\n        if idx is None:\n            return [f\"Location {old_path} не найден\"]\n\n        if self.find_location_index(ast, new_path) is not None:\n            return [f\"Location {new_path} уже существует\"]\n\n        ast[idx]['path'] = new_path\n        changes.append(f\"📝 Переименован location: {old_path} → {new_path}\")\n        return changes\n\n    def apply_make_protected(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                             parser_data: Dict[str, Any]) -> List[str]:\n        \"\"\"MAKE_PROTECTED — добавляет KMS защиту (allow/deny)\"\"\"\n        changes: List[str] = []\n\n        location_path = (\n                response.get('location_path') or\n                response.get('location') or\n                parser_data.get('location_path')\n        )\n\n        # IP адреса из parser_data или стандартные\n        ip_addresses = parser_data.get('ip_addresses', [])\n        if ip_addresses:\n            kms_directives = [f'allow {ip}' for ip in ip_addresses] + ['deny all']\n        else:\n            kms_directives = ['allow 10.0.0.0/8', 'deny all']\n\n        if self.is_server_block_target(location_path):\n            # Добавляем в server block\n            for d in kms_directives:\n                name = self.parse_directive_name(d)\n                # Проверяем нет ли уже\n                exists = any(n.get('name') == name for n in ast if n.get('type') == 'directive')\n                if not exists:\n                    insert_pos = self.find_root_location_index(ast)\n                    ast.insert(insert_pos, {\n                        'type': 'directive',\n                        'name': name,\n                        'value': self.parse_directive_value(d),\n                        'raw': d\n                    })\n                    changes.append(f\"🔒 Добавлено: {d}\")\n        else:\n            # Добавляем в location\n            idx = self.find_location_index(ast, location_path)\n            if idx is None:\n                return [f\"Location {location_path} не найден\"]\n\n            existing = ast[idx].get('directives', [])\n            for d in kms_directives:\n                name = self.parse_directive_name(d)\n                if not any(self.parse_directive_name(str(e)) == name for e in existing):\n                    existing.append(d)\n                    changes.append(f\"🔒 Добавлено в {location_path}: {d}\")\n            ast[idx]['directives'] = existing\n\n        return changes\n\n    def apply_make_public(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                          parser_data: Dict[str, Any]) -> List[str]:\n        \"\"\"MAKE_PUBLIC — удаляет KMS защиту\"\"\"\n        changes: List[str] = []\n\n        location_path = (\n                response.get('location_path') or\n                response.get('location') or\n                parser_data.get('location_path')\n        )\n        kms_names = ['allow', 'deny']\n\n        if self.is_server_block_target(location_path):\n            # Удаляем из server block\n            indices = []\n            for i, node in enumerate(ast):\n                if node.get('type') == 'directive' and node.get('name') in kms_names:\n                    indices.append(i)\n                    changes.append(f\"🔓 Удалено: {node.get('raw')}\")\n\n            for i in sorted(indices, reverse=True):\n                ast.pop(i)\n        else:\n            # Удаляем из location\n            idx = self.find_location_index(ast, location_path)\n            if idx is None:\n                return [f\"Location {location_path} не найден\"]\n\n            existing = ast[idx].get('directives', [])\n            new_existing = []\n            for d in existing:\n                if self.parse_directive_name(str(d)) in kms_names:\n                    changes.append(f\"🔓 Удалено из {location_path}: {d}\")\n                else:\n                    new_existing.append(d)\n            ast[idx]['directives'] = new_existing\n\n        return changes\n\n    def apply_replace_server_block(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                                   parser_data: Dict[str, Any]) -> List[str]:\n        \"\"\"Полная замена server block (когда LLM возвращает результирующий конфиг)\"\"\"\n        changes: List[str] = []\n\n        updated_directives = response.get('updated_directives', [])\n        server_block_params = parser_data.get('server_block_parameters', [])\n\n        if not updated_directives and not server_block_params:\n            return [\"REPLACE: нет updated_directives\"]\n\n        # Сохраняем locations\n        locations = [node for node in ast if node.get('type') == 'location']\n\n        # Очищаем\n        ast.clear()\n\n        # Источник директив\n        directives_source = updated_directives if updated_directives else server_block_params\n\n        # Добавляем новые директивы\n        for d in directives_source:\n            if not d:\n                continue\n            d_str = str(d).strip().rstrip(';')\n            if not d_str or d_str.startswith('location'):\n                continue\n\n            ast.append({\n                'type': 'directive',\n                'name': self.parse_directive_name(d_str),\n                'value': self.parse_directive_value(d_str),\n                'raw': d_str\n            })\n\n        # Возвращаем locations\n        ast.extend(locations)\n\n        # Changes из response\n        for cm in response.get('changes_made', []):\n            if cm:\n                changes.append(str(cm))\n\n        return changes or [\"Server block обновлён\"]\n\n    def apply_modify_parameters(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                                parser_data: Dict[str, Any]) -> List[str]:\n        \"\"\"ADD/MODIFY параметры\"\"\"\n        changes: List[str] = []\n\n        location_path = (\n                response.get('location_path') or\n                response.get('location') or\n                parser_data.get('location_path')\n        )\n        is_server = self.is_server_block_target(location_path)\n\n        # Собираем параметры из разных источников\n        params = []\n\n        # Из LLM response\n        for key in ['updated_directives', 'parameters', 'server_block_parameters', 'location_parameters']:\n            val = response.get(key)\n            if isinstance(val, list):\n                params.extend(val)\n            elif isinstance(val, dict):\n                for name, value in val.items():\n                    if isinstance(value, list):\n                        for v in value:\n                            params.append(f\"{name} {v}\")\n                    else:\n                        params.append(f\"{name} {value}\")\n\n        # Из parser_data (если LLM не предоставил)\n        if not params:\n            for key in ['directives', 'parameters', 'server_block_parameters']:\n                val = parser_data.get(key, [])\n                if isinstance(val, list):\n                    params.extend(val)\n\n        if is_server:\n            for p in params:\n                if not p:\n                    continue\n                p_str = str(p).strip().rstrip(';')\n                if not p_str or p_str.startswith('location'):\n                    continue\n\n                name = self.parse_directive_name(p_str)\n                value = self.parse_directive_value(p_str)\n\n                # Ищем существующую\n                found_idx = None\n                for i, node in enumerate(ast):\n                    if node.get('type') == 'directive' and node.get('name') == name:\n                        found_idx = i\n                        break\n\n                if found_idx is not None:\n                    old = ast[found_idx].get('raw')\n                    ast[found_idx] = {'type': 'directive', 'name': name, 'value': value, 'raw': p_str}\n                    changes.append(f\"📝 Обновлено: {old} → {p_str}\")\n                else:\n                    insert_pos = self.find_root_location_index(ast)\n                    ast.insert(insert_pos, {'type': 'directive', 'name': name, 'value': value, 'raw': p_str})\n                    changes.append(f\"➕ Добавлено: {p_str}\")\n        else:\n            idx = self.find_location_index(ast, location_path)\n            if idx is None:\n                # Создаём location\n                inner = [str(p).strip().rstrip(';') for p in params if p and not str(p).startswith('location')]\n                insert_pos = self.find_root_location_index(ast)\n                ast.insert(insert_pos, {'type': 'location', 'path': location_path, 'directives': inner, 'raw': ''})\n                changes.append(f\"✅ Создан location {location_path}\")\n            else:\n                existing = ast[idx].get('directives', [])\n                for p in params:\n                    if not p:\n                        continue\n                    p_str = str(p).strip().rstrip(';')\n                    if not p_str or p_str.startswith('location'):\n                        continue\n\n                    name = self.parse_directive_name(p_str)\n\n                    # Ищем существующую\n                    found_i = None\n                    for i, e in enumerate(existing):\n                        if self.parse_directive_name(str(e)) == name:\n                            found_i = i\n                            break\n\n                    if found_i is not None:\n                        old = existing[found_i]\n                        existing[found_i] = p_str\n                        changes.append(f\"📝 В {location_path}: {old} → {p_str}\")\n                    else:\n                        existing.append(p_str)\n                        changes.append(f\"➕ В {location_path}: {p_str}\")\n\n                ast[idx]['directives'] = existing\n\n        return changes\n\n    def apply_delete_parameters(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                                parser_data: Dict[str, Any]) -> List[str]:\n        \"\"\"DELETE параметры\"\"\"\n        changes: List[str] = []\n\n        location_path = (\n                response.get('location_path') or\n                response.get('location') or\n                parser_data.get('location_path')\n        )\n        is_server = self.is_server_block_target(location_path)\n\n        # Определяем что удалять - РАСШИРЕННЫЙ ПОИСК\n        to_delete = (\n                response.get('directives_to_delete') or\n                response.get('parameters_to_delete') or\n                response.get('names') or\n                []\n        )\n        if isinstance(to_delete, str):\n            to_delete = [to_delete]\n\n        # Из changes_made\n        if not to_delete:\n            to_delete = self.extract_deleted_from_changes_made(response.get('changes_made', []))\n\n        # 🔴 NEW: Из parser_data если LLM не предоставил\n        if not to_delete:\n            # Выбираем источник в зависимости от location_path\n            if is_server:\n                params = parser_data.get('server_block_parameters', [])\n            else:\n                params = parser_data.get('parameters', [])\n\n            # Парсим имена директив из формата \"name:value\"\n            for param in params:\n                if not param:\n                    continue\n                clean = str(param).strip().rstrip(';')\n                if ':' in clean:\n                    name = clean.split(':', 1)[0].strip()\n                else:\n                    name = clean.split()[0].strip()\n                if name:\n                    to_delete.append(name)\n\n        # ... остальной код без изменений\n\n        normalized = [str(d).strip().rstrip(';') for d in to_delete if d]\n\n        if is_server:\n            indices = []\n            for del_d in normalized:\n                del_name = self.parse_directive_name(del_d)\n                del_value = self.parse_directive_value(del_d)\n\n                for i, node in enumerate(ast):\n                    if node.get('type') != 'directive' or i in indices:\n                        continue\n                    if node.get('name') == del_name:\n                        if del_value is None or node.get('value') == del_value:\n                            indices.append(i)\n                            changes.append(f\"🗑️ Удалено: {node.get('raw')}\")\n\n            for i in sorted(indices, reverse=True):\n                ast.pop(i)\n        else:\n            idx = self.find_location_index(ast, location_path)\n            if idx is None:\n                return [f\"Location {location_path} не найден\"]\n\n            existing = ast[idx].get('directives', [])\n            new_existing = []\n            for e in existing:\n                e_name = self.parse_directive_name(str(e))\n                should_del = any(self.parse_directive_name(d) == e_name for d in normalized)\n                if should_del:\n                    changes.append(f\"🗑️ Из {location_path}: {e}\")\n                else:\n                    new_existing.append(e)\n            ast[idx]['directives'] = new_existing\n\n        return changes\n\n    # ================== Main Dispatcher ==================\n\n    def apply_response(self, ast: List[Dict[str, Any]], response: Dict[str, Any],\n                       parser_data: Dict[str, Any]) -> List[str]:\n        if response.get('status') != 'success':\n            return [f\"⚠️ Пропущен: status={response.get('status')}\"]\n\n        # Операция из LLM или из parser\n        operation = (\n                response.get('operation_type') or\n                response.get('operation') or\n                parser_data.get('operation') or\n                ''\n        ).upper()\n\n        # Маппинг операций\n        handlers = {\n            'CREATE_LOCATION': self.apply_create_location,\n            'DELETE_LOCATION': self.apply_delete_location,\n            'MODIFY_LOCATION_PATH': self.apply_modify_location_path,\n            'MAKE_PROTECTED': self.apply_make_protected,\n            'MAKE_PUBLIC': self.apply_make_public,\n            'DELETE_PARAMETERS': self.apply_delete_parameters,\n            'DELETE_DIRECTIVE': self.apply_delete_parameters,\n            'REMOVE_DIRECTIVE': self.apply_delete_parameters,\n            'ADD_PARAMETERS': self.apply_modify_parameters,\n            'ADD_DIRECTIVE': self.apply_modify_parameters,\n            'MODIFY_PARAMETERS': self.apply_modify_parameters,\n            'UPDATE_DIRECTIVE': self.apply_modify_parameters,\n            'UPDATE_SERVER': self.apply_modify_parameters,\n            'UPDATE_LOCATION': self.apply_modify_parameters,\n        }\n\n        handler = handlers.get(operation)\n        if handler:\n            return handler(ast, response, parser_data)\n\n        # Эвристика по parser_data\n        if parser_data.get('delete_mode'):\n            return self.apply_delete_location(ast, response, parser_data)\n        if parser_data.get('create_mode'):\n            return self.apply_create_location(ast, response, parser_data)\n        if parser_data.get('kms_required'):\n            return self.apply_make_protected(ast, response, parser_data)\n\n        # Эвристика по response\n        if response.get('directives_to_delete') or response.get('parameters_to_delete'):\n            return self.apply_delete_parameters(ast, response, parser_data)\n        elif response.get('location_path') and not self.is_server_block_target(response.get('location_path')):\n            if response.get('updated_directives') or response.get('location_parameters'):\n                return self.apply_create_location(ast, response, parser_data)\n        elif response.get('updated_directives') or response.get('parameters'):\n            return self.apply_modify_parameters(ast, response, parser_data)\n\n        return [f\"⚠️ Неизвестная операция: {operation}\"]\n\n    # ================== Build ==================\n\n    def build_output(self) -> Data:\n        all_changes: List[str] = []\n        errors: List[str] = []\n        processed_files: List[str] = []\n\n        # Очистка кэша если нужно\n        if self.clear_cache:\n            self.clear_all_cache()\n            all_changes.append(\"🔄 Кэш очищен\")\n\n        # Парсим выход от парсера\n        parser_data = self.parse_parser_output(self.parser_output or \"\")\n\n        # Получаем путь к файлу: из parser_data или напрямую\n        file_path = parser_data.get('config_file', '').strip()\n\n        if not file_path:\n            return Data(value={\n                \"error\": \"config_file пустой (из parser_output)\",\n                \"yaml\": \"\",\n                \"changes\": all_changes,\n                \"errors\": [\"empty config_file\"],\n                \"is_final\": self.is_final,\n                \"parser_data\": parser_data\n            })\n\n        # Проверяем кэш\n        cached = self.get_cached_ast(file_path)\n\n        if cached:\n            config, config_key, ast = cached\n        else:\n            try:\n                config, config_key, directives = self.load_yaml_config(file_path)\n                ast = self.build_ast(directives)\n            except Exception as e:\n                return Data(value={\n                    \"error\": str(e),\n                    \"yaml\": \"\",\n                    \"changes\": all_changes,\n                    \"errors\": [str(e)],\n                    \"parser_data\": parser_data\n                })\n\n        # Проверяем config_key\n        parser_config_key = parser_data.get('config_key')\n        if parser_config_key and parser_config_key != config_key:\n            errors.append(f\"config_key mismatch: parser={parser_config_key}, file={config_key}\")\n\n        # Извлекаем JSON от LLM\n        responses = self.extract_json_blocks(self.llm_responses or \"\")\n\n        if not responses:\n            if self.is_final:\n                # Финальная итерация — сохраняем что есть\n                pass\n            else:\n                return Data(value={\n                    \"error\": \"No JSON\",\n                    \"yaml\": \"\",\n                    \"changes\": all_changes,\n                    \"errors\": [\"No JSON in llm_responses\"],\n                    \"parser_data\": parser_data\n                })\n\n        # Применяем ответы\n        for idx, resp in enumerate(responses):\n            try:\n                resp_key = resp.get('config_key')\n                if resp_key and resp_key != config_key:\n                    errors.append(f\"[{idx}] config_key mismatch: resp={resp_key}, file={config_key}\")\n                    continue\n\n                changes = self.apply_response(ast, resp, parser_data)\n                all_changes.extend([f\"[{idx}] {c}\" for c in changes])\n            except Exception as e:\n                errors.append(f\"[{idx}] {type(e).__name__}: {e}\")\n\n        # Сохраняем в кэш\n        self.cache_ast(file_path, config, config_key, ast, all_changes)\n\n        # Рендерим YAML\n        yaml_result = \"\"\n        saved_to = None\n\n        try:\n            new_directives = self.render_ast(ast)\n            config[config_key] = new_directives\n            yaml_result = yaml.dump(\n                config,\n                default_flow_style=False,\n                allow_unicode=True,\n                sort_keys=False,\n                width=4096,\n                Dumper=MyDumper\n            )\n\n            # Сохраняем если финальная итерация\n            if self.is_final and self.output_dir:\n                output_path = self.get_output_path(file_path, self.output_dir)\n                Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n                Path(output_path).write_text(yaml_result, encoding='utf-8')\n                saved_to = output_path\n                processed_files.append(output_path)\n\n        except Exception as e:\n            errors.append(f\"Render/Save: {e}\")\n\n        self._yaml_result = yaml_result\n        self._all_changes = self.get_all_cached_changes()\n\n        self.status = f\"{'✅ FINAL' if self.is_final else '🔄'} {len(responses)} resp, {len(all_changes)} changes\"\n\n        return Data(value={\n            \"yaml\": yaml_result,\n            \"changes\": all_changes,\n            \"errors\": errors,\n            \"responses_processed\": len(responses),\n            \"source_file\": file_path,\n            \"saved_to\": saved_to,\n            \"is_final\": self.is_final,\n            \"cached_files\": list(self._config_cache.keys()),\n            \"total_changes\": sum(len(v) for v in self._all_changes.values()) if hasattr(self, '_all_changes') else 0,\n            \"parser_data\": parser_data,\n        })\n\n    def get_yaml_string(self) -> str:\n        return getattr(self, '_yaml_result', \"\")\n\n    def get_all_changes(self) -> Data:\n        \"\"\"Возвращает все накопленные изменения по всем файлам\"\"\"\n        return Data(value=getattr(self, '_all_changes', {}))"
              },
              "is_final": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Is Final Iteration",
                "dynamic": false,
                "info": "Финальная итерация цикла — сохранить все накопленные изменения",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "is_final",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "llm_responses": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "LLM Responses",
                "dynamic": false,
                "info": "JSON ответы от LLM",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "llm_responses",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_dir": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Directory",
                "dynamic": false,
                "info": "Директория для сохранения результатов",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_dir",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/output/"
              },
              "parser_output": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Parser Output",
                "dynamic": false,
                "info": "Выход от парсера с полями: Index, Operation, Config Key, Config File и др.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "parser_output",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "output",
          "showNode": true,
          "type": "NginxConfigAssemblerAST"
        },
        "dragging": false,
        "id": "NginxConfigAssemblerAST-qbIoX",
        "measured": {
          "height": 467,
          "width": 320
        },
        "position": {
          "x": 12937.098312524131,
          "y": 2014.064101207824
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ParserComponent-hqKni",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts text using a template.",
            "display_name": "Parser",
            "documentation": "https://docs.langflow.org/components-processing#parser",
            "edited": false,
            "field_order": [
              "input_data",
              "mode",
              "pattern",
              "sep"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "ParserComponent",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Parsed Text",
                "group_outputs": false,
                "method": "parse_combined_text",
                "name": "parsed_text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, HandleInput, MessageTextInput, MultilineInput, TabInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.template.field.base import Output\n\n\nclass ParserComponent(Component):\n    display_name = \"Parser\"\n    description = \"Extracts text using a template.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#parser\"\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"input_data\",\n            display_name=\"Data or DataFrame\",\n            input_types=[\"DataFrame\", \"Data\"],\n            info=\"Accepts either a DataFrame or a Data object.\",\n            required=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"Parser\", \"Stringify\"],\n            value=\"Parser\",\n            info=\"Convert into raw string instead of using a template.\",\n            real_time_refresh=True,\n        ),\n        MultilineInput(\n            name=\"pattern\",\n            display_name=\"Template\",\n            info=(\n                \"Use variables within curly brackets to extract column values for DataFrames \"\n                \"or key values for Data.\"\n                \"For example: `Name: {Name}, Age: {Age}, Country: {Country}`\"\n            ),\n            value=\"Text: {text}\",  # Example default\n            dynamic=True,\n            show=True,\n            required=True,\n        ),\n        MessageTextInput(\n            name=\"sep\",\n            display_name=\"Separator\",\n            advanced=True,\n            value=\"\\n\",\n            info=\"String used to separate rows/items.\",\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Parsed Text\",\n            name=\"parsed_text\",\n            info=\"Formatted text output.\",\n            method=\"parse_combined_text\",\n        ),\n    ]\n\n    def update_build_config(self, build_config, field_value, field_name=None):\n        \"\"\"Dynamically hide/show `template` and enforce requirement based on `stringify`.\"\"\"\n        if field_name == \"mode\":\n            build_config[\"pattern\"][\"show\"] = self.mode == \"Parser\"\n            build_config[\"pattern\"][\"required\"] = self.mode == \"Parser\"\n            if field_value:\n                clean_data = BoolInput(\n                    name=\"clean_data\",\n                    display_name=\"Clean Data\",\n                    info=(\n                        \"Enable to clean the data by removing empty rows and lines \"\n                        \"in each cell of the DataFrame/ Data object.\"\n                    ),\n                    value=True,\n                    advanced=True,\n                    required=False,\n                )\n                build_config[\"clean_data\"] = clean_data.to_dict()\n            else:\n                build_config.pop(\"clean_data\", None)\n\n        return build_config\n\n    def _clean_args(self):\n        \"\"\"Prepare arguments based on input type.\"\"\"\n        input_data = self.input_data\n\n        match input_data:\n            case list() if all(isinstance(item, Data) for item in input_data):\n                msg = \"List of Data objects is not supported.\"\n                raise ValueError(msg)\n            case DataFrame():\n                return input_data, None\n            case Data():\n                return None, input_data\n            case dict() if \"data\" in input_data:\n                try:\n                    if \"columns\" in input_data:  # Likely a DataFrame\n                        return DataFrame.from_dict(input_data), None\n                    # Likely a Data object\n                    return None, Data(**input_data)\n                except (TypeError, ValueError, KeyError) as e:\n                    msg = f\"Invalid structured input provided: {e!s}\"\n                    raise ValueError(msg) from e\n            case _:\n                msg = f\"Unsupported input type: {type(input_data)}. Expected DataFrame or Data.\"\n                raise ValueError(msg)\n\n    def parse_combined_text(self) -> Message:\n        \"\"\"Parse all rows/items into a single text or convert input to string if `stringify` is enabled.\"\"\"\n        # Early return for stringify option\n        if self.mode == \"Stringify\":\n            return self.convert_to_string()\n\n        df, data = self._clean_args()\n\n        lines = []\n        if df is not None:\n            for _, row in df.iterrows():\n                formatted_text = self.pattern.format(**row.to_dict())\n                lines.append(formatted_text)\n        elif data is not None:\n            formatted_text = self.pattern.format(**data.data)\n            lines.append(formatted_text)\n\n        combined_text = self.sep.join(lines)\n        self.status = combined_text\n        return Message(text=combined_text)\n\n    def convert_to_string(self) -> Message:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        result = \"\"\n        if isinstance(self.input_data, list):\n            result = \"\\n\".join([safe_convert(item, clean_data=self.clean_data or False) for item in self.input_data])\n        else:\n            result = safe_convert(self.input_data or False)\n        self.log(f\"Converted to string with length: {len(result)}\")\n\n        message = Message(text=result)\n        self.status = message\n        return message\n"
              },
              "input_data": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Data or DataFrame",
                "dynamic": false,
                "info": "Accepts either a DataFrame or a Data object.",
                "input_types": [
                  "DataFrame",
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Convert into raw string instead of using a template.",
                "name": "mode",
                "options": [
                  "Parser",
                  "Stringify"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "Parser"
              },
              "pattern": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": true,
                "info": "Use variables within curly brackets to extract column values for DataFrames or key values for Data.For example: `Name: {Name}, Age: {Age}, Country: {Country}`",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "pattern",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "- Config File: {config_file}\n"
              },
              "sep": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "String used to separate rows/items.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ParserComponent"
        },
        "dragging": false,
        "id": "ParserComponent-hqKni",
        "measured": {
          "height": 327,
          "width": 320
        },
        "position": {
          "x": 7499.987778608884,
          "y": 1659.606653298463
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-i01pc",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "https://docs.langflow.org/components-io#chat-output",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatOutput",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.003169567463043492,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nimport orjson\nfrom fastapi.encoders import jsonable_encoder\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.helpers.data import safe_convert\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, HandleInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.template.field.base import Output\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-output\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Output Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _serialize_data(self, data: Data) -> str:\n        \"\"\"Serialize Data object to JSON string.\"\"\"\n        # Convert data.data to JSON-serializable format\n        serializable_data = jsonable_encoder(data.data)\n        # Serialize with orjson, enabling pretty printing with indentation\n        json_bytes = orjson.dumps(serializable_data, option=orjson.OPT_INDENT_2)\n        # Convert bytes to string and wrap in Markdown code blocks\n        return \"```json\\n\" + json_bytes.decode(\"utf-8\") + \"\\n```\"\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            clean_data: bool = getattr(self, \"clean_data\", False)\n            return \"\\n\".join([safe_convert(item, clean_data=clean_data) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "external_options": {},
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-i01pc",
        "measured": {
          "height": 48,
          "width": 192
        },
        "position": {
          "x": 2082.3094646536265,
          "y": 1759.0719308969585
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-dqFNm",
          "node": {
            "base_classes": [
              "Data",
              "Text"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Собирает YAML конфиг Nginx upstreams. Поддерживает ADD/MODIFY/DELETE операции над апстримами.",
            "display_name": "Nginx Upstream Assembler",
            "documentation": "",
            "edited": true,
            "field_order": [
              "llm_responses",
              "source_file",
              "output_dir",
              "upstream_name",
              "is_final",
              "clear_cache"
            ],
            "frozen": false,
            "icon": "server",
            "legacy": false,
            "lf_version": "1.6.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "group_outputs": false,
                "hidden": null,
                "method": "build_output",
                "name": "output",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "YAML String",
                "group_outputs": false,
                "hidden": null,
                "method": "get_yaml_string",
                "name": "yaml_output",
                "options": null,
                "required_inputs": null,
                "selected": "Text",
                "tool_mode": true,
                "types": [
                  "Text"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "All Changes",
                "group_outputs": false,
                "hidden": null,
                "method": "get_all_changes",
                "name": "all_changes",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clear_cache": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Clear Cache",
                "dynamic": false,
                "info": "Очистить кэш перед обработкой",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "clear_cache",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output, BoolInput\nfrom langflow.schema.data import Data\nimport json\nimport re\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Tuple, Optional\nimport yaml\nimport hashlib\nimport copy\n\n\nclass MyDumper(yaml.Dumper):\n    \"\"\"Custom YAML dumper for better formatting\"\"\"\n    def increase_indent(self, flow=False, indentless=False):\n        return super(MyDumper, self).increase_indent(flow, False)\n\n\nclass NginxUpstreamAssembler(Component):\n    display_name = \"Nginx Upstream Assembler\"\n    description = \"Собирает YAML конфиг Nginx upstreams. Поддерживает ADD/MODIFY/DELETE операции над апстримами.\"\n    icon = \"server\"\n    name = \"NginxUpstreamAssembler\"\n\n    # Хранилище для накопления изменений между вызовами\n    _config_cache: Dict[str, Dict[str, Any]] = {}\n\n    inputs = [\n        MessageTextInput(\n            name=\"llm_responses\",\n            display_name=\"LLM Responses\",\n            info=\"JSON ответы от LLM с операциями над апстримами\",\n            value=\"\",\n            tool_mode=True,\n        ),\n        MessageTextInput(\n            name=\"source_file\",\n            display_name=\"Source File\",\n            info=\"Путь к файлу skdpu_http_upstreams.yml\",\n            value=\"/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/skdpu_config/skdpu_http_upstreams.yml\",\n            tool_mode=False,\n        ),\n        MessageTextInput(\n            name=\"output_dir\",\n            display_name=\"Output Directory\",\n            info=\"Директория для сохранения результатов\",\n            value=\"/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/output/\",\n            tool_mode=False,\n        ),\n        MessageTextInput(\n            name=\"upstream_name\",\n            display_name=\"Upstream Name (Optional)\",\n            info=\"Имя апстрима для операции (опционально, берётся из LLM response)\",\n            value=\"\",\n            tool_mode=True,\n        ),\n        BoolInput(\n            name=\"is_final\",\n            display_name=\"Is Final Iteration\",\n            info=\"Финальная итерация — сохранить все накопленные изменения\",\n            value=False,\n        ),\n        BoolInput(\n            name=\"clear_cache\",\n            display_name=\"Clear Cache\",\n            info=\"Очистить кэш перед обработкой\",\n            value=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n        Output(display_name=\"YAML String\", name=\"yaml_output\", method=\"get_yaml_string\"),\n        Output(display_name=\"All Changes\", name=\"all_changes\", method=\"get_all_changes\"),\n    ]\n\n    # ================== Cache Management ==================\n\n    def get_cache_key(self, file_path: str) -> str:\n        \"\"\"Генерирует ключ кэша из пути файла\"\"\"\n        return str(Path(file_path).resolve())\n\n    def get_cached_config(self, file_path: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Получает конфиг из кэша\"\"\"\n        key = self.get_cache_key(file_path)\n        if key in self._config_cache:\n            return self._config_cache[key]['config']\n        return None\n\n    def cache_config(self, file_path: str, config: Dict[str, Any], changes: List[str]):\n        \"\"\"Сохраняет конфиг в кэш\"\"\"\n        key = self.get_cache_key(file_path)\n        \n        if key not in self._config_cache:\n            self._config_cache[key] = {\n                'config': config,\n                'changes': [],\n                'original_hash': self.compute_hash(config)\n            }\n        \n        self._config_cache[key]['config'] = config\n        self._config_cache[key]['changes'].extend(changes)\n\n    def get_all_cached_changes(self) -> Dict[str, List[str]]:\n        \"\"\"Возвращает все накопленные изменения\"\"\"\n        return {k: v['changes'] for k, v in self._config_cache.items()}\n\n    def clear_all_cache(self):\n        \"\"\"Очищает весь кэш\"\"\"\n        self._config_cache.clear()\n\n    def compute_hash(self, data: Any) -> str:\n        \"\"\"Вычисляет хэш данных\"\"\"\n        return hashlib.md5(json.dumps(data, sort_keys=True, default=str).encode()).hexdigest()\n\n    # ================== File Operations ==================\n\n    def load_upstreams_config(self, file_path: str) -> Dict[str, Any]:\n        \"\"\"Загружает конфиг апстримов из YAML файла\"\"\"\n        if not file_path:\n            raise ValueError(\"Путь к файлу не указан\")\n        \n        path = Path(file_path.strip())\n        if not path.exists():\n            raise FileNotFoundError(f\"Файл не найден: {file_path}\")\n\n        text = path.read_text(encoding=\"utf-8\")\n        data = yaml.safe_load(text)\n\n        if not data or not isinstance(data, dict):\n            raise ValueError(\"Некорректный YAML\")\n\n        # Ожидаем структуру: nginx_http_upstreams: { upstream_name: {...}, ... }\n        if 'nginx_http_upstreams' not in data:\n            raise ValueError(\"Отсутствует ключ 'nginx_http_upstreams' в файле\")\n\n        return data\n\n    def save_config(self, file_path: str, config: Dict[str, Any]) -> str:\n        \"\"\"Сохраняет конфиг в файл\"\"\"\n        yaml_result = yaml.dump(\n            config,\n            default_flow_style=False,\n            allow_unicode=True,\n            sort_keys=False,\n            width=4096,\n            Dumper=MyDumper,\n        )\n        \n        path = Path(file_path)\n        path.parent.mkdir(parents=True, exist_ok=True)\n        path.write_text(yaml_result, encoding='utf-8')\n        \n        return yaml_result\n\n    def get_output_path(self, source_path: str, output_dir: str) -> str:\n        \"\"\"Генерирует путь для выходного файла\"\"\"\n        source = Path(source_path)\n        out_dir = Path(output_dir) if output_dir else source.parent\n        \n        new_name = f\"{source.stem}_modified{source.suffix}\"\n        return str(out_dir / new_name)\n\n    # ================== JSON Extraction ==================\n\n    def extract_json_blocks(self, text: str) -> List[Dict[str, Any]]:\n        \"\"\"Извлекает JSON блоки из текста\"\"\"\n        if not text:\n            return []\n        \n        results: List[Dict[str, Any]] = []\n        \n        # 1. Пробуем ```json блоки\n        json_blocks = re.findall(r'```json\\s*(.*?)\\s*```', text, re.DOTALL)\n        for block in json_blocks:\n            try:\n                parsed = json.loads(block)\n                if isinstance(parsed, dict):\n                    results.append(parsed)\n                elif isinstance(parsed, list):\n                    results.extend(parsed)\n            except Exception:\n                continue\n        \n        if results:\n            return results\n        \n        # 2. Пробуем как единый JSON\n        try:\n            parsed = json.loads(text)\n            if isinstance(parsed, dict):\n                return [parsed]\n            if isinstance(parsed, list):\n                return parsed\n        except Exception:\n            pass\n        \n        # 3. Ищем JSON объекты в тексте\n        brace_depth = 0\n        current_start = None\n        \n        for i, char in enumerate(text):\n            if char == '{':\n                if brace_depth == 0:\n                    current_start = i\n                brace_depth += 1\n            elif char == '}':\n                brace_depth -= 1\n                if brace_depth == 0 and current_start is not None:\n                    json_str = text[current_start:i+1]\n                    try:\n                        results.append(json.loads(json_str))\n                    except Exception:\n                        pass\n                    current_start = None\n        \n        return results\n\n    # ================== Upstream Operations ==================\n\n    def get_upstream(self, config: Dict[str, Any], upstream_name: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Получает апстрим по имени\"\"\"\n        upstreams = config.get('nginx_http_upstreams', {})\n        return upstreams.get(upstream_name)\n\n    def set_upstream(self, config: Dict[str, Any], upstream_name: str, upstream_data: Dict[str, Any]):\n        \"\"\"Устанавливает/обновляет апстрим\"\"\"\n        if 'nginx_http_upstreams' not in config:\n            config['nginx_http_upstreams'] = {}\n        config['nginx_http_upstreams'][upstream_name] = upstream_data\n\n    def delete_upstream(self, config: Dict[str, Any], upstream_name: str) -> bool:\n        \"\"\"Удаляет апстрим\"\"\"\n        upstreams = config.get('nginx_http_upstreams', {})\n        if upstream_name in upstreams:\n            del upstreams[upstream_name]\n            return True\n        return False\n\n    def normalize_server(self, server: str) -> str:\n        \"\"\"Нормализует формат сервера (добавляет порт если нет)\"\"\"\n        server = str(server).strip()\n        if ':' not in server:\n            server = f\"{server}:80\"\n        return server\n\n    def normalize_servers_list(self, servers: List[str]) -> List[str]:\n        \"\"\"Нормализует список серверов\"\"\"\n        return [self.normalize_server(s) for s in servers if s]\n\n    # ================== Operation Handlers ==================\n\n    def apply_modify_upstream(self, config: Dict[str, Any], response: Dict[str, Any]) -> List[str]:\n        \"\"\"\n        MODIFY_UPSTREAM — модификация существующего апстрима\n        \n        Поддерживает:\n        - replace_all: полная замена main и/или backup серверов\n        - add_servers: добавление серверов\n        - remove_servers: удаление серверов\n        \"\"\"\n        changes: List[str] = []\n        \n        upstream_name = response.get('upstream_name')\n        if not upstream_name:\n            return [\"❌ MODIFY_UPSTREAM: не указан upstream_name\"]\n        \n        existing = self.get_upstream(config, upstream_name)\n        if not existing:\n            return [f\"❌ Upstream '{upstream_name}' не найден\"]\n        \n        modification_type = response.get('modification_type', 'replace_all')\n        target_section = response.get('target_section', 'all')  # main, backup, all\n        \n        # Получаем updated_json из LLM response\n        updated_json = response.get('updated_json', {})\n        upstream_update = updated_json.get(upstream_name, {})\n        \n        if not upstream_update and response.get('analysis'):\n            # Строим из analysis если нет updated_json\n            analysis = response['analysis']\n            upstream_update = copy.deepcopy(existing)\n            \n            if 'main' in analysis and analysis['main'].get('new_servers'):\n                upstream_update['main'] = {'servers': analysis['main']['new_servers']}\n            if 'backup' in analysis and analysis['backup'].get('new_servers'):\n                upstream_update['backup'] = {'servers': analysis['backup']['new_servers']}\n        \n        if not upstream_update:\n            return [\"❌ MODIFY_UPSTREAM: нет данных для обновления\"]\n        \n        # Применяем изменения\n        old_upstream = copy.deepcopy(existing)\n        \n        if modification_type == 'replace_all':\n            # Полная замена секций\n            if target_section in ('main', 'all') and 'main' in upstream_update:\n                old_main = existing.get('main', {}).get('servers', [])\n                new_main = upstream_update['main'].get('servers', [])\n                existing['main'] = {'servers': self.normalize_servers_list(new_main)}\n                changes.append(f\"🔄 {upstream_name}/main: {old_main} → {new_main}\")\n            \n            if target_section in ('backup', 'all') and 'backup' in upstream_update:\n                old_backup = existing.get('backup', {}).get('servers', [])\n                new_backup = upstream_update['backup'].get('servers', [])\n                existing['backup'] = {'servers': self.normalize_servers_list(new_backup)}\n                changes.append(f\"🔄 {upstream_name}/backup: {old_backup} → {new_backup}\")\n            \n            # Обновляем метаданные если есть\n            for key in ('domains', 'environment', 'system_id'):\n                if key in upstream_update:\n                    existing[key] = upstream_update[key]\n        \n        elif modification_type == 'add_servers':\n            # Добавление серверов\n            if target_section in ('main', 'all') and 'main' in upstream_update:\n                if 'main' not in existing:\n                    existing['main'] = {'servers': []}\n                new_servers = upstream_update['main'].get('servers', [])\n                for server in new_servers:\n                    normalized = self.normalize_server(server)\n                    if normalized not in existing['main']['servers']:\n                        existing['main']['servers'].append(normalized)\n                        changes.append(f\"➕ {upstream_name}/main: добавлен {normalized}\")\n            \n            if target_section in ('backup', 'all') and 'backup' in upstream_update:\n                if 'backup' not in existing:\n                    existing['backup'] = {'servers': []}\n                new_servers = upstream_update['backup'].get('servers', [])\n                for server in new_servers:\n                    normalized = self.normalize_server(server)\n                    if normalized not in existing['backup']['servers']:\n                        existing['backup']['servers'].append(normalized)\n                        changes.append(f\"➕ {upstream_name}/backup: добавлен {normalized}\")\n        \n        elif modification_type == 'remove_servers':\n            # Удаление серверов\n            servers_to_remove = response.get('servers_to_remove', [])\n            if not servers_to_remove and 'analysis' in response:\n                # Пытаемся извлечь из diff\n                diff = response.get('diff', {})\n                if 'main' in diff:\n                    servers_to_remove.extend(diff['main'].get('old_servers', []))\n                if 'backup' in diff:\n                    servers_to_remove.extend(diff['backup'].get('old_servers', []))\n            \n            normalized_to_remove = set(self.normalize_server(s) for s in servers_to_remove)\n            \n            if target_section in ('main', 'all') and 'main' in existing:\n                old_servers = existing['main'].get('servers', [])\n                new_servers = [s for s in old_servers if self.normalize_server(s) not in normalized_to_remove]\n                removed = set(old_servers) - set(new_servers)\n                if removed:\n                    existing['main']['servers'] = new_servers\n                    changes.append(f\"🗑️ {upstream_name}/main: удалены {list(removed)}\")\n            \n            if target_section in ('backup', 'all') and 'backup' in existing:\n                old_servers = existing['backup'].get('servers', [])\n                new_servers = [s for s in old_servers if self.normalize_server(s) not in normalized_to_remove]\n                removed = set(old_servers) - set(new_servers)\n                if removed:\n                    existing['backup']['servers'] = new_servers\n                    changes.append(f\"🗑️ {upstream_name}/backup: удалены {list(removed)}\")\n        \n        # Сохраняем обновлённый апстрим\n        self.set_upstream(config, upstream_name, existing)\n        \n        if not changes:\n            changes.append(f\"ℹ️ {upstream_name}: без изменений\")\n        \n        return changes\n\n    def apply_create_upstream(self, config: Dict[str, Any], response: Dict[str, Any]) -> List[str]:\n        \"\"\"CREATE_UPSTREAM — создание нового апстрима\"\"\"\n        changes: List[str] = []\n        \n        upstream_name = response.get('upstream_name')\n        if not upstream_name:\n            return [\"❌ CREATE_UPSTREAM: не указан upstream_name\"]\n        \n        existing = self.get_upstream(config, upstream_name)\n        if existing:\n            return [f\"❌ Upstream '{upstream_name}' уже существует. Используйте MODIFY_UPSTREAM\"]\n        \n        # Получаем данные для нового апстрима\n        updated_json = response.get('updated_json', {})\n        new_upstream = updated_json.get(upstream_name, {})\n        \n        if not new_upstream:\n            # Пробуем собрать из других полей\n            new_upstream = {\n                'main': {'servers': response.get('main_servers', [])},\n                'backup': {'servers': response.get('backup_servers', [])},\n                'domains': response.get('domains', []),\n                'environment': response.get('environment', 'production'),\n                'system_id': response.get('system_id', '')\n            }\n        \n        # Нормализуем серверы\n        if 'main' in new_upstream and 'servers' in new_upstream['main']:\n            new_upstream['main']['servers'] = self.normalize_servers_list(new_upstream['main']['servers'])\n        if 'backup' in new_upstream and 'servers' in new_upstream['backup']:\n            new_upstream['backup']['servers'] = self.normalize_servers_list(new_upstream['backup']['servers'])\n        \n        # Создаём апстрим\n        self.set_upstream(config, upstream_name, new_upstream)\n        \n        changes.append(f\"✅ Создан upstream '{upstream_name}'\")\n        if new_upstream.get('main', {}).get('servers'):\n            changes.append(f\"   main: {new_upstream['main']['servers']}\")\n        if new_upstream.get('backup', {}).get('servers'):\n            changes.append(f\"   backup: {new_upstream['backup']['servers']}\")\n        \n        return changes\n\n    def apply_delete_upstream(self, config: Dict[str, Any], response: Dict[str, Any]) -> List[str]:\n        \"\"\"DELETE_UPSTREAM — удаление апстрима\"\"\"\n        changes: List[str] = []\n        \n        upstream_name = response.get('upstream_name')\n        if not upstream_name:\n            return [\"❌ DELETE_UPSTREAM: не указан upstream_name\"]\n        \n        existing = self.get_upstream(config, upstream_name)\n        if not existing:\n            return [f\"❌ Upstream '{upstream_name}' не найден\"]\n        \n        # Удаляем\n        self.delete_upstream(config, upstream_name)\n        changes.append(f\"🗑️ Удалён upstream '{upstream_name}'\")\n        \n        return changes\n\n    def apply_replace_upstream(self, config: Dict[str, Any], response: Dict[str, Any]) -> List[str]:\n        \"\"\"REPLACE_UPSTREAM — полная замена апстрима\"\"\"\n        changes: List[str] = []\n        \n        upstream_name = response.get('upstream_name')\n        if not upstream_name:\n            return [\"❌ REPLACE_UPSTREAM: не указан upstream_name\"]\n        \n        updated_json = response.get('updated_json', {})\n        new_upstream = updated_json.get(upstream_name, {})\n        \n        if not new_upstream:\n            return [\"❌ REPLACE_UPSTREAM: нет данных для замены\"]\n        \n        existing = self.get_upstream(config, upstream_name)\n        \n        # Нормализуем серверы\n        if 'main' in new_upstream and 'servers' in new_upstream['main']:\n            new_upstream['main']['servers'] = self.normalize_servers_list(new_upstream['main']['servers'])\n        if 'backup' in new_upstream and 'servers' in new_upstream['backup']:\n            new_upstream['backup']['servers'] = self.normalize_servers_list(new_upstream['backup']['servers'])\n        \n        # Заменяем\n        self.set_upstream(config, upstream_name, new_upstream)\n        \n        if existing:\n            changes.append(f\"🔄 Заменён upstream '{upstream_name}'\")\n        else:\n            changes.append(f\"✅ Создан upstream '{upstream_name}'\")\n        \n        return changes\n\n    # ================== Main Dispatcher ==================\n\n    def apply_response(self, config: Dict[str, Any], response: Dict[str, Any]) -> List[str]:\n        \"\"\"Применяет ответ LLM к конфигу\"\"\"\n        if response.get('status') not in ('success', 'partial_success'):\n            return [f\"⚠️ Пропущен: status={response.get('status')}\"]\n        \n        operation = (\n            response.get('operation_type') or\n            response.get('operation') or\n            ''\n        ).upper()\n        \n        # Маппинг операций\n        handlers = {\n            'MODIFY_UPSTREAM': self.apply_modify_upstream,\n            'UPDATE_UPSTREAM': self.apply_modify_upstream,\n            'CREATE_UPSTREAM': self.apply_create_upstream,\n            'ADD_UPSTREAM': self.apply_create_upstream,\n            'DELETE_UPSTREAM': self.apply_delete_upstream,\n            'REMOVE_UPSTREAM': self.apply_delete_upstream,\n            'REPLACE_UPSTREAM': self.apply_replace_upstream,\n        }\n        \n        handler = handlers.get(operation)\n        if handler:\n            return handler(config, response)\n        \n        # Эвристика: если есть updated_json — пробуем modify\n        if response.get('updated_json'):\n            return self.apply_modify_upstream(config, response)\n        \n        return [f\"⚠️ Неизвестная операция: {operation}\"]\n\n    # ================== Build ==================\n\n    def build_output(self) -> Data:\n        all_changes: List[str] = []\n        errors: List[str] = []\n        \n        # Очистка кэша если нужно\n        if self.clear_cache:\n            self.clear_all_cache()\n            all_changes.append(\"🔄 Кэш очищен\")\n        \n        file_path = self.source_file.strip() if self.source_file else \"\"\n        \n        if not file_path:\n            return Data(value={\n                \"error\": \"source_file не указан\",\n                \"yaml\": \"\",\n                \"changes\": all_changes,\n                \"errors\": [\"empty source_file\"],\n                \"is_final\": self.is_final,\n            })\n        \n        # Проверяем кэш\n        cached_config = self.get_cached_config(file_path)\n        \n        if cached_config:\n            config = cached_config\n        else:\n            try:\n                config = self.load_upstreams_config(file_path)\n            except Exception as e:\n                return Data(value={\n                    \"error\": str(e),\n                    \"yaml\": \"\",\n                    \"changes\": all_changes,\n                    \"errors\": [str(e)],\n                })\n        \n        # Извлекаем JSON от LLM\n        responses = self.extract_json_blocks(self.llm_responses or \"\")\n        \n        if not responses:\n            if self.is_final:\n                pass  # Финальная итерация — сохраняем что есть\n            else:\n                return Data(value={\n                    \"error\": \"No JSON in llm_responses\",\n                    \"yaml\": \"\",\n                    \"changes\": all_changes,\n                    \"errors\": [\"No JSON in llm_responses\"],\n                })\n        \n        # Применяем ответы\n        for idx, resp in enumerate(responses):\n            try:\n                # Если upstream_name указан в инпуте — используем его\n                if self.upstream_name and not resp.get('upstream_name'):\n                    resp['upstream_name'] = self.upstream_name\n                \n                changes = self.apply_response(config, resp)\n                all_changes.extend([f\"[{idx}] {c}\" for c in changes])\n            except Exception as e:\n                errors.append(f\"[{idx}] {type(e).__name__}: {e}\")\n        \n        # Сохраняем в кэш\n        self.cache_config(file_path, config, all_changes)\n        \n        # Рендерим YAML\n        yaml_result = \"\"\n        saved_to = None\n        \n        try:\n            yaml_result = yaml.dump(\n                config,\n                default_flow_style=False,\n                allow_unicode=True,\n                sort_keys=False,\n                width=4096,\n                Dumper=MyDumper\n            )\n            \n            # Сохраняем если финальная итерация\n            if self.is_final and self.output_dir:\n                output_path = self.get_output_path(file_path, self.output_dir)\n                Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n                Path(output_path).write_text(yaml_result, encoding='utf-8')\n                saved_to = output_path\n                \n        except Exception as e:\n            errors.append(f\"Render/Save: {e}\")\n        \n        self._yaml_result = yaml_result\n        self._all_changes = self.get_all_cached_changes()\n        \n        self.status = f\"{'✅ FINAL' if self.is_final else '🔄'} {len(responses)} resp, {len(all_changes)} changes\"\n        \n        return Data(value={\n            \"yaml\": yaml_result,\n            \"changes\": all_changes,\n            \"errors\": errors,\n            \"responses_processed\": len(responses),\n            \"source_file\": file_path,\n            \"saved_to\": saved_to,\n            \"is_final\": self.is_final,\n            \"cached_files\": list(self._config_cache.keys()),\n            \"total_changes\": sum(len(v) for v in self._all_changes.values()) if hasattr(self, '_all_changes') else 0,\n        })\n\n    def get_yaml_string(self) -> str:\n        return getattr(self, '_yaml_result', \"\")\n\n    def get_all_changes(self) -> Data:\n        \"\"\"Возвращает все накопленные изменения\"\"\"\n        return Data(value=getattr(self, '_all_changes', {}))"
              },
              "is_final": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Is Final Iteration",
                "dynamic": false,
                "info": "Финальная итерация — сохранить все накопленные изменения",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "is_final",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "llm_responses": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "LLM Responses",
                "dynamic": false,
                "info": "JSON ответы от LLM с операциями над апстримами",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "llm_responses",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "output_dir": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Output Directory",
                "dynamic": false,
                "info": "Директория для сохранения результатов",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "output_dir",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/output/"
              },
              "source_file": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Source File",
                "dynamic": false,
                "info": "Путь к файлу skdpu_http_upstreams.yml",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "source_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "/Users/rusk/PycharmProjects/fastapi/portalFastDjango/mosru_nginx/mos_ru_nginx/skdpu_config/skdpu_http_upstreams.yml"
              },
              "upstream_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Upstream Name (Optional)",
                "dynamic": false,
                "info": "Имя апстрима для операции (опционально, берётся из LLM response)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "upstream_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "output",
          "showNode": true,
          "type": "NginxUpstreamAssembler"
        },
        "dragging": false,
        "id": "CustomComponent-dqFNm",
        "measured": {
          "height": 565,
          "width": 320
        },
        "position": {
          "x": 11332.346950613286,
          "y": 3195.463208374547
        },
        "selected": true,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -4384.077243575175,
      "y": -1331.7581539732153,
      "zoom": 0.4809637273323879
    }
  },
  "description": "Create, Connect, Converse.",
  "endpoint_name": null,
  "id": "18040b8c-44e8-4b3b-b645-da05a12652cc",
  "is_component": false,
  "last_tested_version": "1.6.0",
  "name": "Yaml Sub Locations V2",
  "tags": []
}